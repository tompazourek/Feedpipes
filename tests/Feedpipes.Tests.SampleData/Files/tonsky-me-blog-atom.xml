<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-US">
 
  <title>tonsky.me</title>
  <subtitle>Nikita Prokopov’s blog</subtitle>
  <link type="application/atom+xml" href="https://tonsky.me/blog/atom.xml" rel="self" />
  <link rel="alternate" type="text/html" href="https://tonsky.me/" />
  <id>https://tonsky.me/</id>
  <updated>2019-07-16T15:02:09+00:00</updated>
  <author>
    <name>Nikita Prokopov</name>
    <email>niki@tonsky.me</email>
  </author>
 
  
  
    <entry>
      <title>Grumpy chronicles: Pedestal and routing</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/pedestal/" />
      <id>https://tonsky.me/blog/pedestal/</id>
      <published>2019-06-13T00:00:00+00:00</published>
      <updated>2019-06-13T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Migrating a web app from Ring to Pedestal
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>As part of an ongoing experiment, I decided to update Grumpy to Pedestal. The main commit we’ll be discussing is <a href="https://github.com/tonsky/grumpy/commit/141477477dd04d4a327208595b7344e3c4ed50ee">here</a>.</p>

<h1 id="long-live-middlewares">Long live middlewares</h1>

<p>The biggest difference between Ring and Pedestal is interceptors instead of middlewares. I like the idea and sympathize with the reasoning behind it: more control over execution which enables multithreading and async request/responses. Not that I need those for a content site such as Grumpy but it was fun to play with something different for a change.</p>

<p>Interceptors are inherently less elegant than middlewares: they are records, so you have to rely on the interceptor library to build them. That is a bit annoying since now you have two types of things floating around: stuff that can be converted to interceptor and interceptors themselves. Those are not the same, and I used to mistake one for another a few times.</p>

<p>Unlike middlewares, which are simple functions, interceptors do not naturally compose. That means you’ll need something to run them for you, so you’ll have to bring Pedestal dependency whenever you need to play with those.</p>

<p>I was also happy to find out that most interceptors are just standard Ring middlewares converted to the new style. Most of my stuff “just worked” without too much conversion effort. E.g. parameters for Session middleware and Session interceptor <a href="https://github.com/tonsky/grumpy/blob/ea3f6d1f2c227e36760de28dea649aed36bbe00e/src/grumpy/auth.clj#L115-L119">perfectly match</a>, etc.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(def session
  (middlewares/session
    {:store (session.cookie/cookie-store
              {:key cookie-secret})
     :cookie-name "grumpy_session"
     :cookie-attrs session-cookie-attrs}))
</code></pre></div></div>

<p>Writing interceptors is <a href="https://github.com/tonsky/grumpy/blob/ea3f6d1f2c227e36760de28dea649aed36bbe00e/src/grumpy/auth.clj#L100-L113">as easy as writing middleware</a>. The biggest difference being that you now accept Context map and return Context map instead of request/response as in Ring. Context has both request/response as keys though.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(def force-user
  {:name ::force-user
   :enter
   (fn [ctx]
     (if-some [u grumpy/forced-user]
       (assoc-in ctx [:request :session :user] u)
       ctx))
   :leave
   (fn [ctx]
     (if-some [u grumpy/forced-user]
       (update ctx :response assoc
         :cookies {"grumpy_user"
                   (assoc user-cookie-attrs :value u)}
         :session {:user    u
                   :created (grumpy/now)})
       ctx))})
</code></pre></div></div>

<p>Being Clojure, Pedestal operates on loosely typed maps. This bestiary of map types was <a href="http://pedestal.io/reference/index#_handling_http">pretty helpful</a>.</p>

<p>One of the problems with Interceptors is that, despite being a great idea, they are not aiming at being a foundation for the next big Clojure web stack. For now, they are happy just being a part of Pedestal package. Others <a href="https://github.com/metosin/sieppari#differences-to-pedestal">are starting to build alternatives</a> with slightly different semantics, which I’m not sure is a good thing. I mean, alternatives are great, but two version of the same thing with almost the same contract but not quite? Might lead to segmentation and confusion.</p>

<h1 id="starting-server">Starting server</h1>

<p>For some reason there’s no documentation on how to start a server:</p>

<figure>
  <img src="https://tonsky.me/blog/pedestal/deployment.png" />
  These are supposed to be links...
</figure>

<p>Even the Jetty page here is a placeholder.</p>

<figure><img src="https://tonsky.me/blog/pedestal/jetty.png" /></figure>

<p>From <a href="http://pedestal.io/guides/hello-world">one of the guides</a> you can figure out that the method you need is <code class="highlighter-rouge">io.pedestal.http/create-server</code> which also has an empty API doc:</p>

<figure><img src="https://tonsky.me/blog/pedestal/create_server.png" /></figure>

<p>The only clue here is that argument is called “service-map” so you head onto <a href="http://pedestal.io/reference/service-map">third documentation page</a> that’s easiest to find through Google and finally you may have your answers:</p>

<figure><img src="https://tonsky.me/blog/pedestal/service_map.png" /></figure>

<p>Luckily, the server I wanted to use (Immutant) was on the list:</p>

<figure><img src="https://tonsky.me/blog/pedestal/http_type.png" /></figure>

<p>Not sure how hard would it be to use a custom Servlet container for example. I have no idea what “server function” might be, and it doesn’t seem to be documented anywhere.</p>

<h1 id="running-the-app">Running the app</h1>

<p>From there everything was smooth enough. The only annoyance was that production logs kept reporting “Broken pipe” error quite often:</p>

<figure>
  <a href="https://tonsky.me/blog/pedestal/broken_pipe.png"><img src="https://tonsky.me/blog/pedestal/broken_pipe_thumb.png" /></a>
  In full aligment with Clojure, stacktraces are enormous. Click to see full res.
</figure>

<p>As far as I understand, this is an error that happens when the server tries to write to a socket that was effectively closed but not reported as closed yet? I’m not certain on details but enough to know that it repeats quite reliably during normal site usage from a browser.</p>

<p>My point here is: why the heck is it reported as an error at all? If you have a web server, a client disconnect is not something exceptional. It’s not even a warning! This is a normal operation that should not be reported to the logs at all unless specifically asked. Imagine if TCP stack logged each lost packet…</p>

<p>It was not easy to get rid of, too. Writing to the socket is something that happens after all user-defined interceptors have finished, so you can’t use that <a href="http://pedestal.io/reference/error-handling">elaborate error-handling routine</a> to suppress this. My first attempt at catching this error in the last interceptor <a href="https://github.com/tonsky/grumpy/commit/fca324f142b1fd4076a2b834f2e0403103ceec0a">undestandably failed</a>.</p>

<pre style="width: 800px; margin: 0 -100px;"><code>(defn suppress-error [name class message-re]
   (interceptor/interceptor
     {:name name
      :error
      (fn [ctx ^Throwable e]
        (let [cause (stacktrace/root-cause e)
              message (.getMessage cause)]
          (if (and (instance? class cause) (re-matches message-re message))
            (do
              (println "Ignoring" (type cause) "-" message)
              ctx)
            (assoc ctx :io.pedestal.interceptor.chain/error e))))}))

...

(update ::http/interceptors
  #(cons (suppress-error ::suppress-broken-pipe
           java.io.IOException #"Broken pipe") %))</code></pre>

<p>(last :leave/:error interceptor have to go first because logic)</p>

<p>In any other language that would be game over. The error should be handled inside the framework, so it’s either pull request with hopes of getting it merged in the next six months in the best case, or cloning and running your own version.</p>

<p>But thank God we are coding in Clojure! Which means we can redefine anything, anywhere at runtime at no cost. Which is exactly what I did to <a href="https://github.com/tonsky/grumpy/commit/c6bbcc9590394243e37c2a72a4e569a7c506be7d">monkey-patch Pedestal’s internals on the fly</a>!</p>

<pre style="width: 800px; margin: 0 -100px;"><code>; Filtering out Broken pipe reporting
; io.pedestal.http.impl.servlet-interceptor/error-stylobate
(defn error-stylobate [{:keys [servlet-response] :as context} exception]
  (let [cause (stacktrace/root-cause exception)]
    (if (and (instance? IOException cause)
          (= "Broken pipe" (.getMessage cause)))
      (println "Ignoring java.io.IOException: Broken pipe")
      (io.pedestal.log/error
        :msg "error-stylobate triggered"
        :exception exception
        :context context))
    (@#'io.pedestal.http.impl.servlet-interceptor/leave-stylobate context)))


; io.pedestal.http.impl.servlet-interceptor/stylobate
(def stylobate
  (io.pedestal.interceptor/interceptor
    {:name ::stylobate
     :enter @#'io.pedestal.http.impl.servlet-interceptor/enter-stylobate
     :leave @#'io.pedestal.http.impl.servlet-interceptor/leave-stylobate
     :error error-stylobate}))

...

(with-redefs [io.pedestal.http.impl.servlet-interceptor/stylobate stylobate]
  (-&gt; ...
    (http/create-server)
    (http/start)))
</code></pre>

<p>I also <a href="https://github.com/pedestal/pedestal/pull/621">filed it to Pedestal upstream</a>, we’ll see how it goes.</p>

<h1 id="routing">Routing</h1>

<p>Pedestal comes with routing built-in, which is a nice upgrade from Ring that required you to look for a separate library to handle those.</p>

<p>Another welcome change coming from Compojure: in Compojure, you wrap routes in middlewares, which means middlewares apply <em>before</em> routing happens. That works fine unless you want a different set of middleware at different routes. It certainly can be made to work in Compojure as well, just not the default. In Pedestal, routing happens first and everything else is configured per-route.</p>

<p>One minor annoyance with Pedestal routes is that every route requires a unique name. I do agree that names, in general, are great, but not every little thing should have one. With routes, I believe, the method + path themselves make a great name. Forcing user to invent something else will just lead to obscure arbitrary names.</p>

<p>Another thing, a big one. Route composition and overlapping routes. Imagine the following routes:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/post/:id
/post/create
</code></pre></div></div>

<p>First one retrieves post by <code class="highlighter-rouge">id</code>, where <code class="highlighter-rouge">id</code> could be anything. BUT if that anything happens to be the word <code class="highlighter-rouge">"create"</code> then the second route should be triggered instead.</p>

<p>But is it even correct? Personally, I see no problem here. It’s pretty clear what should happen, the only downside is that you can’t have a post with <code class="highlighter-rouge">id == "create"</code> which is an acceptable tradeoff for beautiful URLs.</p>

<p>Compojure can make it work but only if you manually order your routes. That is because <code class="highlighter-rouge">/post/:id</code> also matches <code class="highlighter-rouge">/post/create</code>, but not the other way around.</p>

<p>Compojure matcher is a <em>linear matcher</em>. It examines routes one by one. That works fine as long as you don’t care about matching performance and as long as you can put your routes in the 
correct order.</p>

<p>But linear matching breaks encapsulation. Imagine that the final app is built from multiple namespaces each providing their own set of routes. If you have something like this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(ns A)
(def routes
  ["/post/:id" ...]
  ["/draft/create" ...])

(ns B)
(def routes
  ["/post/create" ...]
  ["/draft/:id" ...])
</code></pre></div></div>

<p>Then no matter in which order you include <code class="highlighter-rouge">A/routes</code> and <code class="highlighter-rouge">B/routes</code> one of the routes will be shadowed. It also makes changes to routes non-local, as adding a new route to one namespace might accidentally break something else <em>in a completely different namespace</em>.</p>

<p>That’s the case against linear routes. Slow performance and bad isolation. Happily, Pedestal comes with two more advanced routes that perform better by using tries instead of the linear scan to match routes. This is faster but unfortunately does not support our use-case.</p>

<p>Map tree only supports static routes. If you need to pass any parameter do it in a query. Not sure if anybody does build applications that way, seems too limiting to me and not too beautiful. <code class="highlighter-rouge">"/post?id=123&amp;action=create"</code> only because our matching algorithm happens to perform better? Nope. Not even once.</p>

<p>Prefix tree router documentation says</p>

<blockquote>
  <p>Wildcard routes always win over explicit paths in the same subtree. E.g., /path/:wild will always match, even if /path/user is defined</p>
</blockquote>

<p>which is basically to say that overlapping routes are not supported at all. Better throw an exception rather than “silently win” because if the user did supply a route that might be also matched as wildcard her intentions are pretty clear and those are not to “just ignore this for me will you?”.</p>

<p>The third router that comes with Pedestal is linear one so we are back at ordering routes ourselves.</p>

<p>I was under impression that <a href="https://metosin.github.io/reitit/">reitit</a> was claiming to handle this exact problem. Turned out that the only thing they fixed was <a href="https://metosin.github.io/reitit/basics/route_conflicts.html">error reporting</a>: the conflicting routes are now reported to the user. Well, that’s much better that Pedestal approach but still leaves me at nothing.</p>

<p>So here’s <a href="https://github.com/tonsky/grumpy/blob/ea3f6d1f2c227e36760de28dea649aed36bbe00e/src/grumpy/routes.clj">what I do</a>: I collect all the routes and sort them myself, then pass the result to linear matcher. Still slow match performance (same to Compojure which I used before that, though) but at least encapsulation is respected.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(defn compare-parts [[p1 &amp; ps1] [p2 &amp; ps2]]
  (cond
    (and (nil? p1) (nil? p2)) 0
    (= p1 p2) (compare-parts ps1 ps2)
    (= (type p1) (type p2)) (compare p1 p2)
    (nil? p1) -1
    (nil? p2) 1
    (string? p1) -1
    (string? p2) 1
    :else (compare p1 p2)))

(defn sort [routes]
  (sort-by :path-parts compare-parts routes))

...

{::http/routes
 (routes/sort (concat routes auth/routes authors/routes))}
</code></pre></div></div>

<p>I also did a little DSL that auto-generates route names (required by Pedestal) from method and path and allows for nested collections of interceptors so that I can add multiple interceptors the same way I add one. Instead of this:</p>

<pre style="width: 800px; margin: 0 -100px;"><code>(io.pedestal.http.route/expand-routes
  #{{}
    ["/forbidden" :get :route-name :forbidden (vec (concat populate-session [route/query-params handle-forbidden]))]
    ...})
</code></pre>

<p>I can write</p>

<pre style="width: 800px; margin: 0 -100px;"><code>(grumpy.routes/expand
  [:get "/forbidden" populate-session route/query-params handle-forbidden]
  ...)
</code></pre>

<p>(in both cases <code class="highlighter-rouge">populate-session</code> is a vector of multiple interceptors that are convenient to use together).</p>

<p>I’m quite happy with the usability of this but would like the performance of trie matcher too. Maybe one day I’ll release my own opinionated router.</p>

<h1 id="conclusion">Conclusion</h1>

<p>Using Pedestal is no harder that Ring. Some included batteries are a welcome addition (router), some edges are rough (unnecessary exceptions) and documentation is scarce. Unfortunately, I didn’t get to the async requests where Pedestal model is supposed to shine, as the Grumpy website has no use of those. Overall an okay experience, but not a deal-breaker for me. I would love to see Clojure community gather around a one true interceptors model but it doesn’t seem to happen quite yet.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Grumpy chronicles: deps and uberdeps</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/uberdeps/" />
      <id>https://tonsky.me/blog/uberdeps/</id>
      <published>2019-06-03T00:00:00+00:00</published>
      <updated>2019-06-03T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Building uberjar from deps.edn
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>I have a small website called <a href="https://grumpy.website/">Grumpy Website</a> for which I implemented my own engine in Clojure. The original development was <a href="https://www.youtube.com/playlist?list=PLdSfLyn35ej8por7aH-5wYvOyDTu-bPoH">streamed on YouTube</a> (videos are in Russian).</p>

<p>Recently I figured it could be a nice playground for trying out new things in Clojure, especially related to web development. This series will cover my adventures in finding the One True Clojure Web Stack.</p>

<p>Please keep in mind that not all of these changes were absolutely necessary. Some of them are purely aesthetic, or just different for the sake of being different. Mainly I just wanted to play with new toys. The code I’ll be discussing lives at <a href="https://github.com/tonsky/grumpy"><nobr>github.com/tonsky/grumpy</nobr></a>.</p>

<h1 id="depsedn">deps.edn</h1>

<p>The first thing I wanted to do was migrating to <a href="https://clojure.org/reference/deps_and_cli">deps.edn</a>. The changes are in <a href="https://github.com/tonsky/grumpy/commit/0b50ae3073d5dfdcd7bb79965a5142a53493049a">this diff</a>.</p>

<p>That went pretty well. Dependency resolution and classpath building are working flawlessly. Time to REPL into an empty namespace reduced from 4 seconds to just 1.5 seconds (still a terribly long time though).</p>

<p>The difference with Lein was that <code class="highlighter-rouge">deps.edn</code> leaves you on your own. Where Lein can do most of the tasks you normally need (packaging, deploying to Clojars, release management, local and remote nREPL etc) deps can only do local REPL. For everything else you need to find a library, which are in a pretty raw state as far as I can see.</p>

<p>TL;DR I like the performance but miss the battle-tested batteries that come with lein.</p>

<h1 id="uberjars">Uberjars</h1>

<p>To deploy Grumpy I use uberjar — a single flat jar file that packages all dependencies’ content, including the transitive ones.</p>

<p>One of the goals for using Grumpy as a playground was to try to use other people’s solutions as much as possible and avoid rolling out my own thing.</p>

<p>So I started looking for existing solutions. Surprisingly, all of them failed in various ways.</p>

<p>A couple of tools (Juxt’s <a href="https://github.com/juxt/pack.alpha">pack</a> and Michał Buczko’s <a href="https://github.com/mbuczko/revolt">revolt</a>) offer to build a Capsule instead of uberjar. It might be a more powerful approach overall, but I wasn’t sure I wanted to bring another Java tool and deal with it just to run my program when uberjars work just fine. Revolt itself offers a whole new ecosystem of plugins and tasks which frankly was too much for me.</p>

<p>And then there’re tools that do traditional flat uberjars.</p>

<p><a href="https://github.com/luchiniatwork/cambada">Cambada</a> just died with ArtifactNotFoundException. Honestly, I haven’t really looked if I could make it work, expecting there are better tools around. People are using <code class="highlighter-rouge">deps.edn</code> somehow, right? They ought to.</p>

<p><a href="https://github.com/healthfinch/depstar">Depstar</a> died with IOException. This time I looked for a solution and found a fork of it <a href="https://github.com/seancorfield/depstar">by Sean Corfield</a>. It worked, but looking at the output I noticed a couple of odd things.</p>

<p>First, it seemed to use classpath of JVM it runs in instead of deducing classpath from the original <code class="highlighter-rouge">deps.edn</code>. This is really inconvenient since your build classpath usually includes stuff you don’t necessarily need in a resulting uberjar. The packaging script itself, for starters: how do you exclude that? Then depstar own files (they have a special case for it, but for it only).  Additionally, I have ClojureScript on <em>build</em> classpath which is pretty huge to simply ignore. I didn’t want to spin up a separate JVM to build everything and then spin another one just to package. Given how slow Clojure is to start that was not a viable solution.</p>

<p>The second problem was that apparently, Depstar unpacks everything to a temp directory before packing it back into uberjar. This seemed like a huge performance bottleneck. Zip files are perfectly streamable, both on read and on write, so there seems to be no reason to unpack everything first when you can just pass bytes from one file to another on the fly.</p>

<h1 id="meet-uberdeps">Meet Uberdeps</h1>

<p>So I figured I had to build my own uberjar packager. It’s pretty simple: resolve dependencies at runtime using tools.deps, read them one-by-one, write to the resulting file. Zip/jar reading and writing are both very straightforward in raw Java, you don’t even need Clojure to do that. Though <code class="highlighter-rouge">clojure.java.io/copy</code> always comes in handy. And tools.deps was meant to be consumed as a library as much as a command-line tool, so relying on it seemed like a good idea too.</p>

<p>The project lives at <a href="https://github.com/tonsky/uberdeps/">github.com/tonsky/uberdeps</a>. Grumpy builder uses it as a library <a href="https://github.com/tonsky/grumpy/blob/875d0bd15fbf643bc48e34b4a6be3d26e6040140/package/grumpy/package.clj">here</a>. You can also see that is has a few additional handles for fine customization:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(binding [uberdeps/exclusions
          (into uberdeps/exclusions
            [#"\.DS_Store"
             #".*\.cljs"
             #"cljsjs/.*"
             #"META-INF/maven/cljsjs/.*"])
          uberdeps/level :debug]
  (uberdeps/package
    (edn/read-string (slurp "deps.edn"))
    "target/grumpy.jar"
    {:aliases #{:uberjar}})))
</code></pre></div></div>

<p>For example, why package cljs sources if we already have them compiled down to <code class="highlighter-rouge">main.js</code>?</p>

<p>Another thing that uberdeps does by default is printing the tree of dependencies. It looks like this:</p>

<pre style="width: 1000px; margin: 0 -200px;"><code>[uberdeps] Packaging MyProject.uberdeps.jar...
+ cheshire/cheshire 5.8.1
.   com.fasterxml.jackson.core/jackson-core 2.9.6
.   com.fasterxml.jackson.dataformat/jackson-dataformat-cbor 2.9.6
! Duplicate entry "META-INF/services/com.fasterxml.jackson.core.JsonFactory" from "com.fasterxml.jackson.dataformat/jackson-dataformat-cbor 2.9.6" already seen in "com.fasterxml.jackson.core/jackson-core 2.9.6"
.   com.fasterxml.jackson.dataformat/jackson-dataformat-smile 2.9.6
! Duplicate entry "META-INF/services/com.fasterxml.jackson.core.JsonFactory" from "com.fasterxml.jackson.dataformat/jackson-dataformat-smile 2.9.6" already seen in "com.fasterxml.jackson.core/jackson-core 2.9.6"
.   tigris/tigris 0.1.1
+ clj-http/clj-http 3.9.1
.   commons-io/commons-io 2.6
.   org.apache.httpcomponents/httpasyncclient 4.1.3
.     org.apache.httpcomponents/httpcore-nio 4.4.6
.   org.apache.httpcomponents/httpclient 4.5.5
.     commons-logging/commons-logging 1.2
.   org.apache.httpcomponents/httpclient-cache 4.5.5
.   org.apache.httpcomponents/httpcore 4.4.9
.   org.apache.httpcomponents/httpmime 4.5.5
.   potemkin/potemkin 0.4.5
.     clj-tuple/clj-tuple 0.2.2
.     riddley/riddley 0.1.12
.   slingshot/slingshot 0.12.2
+ cljs-drag-n-drop/cljs-drag-n-drop 0.1.0
+ com.cognitect/transit-clj 0.8.313
.   com.cognitect/transit-java 0.8.337
.     javax.xml.bind/jaxb-api 2.3.0
.     org.msgpack/msgpack 0.6.12
.       com.googlecode.json-simple/json-simple 1.1.1
.       org.javassist/javassist 3.18.1-GA
+ com.cognitect/transit-cljs 0.8.256
.   com.cognitect/transit-js 0.8.846
+ com.stuartsierra/component 0.4.0
.   com.stuartsierra/dependency 0.2.0
+ compact-uuids/compact-uuids 0.2.0
+ io.pedestal/pedestal.immutant 0.5.5
.   org.jboss.logging/jboss-logging 3.3.2.Final
+ io.pedestal/pedestal.route 0.5.5
.   org.clojure/core.incubator 0.1.4
+ io.pedestal/pedestal.service 0.5.5
.   commons-codec/commons-codec 1.11
.   crypto-equality/crypto-equality 1.0.0
.   crypto-random/crypto-random 1.2.0
.   io.pedestal/pedestal.interceptor 0.5.5
.     org.clojure/core.match 0.3.0-alpha5
.   io.pedestal/pedestal.log 0.5.5
.     io.dropwizard.metrics/metrics-core 4.0.2
.     io.dropwizard.metrics/metrics-jmx 4.0.2
.     io.opentracing/opentracing-api 0.31.0
.     io.opentracing/opentracing-util 0.31.0
.       io.opentracing/opentracing-noop 0.31.0
.     org.slf4j/slf4j-api 1.7.25
.   org.clojure/core.async 0.4.474
.   org.clojure/tools.analyzer.jvm 0.7.2
.     org.clojure/core.memoize 0.5.9
.       org.clojure/core.cache 0.6.5
.         org.clojure/data.priority-map 0.0.7
.     org.clojure/tools.analyzer 0.6.9
.     org.ow2.asm/asm-all 4.2
.   org.clojure/tools.reader 1.2.2
+ juxt/crux 19.04-1.0.3-alpha
.   com.taoensso/nippy 2.14.0
.     com.taoensso/encore 2.93.0
.       com.taoensso/truss 1.5.0
.     net.jpountz.lz4/lz4 1.3
.     org.iq80.snappy/snappy 0.4
.     org.tukaani/xz 1.6
.   org.agrona/agrona 0.9.33
.   org.clojure/tools.logging 0.4.1
+ org.clojure/clojure 1.10.1-RC1
.   org.clojure/core.specs.alpha 0.2.44
.   org.clojure/spec.alpha 0.2.176
+ org.immutant/web 2.1.10
.   org.immutant/core 2.1.10
.     org.clojure/java.classpath 0.2.3
.   org.projectodd.wunderboss/wunderboss-clojure 0.13.1
.   org.projectodd.wunderboss/wunderboss-web-undertow 0.13.1
.     io.undertow/undertow-core 1.4.14.Final
.       org.jboss.xnio/xnio-api 3.3.6.Final
.       org.jboss.xnio/xnio-nio 3.3.6.Final
.     io.undertow/undertow-servlet 1.4.14.Final
! Duplicate entry "META-INF/services/io.undertow.server.handlers.builder.HandlerBuilder" from "io.undertow/undertow-servlet 1.4.14.Final" already seen in "io.undertow/undertow-core 1.4.14.Final"
! Duplicate entry "META-INF/services/io.undertow.attribute.ExchangeAttributeBuilder" from "io.undertow/undertow-servlet 1.4.14.Final" already seen in "io.undertow/undertow-core 1.4.14.Final"
! Duplicate entry "META-INF/services/io.undertow.predicate.PredicateBuilder" from "io.undertow/undertow-servlet 1.4.14.Final" already seen in "io.undertow/undertow-core 1.4.14.Final"
.       org.jboss.spec.javax.annotation/jboss-annotations-api_1.2_spec 1.0.0.Final
.     io.undertow/undertow-websockets-jsr 1.4.14.Final
.     org.projectodd.wunderboss/wunderboss-core 0.13.1
.       ch.qos.logback/logback-classic 1.1.3
.         ch.qos.logback/logback-core 1.1.3
.     org.projectodd.wunderboss/wunderboss-web 0.13.1
.       org.jboss.spec.javax.servlet/jboss-servlet-api_3.1_spec 1.0.0.Final
.       org.jboss.spec.javax.websocket/jboss-websocket-api_1.1_spec 1.1.0.Final
+ org.rocksdb/rocksdbjni 5.17.2
+ ring/ring-core 1.6.3
.   clj-time/clj-time 0.11.0
.     joda-time/joda-time 2.8.2
.   commons-fileupload/commons-fileupload 1.3.3
.   ring/ring-codec 1.0.1
+ rum/rum 0.11.3
.   cljsjs/react 16.2.0-3
.   cljsjs/react-dom 16.2.0-3
! Duplicate entry "deps.cljs" from "cljsjs/react-dom 16.2.0-3" already seen in "cljsjs/react 16.2.0-3"
.   sablono/sablono 0.8.1
.     org.omcljs/om 1.0.0-alpha48
! Duplicate entry "data_readers.clj" from "org.omcljs/om 1.0.0-alpha48" already seen in "juxt/crux 19.04-1.0.3-alpha"
! Duplicate entry "deps.cljs" from "org.omcljs/om 1.0.0-alpha48" already seen in "cljsjs/react 16.2.0-3"
+ resources/**
+ src/**
[uberdeps] Packaged MyProject.uberdeps.jar in 6832 ms
</code></pre>

<p>The motivation for this was that you might accidentally spot something that goes into the jar that shouldn’t. E.g. just from reading it now I noticed that <code class="highlighter-rouge">transit-clj</code> brings in message pack which is not really used anywhere at runtime.</p>

<p>As you can guess, I failed my own goal of only using existing tools for Grumpy. The upside is that somebody else might find it useful. Uberdeps has been powering Grumpy builds since April 2019 without any issues. If you are in need of such tool, consider using it.</p>

<p>P.S. Don’t worry too much about <code class="highlighter-rouge">Duplicate entry</code> warnings. Everything works fine without those for simple cases. For the rest they’ll be handled in <a href="https://github.com/tonsky/uberdeps/issues/1">github.com/tonsky/uberdeps/issues/1</a> and <a href="https://github.com/tonsky/uberdeps/issues/2">github.com/tonsky/uberdeps/issues/2</a>.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>How NOT to hire a software engineer</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/hiring/" />
      <id>https://tonsky.me/blog/hiring/</id>
      <published>2019-03-11T00:00:00+00:00</published>
      <updated>2019-03-11T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          A collection of anti-patterns seen in big IT companies regarding hiring practices
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <figure>
  <picture>
    <source type="image/webp" srcset="https://tonsky.me/blog/hiring/cover@2x.webp 2x, https://tonsky.me/blog/hiring/cover.webp" />
    <img src="https://tonsky.me/blog/hiring/cover@2x.png" srcset="https://tonsky.me/blog/hiring/cover@2x.png 2x, https://tonsky.me/blog/hiring/cover.png" />
  </picture>
  Illustrations by <a href="https://www.instagram.com/yuliaprokopova/" target="_blank">Yulia Prokopova</a>
</figure>

<p>I’m not an expert in hiring for big companies, but I have extensive experience for small ones and a bit of common sense.</p>

<p>Back in 2013, I ran a highly successful hiring campaign for <a href="https://web.archive.org/web/20140101000655/http://aboutecho.com/" target="_blank">AboutEcho.com</a> that led to the hiring of nine senior-level engineers. My Russian-speaking readers could <a href="https://tonsky.livejournal.com/288899.html" target="_blank">read about it here</a>.</p>

<p>All that gives me the confidence to criticize practices Internet Giants use to hire engineers to this day.</p>

<h2 id="dont-aim-for-the-best-solution">Don’t aim for the best solution</h2>

<p>When you arrive at the interview, the interviewer gives you a problem and expects a solution in zero to two minutes. If you spend longer they really start to worry and ask to go with at least something.</p>

<p>I can understand that—after all, they only have 45 minutes and there are lots of things they want to go through with you.</p>

<p>What I can’t understand is that you’re judged by the quality of the solution you came up within two minutes. Because that’s not how human creativity works. It’s easy to come up with many ideas, but strange to expect that best one will always be first. Even geniuses can’t predictably generate world-best answers on a clock.</p>

<p>What creativity is is the ability to evaluate and filter the stream of ideas that you come up with. If you are really interested in that, why don’t you ask the interviewee to compare and evaluate multiple ideas? Check if the person can assess the properties of the proposed solution? If she clearly sees all the pros and cons?</p>

<p>And if you are asking to come up with the best possible solution in two minutes, what you are testing for is luck, nothing more. Are you in a business of hiring lucky employees? Or capable ones?</p>

<h2 id="dont-ask-puzzles">Don’t ask puzzles</h2>

<p>How to check if a linked list has a loop? Does one N-dimensional box fit into another N-dimensional box? Can you swap two variables without a third one? How to find the shortest distance between two moving ships? Find all permutations of N elements doing only N-1 swaps?</p>

<p>Those puzzles are fun to talk about and solutions to them can be very insightful. I used to enjoy lots of them reading <a href="http://www.gutenberg.org/ebooks/26839" target="_blank">Mathematical Recreations and Essays</a> as a kid. Don’t take me wrong, they <em>are</em> fun.</p>

<p>However, no matter how fun they are, they are merely anecdotes. The property of a puzzle is that you either know the answer to it or you don’t. It doesn’t tell you anything else. It has nothing to do with future performance, being smart, capable or anything else whatsoever. Knowing a particular answer does not mean you have an apparatus to solve real problems in a generic and predictable way. The only thing it tells you is that the person has been in a situation when someone shared a solution with him. Nothing more, nothing less. Just stop already.</p>

<figure>
  <picture>
    <source type="image/webp" srcset="https://tonsky.me/blog/hiring/puzzle@2x.webp 2x, https://tonsky.me/blog/hiring/puzzle.webp" />
    <img src="https://tonsky.me/blog/hiring/puzzle@2x.png" srcset="https://tonsky.me/blog/hiring/puzzle@2x.png 2x, https://tonsky.me/blog/hiring/puzzle.png" />
  </picture>

  How do you save yourself before candle burns the rope?
</figure>

<h2 id="be-open-for-alternatives">Be open for alternatives</h2>

<p>This is kind of expected, but big companies seem to still fail at this. If the interviewee proposes an alternative solution, it’s a chance for you as an interviewer to learn something. It’s also a good chance for an in-depth discussion if the proposed solution turned out to be impossible or bad somehow.</p>

<p>Still, I’ve been dismissed for proposing an alternative solution of the same complexity once (and burdened with a lecture on a “one true way to approach that problem”) and strictly led to a particular solution another time. In the latter the interviewer was very eager to ignore all my concerns and only wanted to discuss what he saw as a solution for a problem, later leaving “not impressed” feedback about me.</p>

<p>Nobody knows everything. Be open. Listen. Think. Yes, even if you are interviewing someone.</p>

<h2 id="be-tolerant-for-imperfections">Be tolerant for imperfections</h2>

<p>Off-by-one errors are widely-accepted as one of the hardest problems in CS for a reason—everyone makes them. Errors are part of programmer’s life, not something you can get rid of. Good programmer simply knows what to do about it. Quality of a programmer is NOT defined by how few errors she makes.</p>

<p>Now, if you only select people who made no mistakes during the interview you won’t magically get a squad of programmers who always write perfect code. You just don’t know how they will behave when they will—inevitably—make their mistakes.</p>

<p>So mistakes are actually good because you get to learn how that person mitigates them. Don’t judge the errors, judge how interviewee handles them:</p>

<ul>
  <li>simple code,</li>
  <li>divide and conquer,</li>
  <li>self-checks,</li>
  <li>invariants,</li>
  <li>asserts,</li>
  <li>compiling and running,</li>
  <li>testing.</li>
</ul>

<p>Oh, sorry about the last two. I forgot you don’t let them run their programs. Well, what did you expect then?</p>

<h2 id="let-me-test">Let me test!</h2>

<p>Seriously, what’s the thing with writing program on a whiteboard?</p>

<p>I mean, I’m happy to discuss algorithms there—discussing abstract things is more efficient that way.</p>

<p>But writing programs, actual programs, in a notepad? Without even running them? What’s the point? Getting the first draft of the code is barely one-tenth of the whole process, followed by compiling, checking, tuning, testing, reviewing etc. Who are we kidding? Those are the essential parts of any coder’s workflow. A code is only good to look at when it’s past all those, not before.</p>

<p>It’s like asking a painter to do a painting of a horse, then stop her halfway during the very first sketch just when you can see four vertical lines for legs and judge that. How much will you learn about her?</p>

<figure>
  <picture>
    <source type="image/webp" srcset="https://tonsky.me/blog/hiring/horse.webp" />
    <img src="https://tonsky.me/blog/hiring/horse.png" />
  </picture>
</figure>

<h2 id="get-deep">Get deep</h2>

<p>Five short interviews? Or two long ones?</p>

<p>With five you get five independent opinions, which is better than two. But how deep can you get in 45 minutes? Practice shows it’s barely enough to write 20-30 lines of code and ask a couple of really simple questions (what’s the complexity? how you test it?).</p>

<p>The next interviewer simply repeats the same process, getting as far as the previous one. Which is not far. Not far at all.</p>

<p>Why not make it two, but make them really thorough? E.g. one before lunch and one after? Three hours is not much either, but at least you get the chance to see how person tests the code, how she changes it, how she works with requirements—all within an already established context, not resetting and starting from scratch every 45 minutes.</p>

<p>With that much time you can even ask her to write the code as if it is a part of a system, not just an abstract algorithmic task in a vacuum—and learn another thing or two about her real-world performance.</p>

<p>And if you want more opinions? Put multiple interviewers in the room and let them argue afterward.</p>

<h2 id="learn-the-background">Learn the background</h2>

<p>I mean, I have <a href="https://tonsky.me/projects/">fourteen years of experience</a>. I’d be happy to talk about functional programming, distributed systems, consensus, replication, collaborative text editing, CRDTs, parallel architectures, UI frameworks, team processes, product design, user experience. I have practical and research experience in all those areas. All of them are in direct interest for more or less any internet giants I’ve been interviewed at.</p>

<p>Was I ever asked about any of those? No.</p>

<p>What I get is “imagine you have a function that takes a list…” five times in a row. Five school-level problems are supposed to give you an adequate impression of what? How thorough was I reading Cormen et al? To be fair, you are rarely asked about those either.</p>

<p>Instead, fine-tune the interview for a candidate’s experience. Talk about what she is good at. You’ll get a chance to ask deep questions and learn a lot more about the experience level and the benefits she would bring to your company.</p>

<h2 id="make-the-process-seamless">Make the process seamless</h2>

<p>Wrong directions? Delayed tickets? A questionnaire that requires installing the original Adobe Reader specifically? Cheap ultrabook with unfamiliar keyboard layout and poor web-based editor with no shortcuts whatsoever that lags even on a local machine? Excuse me, I am in the office of the most capable IT-company in the world, am I not?</p>

<p>In my case, the single recruiter was arranging five interviews a day. Five people every day. Times number of recruiters in that company. Imagine all of those candidates slightly frustrated by the process. Every day. Year after year.</p>

<p>You might think it doesn’t matter. Well, it depends. There was an episode of TV show Louie, where a comic’s name was misspelled on his door. So he argued: yes, it’s an easy mistake to make, but it’s also an easy mistake to fix. It doesn’t matter it’s just for one day, if you bothered at all, please do it right.</p>

<p>Yes, I believe anyone can do better.</p>

<figure>
  <picture>
    <source type="image/webp" srcset="https://tonsky.me/blog/hiring/recruiters@2x.webp 2x, https://tonsky.me/blog/hiring/recruiters.webp" />
    <img src="https://tonsky.me/blog/hiring/recruiters.png" srcset="https://tonsky.me/blog/hiring/recruiters@2x.png 2x, https://tonsky.me/blog/hiring/recruiters.png" width="395px" />
  </picture>
  <br />
  How many recruiters does an IT campus fit?
</figure>

<h2 id="in-closing">In closing</h2>

<p>If you are in a business of hiring software engineers, big companies’ practices are not your friends. Common sense, fairness, tolerance, real interest, and open-mindedness are.</p>

<p>Good hiring!</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Redesigning Github repository page</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/github-redesign/" />
      <id>https://tonsky.me/blog/github-redesign/</id>
      <published>2019-02-28T00:00:00+00:00</published>
      <updated>2019-02-28T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Better design for Github repository page
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <style>
@media (min-width: 768px) {
  .w768 { width: 768px; margin-left: -112px; margin-right: -112px; }
  .w500 { width: 500px; margin-left: 22px; margin-right: 22px; }
  .w400 { width: 400px; margin-left: 72px; margin-right: 72px; }
}
</style>

<figure class="w768">
  <img src="https://tonsky.me/blog/github-redesign/00_cover.png" />
  Illustration by <a href="https://www.behance.net/yuliaprokopova" target="_blank">Yulia Prokopova</a>
</figure>

<p>Github design is pretty good: it gets the job done, it’s clean, has consistent visual language, its design is calm and suitable for everyday use.</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/10_as-is.png" /></figure>

<p>Given all that, there are still many areas that could be improved. Today we’ll take one interface—repository page—and look what UI problems it has and if we can fix them.</p>

<h2 id="first-problem-nested-tabs">First problem: nested tabs</h2>

<p>Let’s start with the biggest issue right away: information architecture. Take tabs. Currently there’re two levels of tabs, one nested under the other:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/20_tabs.png" /></figure>

<p>If you are a programmer, you might be surprised but other people normally don’t like hierarchies. Nested structures are hard to grasp, remember, navigate, and grouping is very often non-intuitive. Nested tabs are one of the worst UI patterns out there.</p>

<p>Then there’s a plain usability issue: let’s say I’m in Wiki and need to see Releases. What should I do? There’s no Releases tab visible, so I must figure out somehow that Releases are part of the Code (?). That makes almost no sense. Releases are as much part of the Code as Issues or Wiki are.</p>

<p>Solution here is to flatten all tabs into a single navigational control:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/30_tabs-merged.png" /></figure>

<p>Organized that way, tabs are immediately accessible <em>from anywhere</em> in the repo. <em>This is a big deal</em>.</p>

<p>As a bonus, we also won quite a bit of vertical space without sacrificing anything! Vertical space is very important, it lets you see more content and get to it faster—all good things.</p>

<p>We still have one problem though: tabs don’t fit. We’re going to solve it by removing icons, but let me build up a case for that first.</p>

<h2 id="problem-2-redundant-icons">Problem 2: Redundant icons</h2>

<p>Icons are visual cues that help you scan the UI quickly. “Quickly” here means faster than reading text labels. If for some reason reading labels is still faster then icons aren’t working.</p>

<p>One example of icons misuse: if you put too many icons in a row and they are <em>all</em> different, they won’t work.</p>

<figure><img src="https://tonsky.me/blog/github-redesign/35_icons.png" /></figure>

<p>Prioritizing, or highlighting, something means deprioritizing everything else. You can’t highlight everything.</p>

<p>Another way to fail at icons: if you use obscure graphics, people will have to read labels anyways, so, again, not working.</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/37_obscure_icons.jpeg" /></figure>

<p>Now let’s be honest: the domain of repository and project management is pretty abstract. No matter how good you are at design and how hard you try, you won’t come up with a great icon for a commit. Or a release. Or an issue. Or a license. A great icon is something <em>other</em> people know and understand. And for repositories, there’s simply none. I mean,</p>

<figure><img src="https://tonsky.me/blog/github-redesign/40_is-this-a-commit.png" /></figure>

<p>So Github tab icons are purely decorative. If you don’t believe me, look at what Github itself is doing. They dim icons:</p>

<figure><img src="https://tonsky.me/blog/github-redesign/45_commits.png" /></figure>

<p>That’s a sure sign that they, too, think it’s near impossible to figure out why backward clock means “Commit”. Github knows people will be looking at the labels anyways.</p>

<p>But even being decorative, they’re bad at it. I mean, Icon + Label + Counter make for a symmetric and weak composition:</p>

<figure><img src="https://tonsky.me/blog/github-redesign/50_composition.png" /></figure>

<p>By removing icons we:</p>

<ol>
  <li>free up a lot of horizontal space,</li>
  <li>make design stronger, and</li>
  <li>get rid of visual noize.</li>
</ol>

<p>Win-win-win! Here’s the result, tabs without icons:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/60_icons-removed.png" /></figure>

<p>Test yourself, see if you can find Releases tab without an icon and if it was harder than before? It wasn’t, was it?</p>

<p>A note on this design: I am using the same limitations Github already uses: English language only, locked page width of 1020px. For different conditions, say, for the adaptive design we might want a different solution.</p>

<p>Another note: I had to remove Contributors tab (which was actually not a tab, but a sub-tab from Insights that was duplicated in Code for some reason) to accommodate for Settings tab. Don’t worry, we’ll get Contributors back later.</p>

<h2 id="problem-3-vanity-counters">Problem 3: Vanity counters</h2>

<p>This is the “vanity menu”:</p>

<figure class="w400"><img src="https://tonsky.me/blog/github-redesign/70_vanity.png" /></figure>

<p>The thing with vanity metrics is that there should be just one. One metrics is simple to understand and focus. Two or three split attention, making everything weaker.</p>

<p>Luckily for us, both watchers and forks perform poorly as metrics anyways. For watches, people tend not to watch too much. For forks, people tend to fork for no reason.</p>

<p>But stars work. They work because they have no other function but to represent vanity. So let’s keep stars and move them to the left to get more attention:</p>

<figure class="w400"><img src="https://tonsky.me/blog/github-redesign/73_vanity.png" /></figure>

<h2 id="problem-4-watch-button-ambiguity">Problem 4: “Watch” button ambiguity</h2>

<p>In the watch button we have a classic “button or status” UX dilemma. Buttons tell us what can be done but don’t say what the current status is. Status tells current state but it’s not clear what it would change to.</p>

<p>In Github case “Watch” has a button label but it doesn’t act as a button: clicking on it won’t make you watch the repo. It’s not a status either: if you see “Watch” it means you are <em>not</em> watching. Same for the other two states: they are neither buttons nor states.</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/75_vanity.png" /></figure>

<p>The problem here is that a single button can’t be used to switch between three states. But dropdown can! Dropdowns are a well-established UI component that shows status <em>and</em> can be used to change it at the same time.</p>

<p>Funny, but Github is already using a dropdown! We just need to fix it to work as any other dropdown on Earth works: to show current status. Trivial fix, really:</p>

<figure class="w500"><img src="https://tonsky.me/blog/github-redesign/77_vanity.png" /></figure>

<p>Minor, but annoying: that checkmark is really hard to spot. Let’s highlight the whole row:</p>

<figure class="w500"><img src="https://tonsky.me/blog/github-redesign/78_vanity.png" /></figure>

<p>All together so far:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/80_vanity-reorganized.png" /></figure>

<p>Uff, we’ve done a lot! If you need a little break, now would be a perfect time for it. Don’t worry, I’ll wait.</p>

<p>Back? Great! Let’s move on.</p>

<h2 id="problem-5-repo-description">Problem 5: Repo description</h2>

<p>This is the repository description:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/90_details.png" /></figure>

<p>The problem with it is: why is it located under the Code tab? It’s a description of the whole repository, not just its code, right?</p>

<p>To fix this let’s move it above the tabs, to the area that belongs to the whole repository:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/100_details-moved.png" /></figure>

<p>It still needs a couple of touches.</p>

<p>First, font is neither big nor small (it’s 16px, standing between 18px repository name and 14px tabs). Let’s make it 14px so that there’re only two distinct font sizes. Also I’m sure there’s no need to render “https://” in the URL:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/112_details.png" /></figure>

<p>The second change is to move topics right next to the repository name. There’re usually just a few of those, so it seems wasteful to dedicate a whole line to them:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/114_details.png" /></figure>

<p>Look at us, winning more vertical space again!</p>

<h2 id="problem-6-removing-background-color">Problem 6: Removing background color</h2>

<p>Blue topics on blue background became harder to read. This is because they used to be on #FFF and now they’re on Github’s #FAFBFC “very light dirty blue”.</p>

<p>Let’s change tab’s background to #FFF too:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/115_details.png" /></figure>

<p>But why was that background there in the first place? What did it do?</p>

<p>My guess is Github had to add it because the structure of their menu layers was becoming too complex and they needed visual cues to help you “split” it in order to understand. The black top bar serves the same purpose: to separate. I mean, they were literally spending a good half of 768px screen at navigation alone.</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/116_details.png" /></figure>

<p>When split into layers, at least you are not immediately scared by it. Without a background, it would be a mess.</p>

<p>But because we simplified the whole header so much and removed one intermediate layer, we don’t need that color coding anymore. Instead, we can enjoy fresh crisp white:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/119_details.png" /></figure>

<p>And look at all that free space! Finally, we can see some content in the top half of the screen too.</p>

<h2 id="problem-7-description-editing">Problem 7: Description editing</h2>

<p>A small touch. If you own the repository, you get to edit both its description and its topics:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/120_details.png" /></figure>

<p>First, the “Edit” button is badly misplaced — too far, easy to miss.</p>

<p>Second, separate edit button for topics is an artifact of topics system being developed at a different time, maybe by a different team. There’s really no need to have two separate buttons.</p>

<p>The solution? How many edit buttons do we need? I say none.</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/122_details.png" /></figure>

<p>“But… Where did edit buttons go?” You might ask.</p>

<p>You see, the nature of description and topics is that it’s important to get people to fill them when they first create their repo. After that, people rarely change them at all.</p>

<p>When there is no description or no topics, we will show a button to add one:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/124_details.png" /></figure>

<p>And if description/topics are already filled, go to Settings to change them. Problem solved!</p>

<h2 id="problem-8-files-description">Problem 8: Files description</h2>

<p>The traditional Windows File Explorer, together with macOS Finder, have established a simple pattern for file browsing: files on the left, details on the right.</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/132_file_explorer.png" /></figure>

<p>Github decided to copy that pattern, but they put a very unexpected thing as details: a message from the last commit when that particular file was changed.</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/130_code_browser.png" /></figure>

<p>Why? I don’t know. Commits often touch files for completely arbitrary reasons, so the last commit tells you almost nothing. I can’t think of any case when somebody would need that particular information.</p>

<p>Maybe they wanted Github to be “about git” more than about traditional file browsing, and this was the only thing they could think of? That’s my speculation, anyway.</p>

<p>The problem with those details is not that such a huge area is filled with something so rarely useful. The problem is that it looks <em>so much</em> like file description it confuses me every time. “Tweak layout” is not a description of the “Docs” folder. “Need these debug tools too” for “Tools”—why should I care?</p>

<p>That means we can get rid of the descriptions without really losing anything:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/135_no_description.png" /></figure>

<h2 id="problem-9-repository-overview">Problem 9: Repository overview</h2>

<p>When you get to the repository, the first page you see should not necessarily be Code. We better call it Overview—something to get a quick idea of what’s going on.</p>

<p>Now, the Github repository is more than just a list of files. It’s also about how those files change over time. What new features were added? Which bugs were fixed? Were there any new releases recently? All those are as important as the files themselves.</p>

<p>That’s why I suggest we add a list of recent commits to the Overview page next to files.</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/140_code_commits.png" /></figure>

<p>You can now see if a project is actively developed, maintained or abandoned, if an issue you care about was recently fixed, if a new version was recently published etc (notice tags and branches pills in commit list—I miss this feature on Commits tab SO MUCH).</p>

<p>What about that free space on the right? We can put useful stats there:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/150_lang_stats.png" /></figure>

<p>First, I added contributors. Github is all about people and collaboration, that’s why they put so much emphasis on Fork and PR buttons. Well, people are the face of that collaboration. They put their free time and energy to make that code happen. It’s only fair to see some of their faces.</p>

<p>Activity is a relatively new feature that hasn’t found its place on repository page yet—until now. Helps you see how much momentum the project has.</p>

<p>Language statistics was unfairly hidden away, now it’s front and foremost. I also added code size in lines of code — an obvious addition that Github still doesn’t have for some reason.</p>

<p>Altogether, in my opinion, the new Overview tab is more helpful in everyday use.</p>

<h2 id="problem-10-contextualizing-buttons">Problem 10: Contextualizing buttons</h2>

<p>Both “Create new file”, “Upload files” and “Find files” all relate to files, so it will be reasonable to move them right next to the thing they operate on: Files.</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/160_files_buttons.png" /></figure>

<h2 id="problem-11-hidden-clone-link">Problem 11: Hidden clone link</h2>

<p>Github always used to have clone URL directly on a page. That was pretty useful—when you needed to grab the code, no additional clicks were required.</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/165_clone.png" /></figure>

<p>Unfortunately, during one of the redesigns Github hid the clone URL behind a button. My guess is they did it because there was simply not enough space. But people kept looking for it so they had to paint the button green.</p>

<p>Well, after moving file buttons we have enough space to restore full-length Clone link:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/170_clone.png" /></figure>

<p>I also unified all four ways to get the repo into a single control, because semantically they are pretty much the same: a way to get the code on your machine.</p>

<h2 id="last-problem-dated-look">Last problem: dated look</h2>

<p>This is how Github <a href="https://blog.github.com/2013-06-17-repository-next/">used to look back in 2013</a>:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/180_github_2013.jpg" /></figure>

<p>And this is <a href="https://blog.github.com/2015-11-16-a-new-look-for-repositories/">a screenshot from 2015</a>:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/190_github_2015.png" /></figure>

<p>Finally, this is how it looks today:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/10_as-is.png" /></figure>

<p>As you can see, the color scheme and main UI elements haven’t changed much since at least 2013. It’s not necessarily bad and mostly proves that the original design was good enough to stand the test of time.</p>

<p>But maybe it’s time to fresh it up a little? Get rid of gradients, dirty washed-out colors, unnecessary separators, add a little more air. Something like this:</p>

<figure class="w768"><img src="https://tonsky.me/blog/github-redesign/200_new_look.png" /></figure>

<p>If you feel disoriented, give it a minute. Once you are used to it, you might notice it’s actually easier on the eyes and a bit lighter.</p>

<h2 id="finally">Finally</h2>

<p>Current Github design next to my proposal (click to open in a new window):</p>

<figure class="w768"><a href="https://tonsky.me/blog/github-redesign/210_compare.png" target="_blank"><img src="https://tonsky.me/blog/github-redesign/210_compare.png" /></a></figure>

<p>We’ve added ~4 more files to the screen of the same vertical size, 6 last commits, 3 branches, 10 contributors’ faces, project activity AND expanded language stats WITHOUT losing any information.</p>

<p>If you know someone at Github, send them a link to this article. Maybe someone there will like my ideas and eventually get to implement them—who knows?</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>It is fast or it is wrong</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/slow-wrong/" />
      <id>https://tonsky.me/blog/slow-wrong/</id>
      <published>2018-12-29T00:00:00+00:00</published>
      <updated>2018-12-29T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Fast programs are always fast, slow programs are slow even on a most powerful computers. Knowing that fast solution exists makes slow one plain wrong.
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>I’ve been doing some <a href="https://adventofcode.com/2018">Advent of Code</a> programming recently (you can <a href="https://www.youtube.com/playlist?list=PLdSfLyn35ej-UL9AuxUvoFXerHac4RYnH">watch the recordings</a>). They publish a small programming problem every day during December and you are supposed to write a program that solves it for you. It usually takes anything from a couple of minutes to a couple of hours and is pretty fun, I recommend that you try it too. Once the task is up, it’s always accessible, not only during December.</p>

<figure><img src="advent.png" /></figure>

<p>One thing it taught me is that there are two types of solutions you end up with: ones that can calculate the answer in a couple of milliseconds and the ones that would take years to finish. If you end up with the second type, you’re doing it wrong. There’s no point in waiting, although <em>technically</em> it might do the right thing too.</p>

<p>Another interesting observation is that it makes no difference what hardware you use to run it. If the solution is fast, it’ll be fast on a notebook as well as on a beefed-up workstation-class desktop. Sure, it might be twice or thrice slower, but it’ll be a difference between 10ms and 30ms. You still get your answer, so it doesn’t really matter.</p>

<p>If it’s slow, on the other hand, then you can throw at it any amount of computing power and it still won’t be enough. It might reduce the time from three years on a notebook to one year on a most powerful computer I can possibly build. So what? It’s still too long.</p>

<p>Now let’s get to software. It’s easy to call solutions of Advent Of Code wrong when they are slow since we know the fast solution has to exist. With real-world problems, nobody guarantees that.</p>

<p>Except sometimes.</p>

<p>Actually, quite often.</p>

<p>I’d say, almost always, in fact.</p>

<p>Let’s see. I have a library called <a href="https://github.com/tonsky/datascript">Datascript</a>. It’s a persistent data structure slash embedded database that, so it happens, is implemented for two platforms: JVM and JS. More so, it is actually written in Clojure and most parts of its codebase are shared between both platforms. It means that we know both versions always do the same motions. There’s a small layer that covers up platform-specific details like datatypes and standard library, but rest is shared. It’s not like one version is original and the other one is an inefficient port. They are both playing the same game.</p>

<p>You might think that if they do the same, they must perform the same, right? That would be logical to think so.</p>

<p>Let’s look at actual times it takes to compile the codebase and run full integration tests suite. We are talking about a codebase that is just a little over 9000 LOC, of which tests are 4000 LOC:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Clojure 1.10 on JVM:
  REPL boot time: 1.5 sec
  Compile time:   6.5 sec
  Tests time:     0.45 sec
  
ClojureScript 1.10.439 with advanced compilation:
  Compile time:   78 sec
  Tests time:     1 sec
  
ClojureScript 1.10.439 without Google Closure compilation:
  Compile time:   24 sec
  Tests time:     1.3 sec
</code></pre></div></div>

<p>So what do these numbers tell us? Basically, to process exactly the same code, you can either spend ~8 seconds, 24 seconds or 78 seconds. Your choice. Also, by running the same program, you can get your result either in half a second, full second or close to one and a half second.</p>

<p>“<em>But wait, Tonsky, you can’t compare those! Those are apples and oranges! They are built to do completely different things! One is running in the browser!</em>”</p>

<p>Of course you can. Let me remind you: we compile exactly the same code, built to do exactly the same thing, using the same algorithms and running on the same hardware. The end result is the same in both cases: you either get your Datalog query answered in short time or in a long time. You either spend half of your workday waiting for a compiler or you spend it playing in the REPL, building stuff.</p>

<p>What do ClojureScript/Google Closure compilers do for so long? They are wasting your time, that’s what. Of course it’s nobody’s fault, but in the end, this whole solution is simply <em>wrong</em>. We can do the same thing much faster, we have proof of that, we have the means to do it, it just happens that we are not. But we could. If we wanted to. That huge overhead you’re paying, you’re paying it for nothing. You don’t get anything from being on JS, except a 2× performance hit and astronomical build times.</p>

<p>The same applies to all languages with terribly long build times. It’s not that they couldn’t build faster. They just choose not to. C++ or Rust program compiles for too long? Well, OCaml could probably compile the equivalent program in under a second. And it’ll still be machine-level fast.</p>

<p>“<em>Wow, wow, slow down! This is even more unfair! Now it’s not just apples and oranges, now it’s toothbrushes and spaceships. You completely ignore what each language brings to the table. There’s a reason they spend so much time compiling, you know?</em>”</p>

<p>I know. But still, I think you kind of can compare them. They are all general-purpose languages, after all, and in the end what matters is if you have a working program on your hand and if it can produce the answer in a reasonable time. It doesn’t really matter how the developer arrived there. You might get some comfort in thinking that it does, but nobody really cares.</p>

<p>Imagine this: there’s a plane from Moscow to Novosibirsk, the heart of Siberia, that takes 4 hours to fly 2800 kilometers. And there’s also a train that takes three days to cover the same distance. The train has no shower, bad food, beds you can’t sleep in. And the plane is a comfortable modern airplane. Which one would you choose? The price is the same. The only difference is your comfort and your time.</p>

<figure><img src="train.jpg" /></figure>

<p>If we take this as a metaphor for software development, you’d be surprised that programmers are happily choosing train. They would even argue you to death there are indisputable reasons to choose the train. No, they don’t mind the compiler taking its time to “do the work”. Even though faster ways to get to the same destination exist. It’s easy to get lost arguing the details, but remember: <em>we all end up in the same place</em>, no matter what language we use.</p>

<p>Browsers? Same story. HTML is a pretty inefficient way to put pixels on a screen. A computer that might render millions of polygons a frame could easily struggle to scroll a web page. Same as with Advent of code solutions, it doesn’t really depend on how powerful your computer is. And even a highly optimized web code based on Canvas and WebAssembly (<a href="https://figma.com">Figma</a>) makes my Macbook fans spin while running native Sketch in complete silence.</p>

<figure><img src="crysis.jpg" /></figure>

<p>There’re just limits on how far this wrong solution can go. Electron text editors can’t resize their own window in real-time and drop frames while you just move your cursor around. Slack would be as slow and memory-hungry on iMac Pro as it would be on a 12” Macbook.</p>

<p>The whole solution, the “web stack”, <em>is wrong</em>. The same thing could be done faster and more efficient <em>easily</em>—there is just so much wasted potential. Time to admit that and start over. There are fast text editors and chat programs around, very well within capabilities of even the least powerful netbooks.</p>

<p>I can go on and on. The thing to remember is: think what are you getting out of it. Are the problem and the resources wasted on it even comparable? It’s easy to find excuses why things are the way they are. They are all probably valid, but they are <em>excuses</em>. We know way faster programs <em>are possible</em>, and that makes everything else just plain wrong.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Better Clojure formatting</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/clojurefmt/" />
      <id>https://tonsky.me/blog/clojurefmt/</id>
      <published>2018-12-05T00:00:00+00:00</published>
      <updated>2018-12-05T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          A Clojure formatting style good enough to be a default standard
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <style>
blockquote > pre { margin: 15px 0; padding: 0; background: none; }
</style>

<p>There has been <a href="https://clojureverse.org/t/clj-commons-building-a-formatter-like-gofmt-for-clojure/3240">a discussion</a> recently whether Clojure should have its own version of gofmt, a default go code formatter. I think it’s a good opportunity to collect and formulate my thoughts on the subject.</p>

<p>If you have no idea why default formatter is such a good idea, <a href="https://talks.golang.org/2015/gofmt-en.slide#1">this fantastic slidedeck</a> might shed a light.</p>

<h2 id="clojure-style-guide-wont-do">Clojure Style Guide won’t do</h2>

<p>As I understand, current <a href="https://github.com/bbatsov/clojure-style-guide">community standard</a> takes its roots in prior LISP conventions and Emacs formatter. Although many people use it, following it to the letter might not be the goal, mainly because it seems to be in conflict with other constraints (we’ll get to them in a bit).</p>

<p>“But! Most of Clojure code is <em>already</em> written with it!”</p>

<p>Yes. And another reason why not following the current community standard might be ok is that when hypothetical <code class="highlighter-rouge">clojurefmt</code> arrives, nobody’s code will probably match it to the letter. So everybody will have to reformat, and if everybody is reformatting it’s doesn’t really matter how much. You either join <code class="highlighter-rouge">clojurefmt</code> and hand all your code to the machine or you don’t.</p>

<h2 id="one-formatter-to-rule-them-all">One formatter to rule them all</h2>

<p>Ok. Now to constraints and why none of the existing conventions nor tools solve the problem.</p>

<p>Design constraints for <code class="highlighter-rouge">clojurefmt</code> are kind of unique. Once a tool like this is set up, there’s no changing it. It’s set in stone. That’s by definition: we want one and only clojure formatter that everyone agrees on. Two versions are the same as having two formatters. That means chaos. Can’t have that.</p>

<p>So formatter can’t be extensible, can’t have patches and releases. Which means it has to be designed with future changes in mind. That includes clojure.core and language changes that didn’t happen yet!</p>

<p>This is why config/hard-coded rules/exception-based solutions don’t work here. When Clojure 1.6 added <code class="highlighter-rouge">when-some</code> and <code class="highlighter-rouge">if-some</code>, no formatters supported it and as a result, <code class="highlighter-rouge">when-let</code> and <code class="highlighter-rouge">when-some</code> was formatting differently. This is because <code class="highlighter-rouge">when-let</code> was is config but <code class="highlighter-rouge">when-some</code> wasn’t. This also means library macros never would be formatted correctly.</p>

<p>The important thing to understand here is that such changes DID happen in the past and WILL happen in the future. So we can’t rely on “let’s enumerate all the exceptions and live forever with them”.</p>

<h2 id="invade-everything">Invade everything!</h2>

<p><code class="highlighter-rouge">Clojurefmt</code> has to be everywhere. Any editor. Any language. Stand-alone tool. Browser. Libraries. If we want everyone to use it, we should give it to everyone. Nothing sucks more than “it works in Emacs but everybody else needs to figure out a way to run it”. Or “it’s written in Clojure so it takes 10 seconds to start up, practically unusable”.</p>

<p>This constraint requires a certain simplicity of the standard. Fewer rules, low language specificity, simpler conditions. So it could be reimplemented everywhere.</p>

<p>For example, I’d be happy if I could express the rules of <code class="highlighter-rouge">clojurefmt</code> in VS Code Auto Indent syntax, so that editor would support them natively and place my cursor where it’s supposed to be. This is much better UX than formatting afterward. Ideally, onsave/beforecommit formatting should be for correcting mistakes. Unless you fight it, an editor should produce correctly formatted code while you write it.</p>

<p>Simplicity also means there’s less chance for different implementations to diverge.</p>

<h2 id="whats-wrong-with-the-status-quo">What’s wrong with the status quo?</h2>

<p>Clojure Style Guide has multiple rules that don’t play nice with those constraints.</p>

<blockquote>
Use 2 spaces to indent the bodies of forms that have body parameters.
<pre>
(when something
  (something-else))
</pre>
</blockquote>

<p>How would we know if the form has body params or not? Whitelisting doesn’t work. Parsing codebase to find macro source doesn’t either.</p>

<blockquote>
Vertically align function (macro) arguments spanning multiple lines.
<pre>
(filter even?
        (range 1 10))
</pre>
</blockquote>

<p>This rule would be easy to automate if it didn’t have a huge list of exceptions. <code class="highlighter-rouge">let, cond, if, defn</code> and many other forms simply don’t follow this rule.</p>

<blockquote>
Use a single space indentation for function (macro) arguments when there are no arguments on the same line as the function name.
<pre>
(filter
 even?
 (range 1 10))
</pre>
</blockquote>

<p>Again, exceptions! E.g. <code class="highlighter-rouge">try</code> doesn’t follow it. Also, having a mix of one- and two-space indents was driving me mad when I was trying to follow those rules manually.</p>

<blockquote>
  <p>Where feasible, avoid making lines longer than 80 characters.</p>
</blockquote>

<p>This is just a silly cargo-cult rule that people like to bring up for no reason. Punched cards used to have 80 columns and we follow this limit ever since. 80-column text on a 1920-px display is as stupid as 135-column text on a narrow mobile phone screen.</p>

<p>Bikeshedding, but here’s an ultimate argument: any editor can fit long text for a screen of any size. No editor can fit 80-column text on display that has three times as much space though.</p>

<blockquote>
  <p>Avoid trailing whitespace.</p>
</blockquote>

<p>This is one of the stupidest things to automate. Unlike indenting, removing trailing whitespace simply produces diffs <em>where it doesn’t matter</em>. And does nothing more.</p>

<h2 id="ok-what-do-we-do-then">Ok, what do we do then?</h2>

<p>I propose two simple unconditioned formatting rules:</p>

<ul>
  <li>Multi-line lists that start with a symbol are always indented with two spaces,</li>
  <li>Other multi-line lists, vectors, maps and sets are aligned with the first element (1 or 2 spaces).</li>
</ul>

<p><em>Note: rules was updated to address an issue with Parinfer and multi-arity fns indentation, as many people has pointed out.</em></p>

<p>Basically, these examples will “simply work”, with no form-specific rules or any exceptions:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(when something
  body)

(defn f [x]
  body)
  
(defn f
  [x]
  body)
  
(defn many-args [a b c
                 d e f]
  body)
  
(defn multi-arity
  ([x]
   body)
  ([x y]
   body))

(let [x 1
      y 2]
  body)
  
[1 2 3
 4 5 6]

{:key-1 v1
 :key-2 v2}
 
#{a b c
  d e f}
</code></pre></div></div>

<p>They will also work with any user-defined macros, any libraries and any possible extensions to clojure.core.</p>

<p>These will produce results different from what you’re used to (not a bad thing!):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>; second cond is not aligned
(or (condition-a)
  (condition-b))
  
; or/and are the only forms where this looks not ideal
; other forms don’t win/lose much because of this change
(filter even?
  (range 1 10))
  
; my way is actually better if fn name is looooooooooong
(clojure.core/filter even?
  (range 1 10))

; 1 additional space, no big deal
(filter
  even?
  (range 1 10))
</code></pre></div></div>

<p>It might be not what you’re used to, but it still looks decent, doesn’t it?</p>

<p>In fact, differences are so marginal you might not even notice them unless you’ve spent a couple of days working on code formatting already.</p>

<p>What’s important is that those rules are much simpler to establish, implement and follow. They even fit in your head!</p>

<h2 id="road-to-adoption">Road to adoption</h2>

<p>As Robert Griesemer put it in <a href="https://talks.golang.org/2015/gofmt-en.slide#33">his slides</a>, “gofmt’s style is nobody’s favorite, yet gofmt is everybody’s favorite”.</p>

<p>The point of such formatter is not to produce a style that everybody would love. This is probably impossible. The point is to enforce a style that will free people from arguing and making style decisions <em>at all</em>. To accomplish it, it doesn’t need to be smart, or pretty, or sophisticated. It has to be ubiquitous. It has to be everywhere.</p>

<p>Let Clojure community know if you think this formatting is better fit for one-and-only-clojure-default-formatter-that-everyone-has-to-use-no-knobs-no-settings-no-questions-asked. Vote <a href="https://github.com/clj-commons/formatter/issues/9#issuecomment-445528667">on Github</a>, comment on <a href="https://news.ycombinator.com/item?id=18620309">Hacker News</a> or <a href="https://twitter.com/nikitonsky/status/1070654163288276993">on Twitter</a>.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>You need neither PWA nor AMP to make your website load fast</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/pwa/" />
      <id>https://tonsky.me/blog/pwa/</id>
      <published>2018-11-21T00:00:00+00:00</published>
      <updated>2018-11-21T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Good performance practices are still needed when developing fast web experience.
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>There has been a trend of new “revolutionary” techniques on the Web that basically let you do stuff possible decades ago.</p>

<h1 id="amp">AMP</h1>

<p>First, AMP (Accelerated Mobile Pages). Think about it: web, in general, failed to be fast, so Google invents a parallel web where they simply don’t let you use JavaScript. Oh, and they let you use a couple of Google-approved AMP JS components. But wait, can’t regular web run without JavaScript? Of course it can. Can regular web include custom JS components? You bet. Can it be fast? Netflix <a href="https://medium.com/dev-channel/a-netflix-web-performance-case-study-c0bcde26a9d9">recently found out</a> that if they remove 500 Kb of JavaScript from a static (!!!) webpage it will load WAY faster and users will generally be happier. Who would have thought, right?</p>

<p>So why was AMP needed? Well, basically Google needed to lock content providers to be served through Google Search. But they needed a good cover story for that. And they chose to promote it as a performance solution.</p>

<p>Thing is, web developers don’t believe in performance. They <em>say</em> they do, but in reality, they don’t. What they believe in is hype. So if you hype old tricks under a new name, then developers can say “Now, finally, I can start writing fast apps. Thank you Google!”. Like if Google ever stopped you from doing so beforehand.</p>

<blockquote>
  <p>“But AMP is new! <code class="highlighter-rouge">&lt;amp-img&gt;</code> does so much more than <code class="highlighter-rouge">&lt;img&gt;</code>!”</p>
</blockquote>

<p>It might, but what stops Google, if it really has an intention to help, from releasing it as a regular JS library?</p>

<p>So hype worked, lots of developers bought the cover story and rushed creating a parallel version of every webpage they serve with “AMP-enabled” performance boost.</p>

<p>Before:</p>

<blockquote>
  <p>“Hey boss, let’s rewrite our website to make it load fast!”<br />“Fuck off!”<br />“But studies show that every second of load time…”<br />“I said fuck off!”</p>
</blockquote>

<p>Now:</p>

<blockquote>
  <p>“Hey boss, let’s rewrite our website with AMP. It’s a new tech by Google…”<br />“Drop everything! Here, take $$$”<br />“It also might improve…”<br />“I don’t care. Get on this NOW!”</p>
</blockquote>

<p>I’m not saying practices promoted by AMP are bad or useless. They are good practices. But nothing stops you from following them in the regular web. Nothing has ever stopped you from writing performant pages, from the very inception of the web. Google hardly invented CDNs and async script loading. But nobody cared because old tech and good practices are never as tempting as something branded as “new”.</p>

<h1 id="pwa">PWA</h1>

<p>Enter PWA. Progressive Web Applications. Or Apps. Progressive Web Apps. Whatever.</p>

<p>So the idea was to be able to create a native-like experience but with web stack. What was the Web missing? Installing apps. Offline mode. Notifications (Ew). Working in the background. Yeah, that’s basically it. That’s it.</p>

<p>Again, I’m not going to say these things are wrong<a id="f1" href="#fn1" class="footnote">†</a>. They are not. If you want to create a native-like app using web technologies, you’ll have to use something like that. And it makes sense for apps like a shopping list or, I don’t know, alarm clock?</p>

<p>The problem with PWA is, well, there are two problems.</p>

<p>First is that most apps would be better off as websites rather than apps. Websites load each resource gradually, as it’s needed, unlike apps which have to fetch everything at install (that’s why app bundle sizes are usually way bigger than websites). Sites are more efficient but you can’t use them while offline.</p>

<p>But most “apps” today are online-only anyways! You can’t call Uber while being offline, and why would you open Uber app otherwise? Tinder is useless offline. You can’t date empty chat screens. You can’t join a meetup at Meetup.com without network connection. You can’t choose or book a hotel, you can’t transfer money or check your account balance offline. And nobody wants to re-read old cached tweets from Twitter or yesterday photos from Instagram. It just doesn’t make any sense.</p>

<p>So yeah, I would prefer those “apps” to be just websites. Believe it or not, there are benefits to that. I enjoy smaller download size, especially if I visit a site occasionally just for a quick look. I enjoy that websites do not consume my resources in the background<a id="f2" href="#fn2" class="footnote">‡</a>. When I close it it unloads and does not constantly download new versions of its own libraries, which <a href="https://medium.com/@paularmstrong/d28a00e780a3#8255">developers frequently need to deploy</a>. I’m more than ready to sacrifice offline mode for that.</p>

<p>The second problem with PWA, and more relevant to our topic, is that it somehow <a href="https://www.thinkwithgoogle.com/intl/en-154/insights-inspiration/case-studies/trivago-embrace-progressive-web-apps-as-the-future-of-mobile/">got associated with performance</a>.</p>

<p>The thing is, it has nothing to do with performance. I mean, nothing <em>new</em>. You were always able to cache resources to make navigation between pages quick, and browsers are pretty good at doing so. With HTTP/2 you can efficiently fetch resources in bulk and even push resources from the server for a “more instant” experience.</p>

<p>So managing resource cache yourself, in a ServiceWorker, seems more like a burden than a blessing. HTTP caching is also declarative, well-tested and well understood at this point, in other words, hard to screw up. Which you can’t say about your ServiceWorker. Caching is one of two <a href="https://www.martinfowler.com/bliki/TwoHardThings.html">hardest things in Computer Science</a>. I personally <a href="https://twitter.com/nikitonsky/status/1064899552069722112">had a bad experience</a> with Meetup.com PWA when an error in their cache code made the whole site unusable to the point where it wouldn’t open meetup pages. And unlike HTTP, it’s not that easy to reset. Nope, refresh didn’t help.</p>

<p>But it would’ve been ok if ServiceWorker was a tradeoff: you pay complexity fee but get exciting new capabilities. Except you don’t. Nothing useful that you can do with ServiceWorker you can’t do with HTTP cache/AJAX/REST/Local Storage. It’s just a complexity hole you’ll sink countless workhours in.</p>

<p>PWA, as well as AMP, doesn’t even guarantee your website would be anywhere near “fast” or “instant”. It’s kind of funny how <a href="https://medium.com/@addyosmani/78919d98ece0">Tinder case study</a> shows that login screen (one text input, one button, one SVG logo and a background gradient) takes 5 seconds to load on a 4G connection! I mean, they had to add loader for 2-5 seconds so users don’t close this bullshit immediately. And they call it fast.</p>

<p>This is fast:</p>

<figure><video autoplay="" muted="" loop="" preload="auto" playsinline="" controls="" style="width: 300px; "><source src="https://tonsky.me/blog/pwa/rss/wikipedia.mp4" type="video/mp4" /></video></figure>

<p>How did they do it? By fucking caring about performance. As simple as that.</p>

<p>Oh, also not serving a gazillion of JavaScript bundles and not rendering on a client with React served over GraphQL via fetch polyfill. That probably helped too.</p>

<figure><a href="https://tonsky.me/blog/pwa/airbnb.png" target="_blank"><img src="https://tonsky.me/blog/pwa/rss/airbnb.jpg" /></a></figure>

<p>ServiceWorker or AMP, if your landing page is 170+ requests for 3.1 Mb for an image and four form fields, it can’t load fast no matter how many new frameworks you throw at it.</p>

<h1 id="verdict">Verdict</h1>

<p>So what’s the verdict? To write fast websites with AMP and PWA you still need to understand performance optimization deeply. Without that, the only choice you have is to go with the hype.</p>

<p>But remember that neither AMP nor PWA would magically make your website any faster than say just a regular rewrite would.</p>

<figure>
  <a href="https://tonsky.me/blog/pwa/index.png" target="_blank"><img src="https://tonsky.me/blog/pwa/rss/index.jpg" /></a>
  Airbnb famous 800Kb index page. I would expect more care perf-wise from 900+ developers with average salary of $290,000/year. Even SublimeText gives up highlighting this bullshit at some point. 
</figure>

<p>Once you understand performance, though, you’ll notice you need neither AMP nor PWA. Just stop doing bullshit and web suddenly starts to work <em>instantly</em>. AMP didn’t invent CDN and <code class="highlighter-rouge">&lt;noscript&gt;</code>. PWA didn’t invent caching. Static web still runs circles around any modern-day much-hyped framework.</p>

<figure><img src="https://tonsky.me/blog/pwa/rss/oldweb.png" /></figure>

<p>“But the users! They want our fancy-schmancy interactivity. They DEMAND animations!”</p>

<p>I’ll tell you one thing. No one enjoys staring at the loading screen for 5 seconds. Loader being animated doesn’t make any difference. If you can’t into performance, at least don’t pretend it’s a feature.</p>

<div class="footnotes-br"></div>

<ol class="footnotes_alt">
<li id="fn1"><span class="dagger">†</span> Although I don’t think we need more notifications in our life either. Especially <a href="https://grumpy.website/post/0PKEDf3JE">not from random web pages we visit</a>. Even not from native apps—I keep my phone in permanent Do Not Disturb mode with a short list of whitelisted apps. <a href="#f1" class="">↩︎</a></li>
<li id="fn2"><span class="dagger">‡</span> By the way, since you first opened this article my ServiceWorker has downloaded <code id="downloaded">0 Kb</code> of useless data in background. I hope you are on WiFi :) <a href="#f2" class="">↩︎</a></li>
</ol>

<script>
  if (!localStorage.getItem("first_opened"))
    localStorage.setItem("first_opened", "" + new Date().getTime());
  var first_opened = parseInt(localStorage.getItem("first_opened"));

  function update_downloaded() {
    var downloaded_kb = Math.ceil((new Date().getTime() - first_opened) / 200);
        text = downloaded_kb >= 1000000 ? Math.ceil(downloaded_kb / 1000) / 1000 + " Gb"
               : downloaded_kb >= 1000 ? downloaded_kb / 1000 + " Mb"
               : downloaded_kb + " Kb";
    document.getElementById("downloaded").innerHTML = text;
  }
  update_downloaded();
  setInterval(update_downloaded, 1000);

  if ('serviceWorker' in navigator) {
    navigator.serviceWorker.register('/sw.js', {scope: '/'}).then(function(registration) {
      console.log('Service worker registration succeeded:', registration);
    });
  }

</script>


      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Solve the problem at hand</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/concrete-vs-abstract/" />
      <id>https://tonsky.me/blog/concrete-vs-abstract/</id>
      <published>2018-11-14T00:00:00+00:00</published>
      <updated>2018-11-14T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Always prefer concrete code to abstract one. Don’t try to solve problems you don’t have.
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>Imagine being at the interview where the interviewer asks you to convert a binary string into a number.</p>

<p>“Please write such <code class="highlighter-rouge">f()</code> so that e.g. <code class="highlighter-rouge">f("101") === 5</code>.”</p>

<p>I would start writing something like this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>function char_to_int(char) {
  switch (char) {
    case "0": return 0;
    case "1": return 1;
  }
}
</code></pre></div></div>

<p>“Wait-wait-wait,” he would stop me. “What if string is not binary?”</p>

<p>“Oh, so you want me to convert decimal string? Is it not binary?”</p>

<p>“No, it still is. But, you know, in the future…”</p>

<p>So he wants me to write generic code that still solves the specific problem. It might be ok for an interview, but in real engineering work, I would always prefer concrete code to generalized one.</p>

<p>For one, it’s faster to write. If you only solve a problem for specific cases you usually have a very limited amount of code paths to think of. It’s simpler to write.</p>

<p>It’s easier to get right too. Because you already know the problem. And you know it because you have it at hand, and you can dig as deep as you need, learn all the details you need and <em>make the right call</em>. Whether with a generalized version you’ll be <em>speculating</em> about what problems you <em>might</em> have in the future. You might have them. You might not. You might have a different problem, or you might misjudge the details.</p>

<p>Concrete is also easier to read. The code is filled with clues, concrete details that tell you the specifics of the problem that is being solved here. You see helpful constants (like <code class="highlighter-rouge">0</code> and <code class="highlighter-rouge">1</code> in the example above). You see branch conditions that make sense. You see a complete list of possible states instead of abstract opaque “collections” that could contain everything. A generalized code is usually one step above that, so you’ll have to <em>imagine</em> concrete values before you could go through the code in your “mental debugger” (that’s how I read the code anyway).</p>

<p>But what if your prediction <em>was</em> right and you actually <em>will</em> need generalized version soon? Well, you could write it then. It’s the requirements that make writing good code hard, not the act of coding itself. And I doubt you’re good at predicting requirements. Nobody is. So you’ll just spend more time and create more obstacles for yourself in the future.</p>

<p>That’s what the Clojure ecosystem has taught me. Everything is as concrete as possible. Clojure just has no facilities to overgeneralize. It’s either a concrete thing or nothing. Get to the meat as fast as possible. Cut to the chase. If you need to print, just print, don’t invent printing facilities. If you have a record, put in fields you know about and don’t worry about the rest. Add them when you need them.</p>

<p>The advice is simple: don’t solve a problem you don’t have. Be rather afraid to create obstacles for the future you. You can’t see the future, but you can make the present as simple as it could be.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Medium is a poor choice for blogging</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/medium/" />
      <id>https://tonsky.me/blog/medium/</id>
      <published>2018-11-13T00:00:00+00:00</published>
      <updated>2018-11-13T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          If you think about publishing an article, starting a blog or even just sharing a short rant on Medium, please consider what you’ll be putting your readers through.
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>To get the point better, read it <a href="https://medium.com/@nikitonsky/medium-is-a-poor-choice-for-blogging-bb0048d19133">on Medium</a>.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Apple Design Team vs the World</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/ipad/" />
      <id>https://tonsky.me/blog/ipad/</id>
      <published>2018-11-05T00:00:00+00:00</published>
      <updated>2018-11-05T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          How iPad Pro redesign made it better and worse at the same time
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>Last week Apple announced new iPad. Don’t take me wrong: it’s an amazing piece of technology. It’s thinner, lighter, more powerful, bigger better screen and more. It’s a miracle they keep doing it every single time.</p>

<p>Two things caught my eye though. First is the camera. It now has a significant bump. I understand that it has to be of a certain depth, it’s physics and not much even Apple can do about it.</p>

<figure><img src="bump.jpg" height="195" /></figure>

<p>But what I wish they considered is how iPad is used. You see, camera bump on an iPhone is nothing but a minor inconvenience. After all, phones are meant to be mostly held in your hand and used “in the air”, not on the table (for a majority of times, anyway).</p>

<p>iPad, though, is a different story. Although it could be used on your lap, the main position is on the table. Especially if you are drawing on it. And it IS meant for active, long drawing sessions. This is how Apple seems to position it anyways: they are advertising it with Pencil and mobile Photoshop and whatever. Funny, but non-professional iPad now has no bump and is better suited for professional use.</p>

<p>Why do you need a camera on a tablet anyway? On a professional drawing tablet? Honestly, I don’t know. It’s too bulky to be used as a camera, and you usually have your phone around anyways. Sharing photos is trivial with AirDrop. And if you consider iPad as the main device for taking photos, there are better and more compact options.</p>

<figure><img src="photo.jpg" height="400" /></figure>

<p>I’d love to have a camera-less iPad Pro, at least as an option, same as we can get SIM-free iPad. Either for a small discount (not important) or flatter back (very, very important).</p>

<p>The second problem is with the Pencil. Yes, it looks and feels great. Yes, they fixed this disaster with charging from Pencil 1:</p>

<figure><img src="charging.jpg" height="450" /></figure>

<p>They also fixed the problem of easy-to-lose pencil cap and adapter. Yes, Pencil 1 came with an adapter to charge from the lightning port and there’s nowhere to put it so you have most probably already lost it. Unless you are very, very inventive:</p>

<figure><img src="cap.jpg" height="451" /></figure>

<p>But design is a delicate deal. Sometimes fixing one thing might break another one. The new Pencil charges by attaching magnetically to the iPad side:</p>

<figure><img src="magnet.jpg" height="144" /></figure>

<p>It also features touch-sensitive buttons on its flat side. This is important too.</p>

<p>Now, remember how I said that iPad Pro is aimed at professionals doing long, active drawing sessions? Well, guess what? Unless you’re in a business meeting doodling and making a couple of notes an hour, Apple Pencil is not really comfortable to hold. I mean, hold for a long time. Drawing extensively. So most artists figured a way around it:</p>

<figure>
  <img src="rubber.jpg" height="338" />
  <a href="https://twitter.com/freetonik/status/1057567093401497601">source</a>
</figure>

<figure>
  <img src="rubber2.jpg" height="450" />
  <a href="https://twitter.com/SameCloud/status/1057587861728477184">source</a>
</figure>

<figure><img src="rubber3.jpg" height="450" /></figure>

<figure><img src="rubber4.jpg" height="600" /></figure>

<p>Yep, these rubber grips make it 500% easier and more comfortable to use.</p>

<p>Even people predicting Pencil 2 before its official announcement wished there was a rubber grip:</p>

<figure>
  <img src="rubber5.jpg" height="470" />
  <a href="https://www.idropnews.com/news/exclusive-ipad-pro-2-and-apple-pencil-2-visualizations-predict-what-apples-upcoming-products-could-look-like/30434/">source</a>
</figure>

<p>And this is what we got from Apple:</p>

<figure><img src="nogrip.jpg" height="145" /></figure>

<p>Now if you add that grip yourself you won’t be able to attach it to the iPad nor access touch buttons. Back to the drawing board, I guess.</p>

<p>It’s a shame because iPad Pro is really a great device for doing art, drawing, doodling, scheming, planning, note-taking, and mind-mapping. No doubt people will find their ways around this iteration too. I just wanted to point out that life sometimes is more complex than what designers imagine it is.</p>

<figure>
  <video autoplay="" muted="" loop="" preload="auto" playsinline="" controls=""><source src="customers.mp4" type="video/mp4" /></video>
  Design vs User Experience
</figure>

<p>And not all pretty things are necessarily great in everyday use.</p>

<figure>
  <img src="realpencil.jpg" />
  <a href="https://www.youtube.com/watch?v=hZvidv1LYCM">source</a>
</figure>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Address the root cause</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/root-cause/" />
      <id>https://tonsky.me/blog/root-cause/</id>
      <published>2018-10-24T00:00:00+00:00</published>
      <updated>2018-10-24T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Do not just fix symptoms. Find out the root cause and address it instead
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>Today I was listening for <a href="https://www.youtube.com/watch?v=6ftW8UwwP_4">Apropos Clojure #20</a> and looks like it was me who <a href="https://twitter.com/nikitonsky/statuses/1014596144347926529">triggered Stu</a> to start looking into the problem. What surprised me was what he said next.</p>

<p>Many people complain that Clojure stacktraces are ugly and look like you broke your computer. They are not incorrect:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#error {
 :cause "Divide by zero"
 :via
 [{:type java.lang.ArithmeticException
   :message "Divide by zero"
   :at [clojure.lang.Numbers divide "Numbers.java" 188]}]
 :trace
 [[clojure.lang.Numbers divide "Numbers.java" 188]
  [clojure.lang.Numbers divide "Numbers.java" 3901]
  [user$eval1 invokeStatic nil 1]
  [user$eval1 invoke nil 1]
  [clojure.lang.Compiler eval "Compiler.java" 7172]
  [clojure.lang.Compiler eval "Compiler.java" 7135]
  [clojure.core$eval invokeStatic "core.clj" 3206]
  [clojure.core$eval invoke "core.clj" 3202]
  [clojure.main$repl$read_eval_print__8898$fn__8901 invoke "main.clj" 309]
  [clojure.main$repl$read_eval_print__8898 invoke "main.clj" 307]
  [clojure.main$repl$fn__8907 invoke "main.clj" 332]
  [clojure.main$repl invokeStatic "main.clj" 332]
  [clojure.main$repl_opt invokeStatic "main.clj" 396]
  [clojure.main$main invokeStatic "main.clj" 495]
  [clojure.main$main doInvoke "main.clj" 458]
  [clojure.lang.RestFn invoke "RestFn.java" 397]
  [clojure.lang.AFn applyToHelper "AFn.java" 152]
  [clojure.lang.RestFn applyTo "RestFn.java" 132]
  [clojure.lang.Var applyTo "Var.java" 705]
  [clojure.main main "main.java" 37]]}
</code></pre></div></div>

<p>Compare to Python stacktrace:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; 1 / 0
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
ZeroDivisionError: integer division or modulo by zero
</code></pre></div></div>

<p>So Clojure exceptions are ugly and something should be done about that. BUT! The solution IS NOT to just hide them. Exceptions are useful, and hiding them does not address the root problem: they are hard to use and contain lots of unnecessary info.</p>

<p>Look at Clojure stacktrace again. Everything starting from stack element 5 is unrelated to my program <em>at all</em>. <code class="highlighter-rouge">user$eval1</code> is what I’m interested in but it is cryptic and appears twice and has no clues about the place in the REPL where that error came from.</p>

<p>Compacted version (Clojure behaviour by default from 1.9) is no better:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user=&gt; (/ 1 0)
Evaluation error (ArithmeticException) at clojure.lang.Numbers.divide (Numbers.java:188).
Divide by zero
</code></pre></div></div>

<p>The message is correct but file/line number lead back into Clojure internals. When I see that <em>I have to</em> expand stacktrace anyways and fight the complexity of it on my own. So everything this solution does is merely postponing the moment I frighten myself with the horror of the stack.</p>

<p>Another solution that was mentioned is <a href="https://github.com/yogthos/clojure-error-message-catalog">Clojure Error Message Catalog</a>. This should not be treated as a helpful resource (although it is, thx @yogthos for collecting those!) but as a bug list to fix in Clojure core. If something blows up in a confusing way, the solution is not to educate everyone about that specific “language peculiarity”. The solution is to go back to Clojure core and put an appropriate check in an appropriate place so that next time it blows up the message is clear and precise.</p>

<p>The same faulty approach was mentioned in <a href="https://www.therepl.net/episodes/7/">The REPL #7</a> with Ben Brinckerhoff regarding Clojure.spec validation. Ben said that Spec simply does not provide enough data to transform Spec errors into nice-looking useful messages. Again, Clojure.core position on this has always been: we’ve made the Spec and other people should figure out how to live with it.</p>

<p>But here the one of the core components is missing, so it <em>is not</em> a viable solution. Instead of asking other people to invent ingenious ways to overcome this limitation, the solution should be addressed in Spec itself. Everything else would be a compromise and will only lead to a complicated, fragile ecosystem in the long run.</p>

<p>Yes, sometimes Clojure core can’t be changed enough to address the core issues because of the backward compatibility. Sometimes it might be harder than waiting for people to invent their workarounds, and Clojure.core resources are limited. But at least let’s talk about that openly? Let’s clearly call compromise a compromise when we make one?</p>

<p>And when something can be fixed—why not do it? Why not address the root reason instead of fixing the symptoms? Maybe it’s time we stop treating core as some sacred texts and start cleaning it up? At least could we start acknowledging some problems should be addressed there instead of at ecosystem level?</p>

<p>My greates sympathies to Clojure.core team and everything they’ve done so far. I’m using software you made every day and couldn’t be happier about it. I’m only writing this so we can see problems clearly and talk about them more openly.</p>

<p>UPD: A separate “dev” mode was also suggested in a podcast and <a href="https://twitter.com/puredanger/status/1055109097362731010">on Twitter</a>. This comes from a premise that novice developers and “pros” need different things. WRONG. We do not need different things. We both want the same thing: good error messages reporting the correct cause and a relevant stacktrace frames. We both DO NOT want cryptic messages reported at the wrong place.</p>

<p>Do you imagine it like novice gets “You need to pass a set to core.set/union” and line number where he passed the wrong thing but “pro” gets a “Count not supported on this type: Long” and three times longer stacktrace pointing at the wrong place? No. Any pro will prefer “novice” option any time of the day. Professional are as annoyed with this as any novice would be.</p>

<p>Just do the right thing and <em>everyone</em> will be happy.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Software disenchantment</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/disenchantment/" />
      <id>https://tonsky.me/blog/disenchantment/</id>
      <published>2018-09-17T00:00:00+00:00</published>
      <updated>2018-09-17T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Everything is going to hell and nobody seems to care
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <figure><img src="cover.jpg" height="337" /></figure>

<p><em>Translations: <a href="https://blog.romainfallet.fr/desenchantement-logiciel/" target="_blank">French</a> <a href="it/">Italian</a> <a href="https://muchtrans.com/translations/software-disenchantment.ko.html" target="_blank">Korean</a> <a href="pt/">Portuguese</a> <a href="https://habr.com/post/423889/" target="_blank" rel="nofollow">Russian</a> <a href="es/">Spanish</a></em></p>

<p>I’ve been programming for 15 years now. Recently, our industry’s lack of care for efficiency, simplicity, and excellence started really getting to me, to the point of me getting depressed by my own career and IT in general.</p>

<p>Modern cars work, let’s say for the sake of argument, at 98% of what’s physically possible with the current engine design. Modern buildings use just enough material to fulfill their function and stay safe under the given conditions. All planes converged to the optimal size/form/load and basically look the same.</p>

<p>Only in software, it’s fine if a program runs at 1% or even 0.01% of the possible performance. Everybody just seems to be ok with it. People are often even proud about how inefficient it is, as in “why should we worry, computers are fast enough”:</p>

<blockquote>
  <p><a href="https://twitter.com/tveastman/status/1039002300600147968">@tveastman</a>: I have a Python program I run every day, it takes 1.5 seconds. I spent six hours re-writing it in rust, now it takes 0.06 seconds. That efficiency improvement means I’ll make my time back in 41 years, 24 days :-)</p>
</blockquote>

<p>You’ve probably heard this mantra: “Programmer time is more expensive than computer time.” What it means basically is that we’re wasting computers at an unprecedented scale. Would you buy a car if it eats 100 liters per 100 kilometers? How about 1000 liters? With computers, we do that all the time.</p>

<figure><a href="https://xkcd.com/2021/" target="_blank"><img src="software_development_2x.gif" height="440" /></a></figure>

<h2 id="everything-is-unbearably-slow">Everything is unbearably slow</h2>

<p>Look around: our portable computers are thousands of times more powerful than the ones that brought man to the moon. Yet every other webpage struggles to maintain a smooth 60fps scroll on the latest top-of-the-line MacBook Pro. I can comfortably play games, watch 4K videos, but not scroll web pages? How is that ok?</p>

<p>Google Inbox, a web app written by Google, running in Chrome browser also by Google, <a href="https://twitter.com/nikitonsky/statuses/968882438024941568">takes 13 seconds to open moderately-sized emails</a>:</p>

<figure><video autoplay="" muted="" loop="" preload="auto" playsinline="" controls=""><source src="inbox.mp4" type="video/mp4" /></video></figure>

<p>It also animates empty white boxes instead of showing their content because it’s the only way anything can be animated on a webpage with decent performance. No, decent doesn’t mean 60fps, it’s rather “as fast as this web page could possibly go”. I’m dying to see the web community answer when 120Hz displays become mainstream. Shit barely hits 60Hz already.</p>

<p>Windows 10 <a href="https://grumpy.website/post/0PeXr1S7N">takes 30 minutes to update</a>. What could it possibly be doing for that long? That much time is enough to fully format my SSD drive, download a fresh build and install it like 5 times in a row.</p>

<figure><img src="windows_update.gif" height="435" /></figure>

<blockquote>
  <p><a href="https://pavelfatin.com/typing-with-pleasure/">Pavel Fatin</a>: Typing in editor is a relatively simple process, so even 286 PCs were able to provide a rather fluid typing experience.</p>
</blockquote>

<p>Modern text editors have higher latency than 42-year-old Emacs. Text editors! What can be simpler? On each keystroke, all you have to do is update a tiny rectangular region and modern text editors can’t do that in 16ms. It’s a lot of time. A LOT. A 3D game can fill the whole screen with hundreds of thousands (!!!) of polygons in the same 16ms and also process input, recalculate the world and dynamically load/unload resources. How come?</p>

<p>As a general trend, we’re not getting faster software with more features. We’re getting faster hardware that runs slower software with the same features. Everything works way below the possible speed. Ever wonder why your phone needs 30 to 60 seconds to boot? Why can’t it boot, say, in one second? There are no physical limitations to that. I would love to see that. I would love to see limits reached and explored, utilizing every last bit of performance we can get for something meaningful in a meaningful way.</p>

<h2 id="everything-is-huuuuge">Everything is HUUUUGE</h2>

<p>And then there’s bloat. Web apps could open up to 10 times faster if you just simply blocked all ads. Google begs everyone to stop shooting themselves in the foot with the AMP initiative—a technology solution to a problem that doesn’t need any technology, just a little bit of common sense. If you remove bloat, the web becomes crazy fast. How smart do you have to be to understand that?</p>

<p>An Android system with no apps <a href="https://grumpy.website/post/0Oz1lDOq5">takes up almost 6 GB</a>. Just think for a second about how obscenely HUGE that number is. What’s in there, HD movies? I guess it’s basically code: kernel, drivers. Some string and resources too, sure, but those can’t be big. So, how many drivers do you need for a phone?</p>

<figure><img src="android_storage.jpg" height="489" /></figure>

<p>Windows 95 was 30MB. Today we have web pages heavier than that! Windows 10 is 4GB, which is 133 times as big. But is it 133 times as superior? I mean, functionally they are basically the same. Yes, we have Cortana, but I doubt it takes 3970 MB. But whatever Windows 10 is, is Android really 150% of that?</p>

<p>Google’s keyboard app routinely eats 150 MB. Is an app that draws 30 keys on a screen really five times more complex than the whole Windows 95? Google app, which is basically just a package for Google Web Search, is 350 MB! Google Play Services, which I do not use (I don’t buy books, music or videos there)—300 MB that just sit there and which I’m unable to delete.</p>

<figure><img src="apps_storage.gif" height="480" /></figure>

<p>All that leaves me around 1 GB for my photos after I install all the essential (social, chats, maps, taxi, banks etc) apps. And that’s with no games and no music at all! Remember times when an OS, apps and all your data fit on a floppy?</p>

<p>Your desktop todo app is probably written in Electron and thus <a href="https://josephg.com/blog/electron-is-flash-for-the-desktop/">has a userland driver for the Xbox 360 controller in it</a>, can render 3D graphics and play audio and take photos with your web camera.</p>

<figure><img src="slack_memory.jpg" height="388" /></figure>

<p>A simple text chat is notorious for its load speed and memory consumption. Yes, you really have to count Slack in as a resource-heavy application. I mean, chatroom and barebones text editor, those are supposed to be two of the less demanding apps in the whole world. Welcome to 2018.</p>

<p>At least it works, you might say. Well, bigger doesn’t imply better. Bigger means someone has lost control. Bigger means we don’t know what’s going on. Bigger means complexity tax, performance tax, reliability tax. This is not the norm and should not become the norm. Overweight apps should mean a red flag. They should mean run away scared.</p>

<h2 id="everything-rots">Everything rots</h2>

<p>A 16GB Android phone was perfectly fine 3 years ago. Today, with Android 8.1, it’s barely usable because each app has become at least twice as big <em>for no apparent reason</em>. There are no additional features. They are not faster or more optimized. They don’t look different. They just…grow?</p>

<p>The iPhone 4s was released with iOS 5, but can barely run iOS 9. And it’s not because iOS 9 is that much superior—it’s basically the same. But their new hardware is faster, so they made software slower. Don’t worry—you got exciting new capabilities like…running the same apps with the same speed! I dunno.</p>

<p>iOS 11 dropped support for 32-bit apps. That means if the developer isn’t around at the time of the iOS 11 release or isn’t willing to go back and update a once-perfectly-fine app, chances are you won’t be seeing their app ever again.</p>

<blockquote>
  <p>@<a href="https://twitter.com/jckarter/statuses/1017071794245623808">jckarter</a>: A DOS program can be made to run unmodified on pretty much any computer made since the 80s. A JavaScript app might break with tomorrow’s Chrome update</p>
</blockquote>

<p>Web pages working today <a href="http://tonsky.me/blog/chrome-intervention/">would not be compatible with any browser in 10 years time</a> (probably sooner).</p>

<p>“It takes all the running you can do, to keep in the same place”. But what’s the point? I might enjoy occasionally buying a new phone and new MacBook as much as the next guy, but to do so just to be able to run all the same apps which just became slower?</p>

<p>I think we can and should do better than that. Everyone is busy building stuff for right now, today, rarely for tomorrow. But it would be nice to also have stuff that lasts a little longer than that.</p>

<h2 id="worse-is-better">Worse is better</h2>

<p>Nobody understands anything at this point. Neither do they want to. We just throw barely baked shit out there, hope for the best and call it “startup wisdom”.</p>

<p>Web pages ask you to refresh if anything goes wrong. Who has time to figure out what happened?</p>

<figure><img src="reload.jpg" height="185" /></figure>

<p>Any web app produces a constant stream of “random” JS errors in the wild, even on compatible browsers.</p>

<p>The whole webpage/SQL database architecture is built on a premise (hope, even) that nobody will touch your data while you look at the rendered webpage.</p>

<p>Most collaborative implementations are “best effort” and have many common-life scenarios in which they lose data. Ever seen this dialogue “which version to keep?” I mean, the bar is so low today that your users would be happy to at least have a window like that.</p>

<figure><img src="icloud_conflict.jpg" height="468" /></figure>

<p>And no, in my world, an app that says “I’m gonna destroy some of your work, but you get to choose which one” is not okay.</p>

<p>Linux kills random processes <em>by design</em>. And yet it’s the most popular server-side OS.</p>

<p>Every device I own fails regularly one way or another. My Dell monitor needs a hard reboot from time to time because there’s software in it. Airdrop? You’re lucky if it’ll detect your device, otherwise, what do I do? Bluetooth? The spec is so complex that devices <a href="https://thewirecutter.com/blog/understanding-bluetooth-pairing-problems/">won’t talk to each other</a> and <a href="http://time.com/4358533/bluetooth-fix-how/">periodic resets are the best way to go</a>.</p>

<figure><img src="plz_connect.jpg" height="450" /></figure>

<p>And I’m not even touching the <a href="https://twitter.com/internetofshit">Internet of Things</a>. It’s so far beyond the laughing point I’m not even sure what to add.</p>

<p>I want to take pride in my work. I want to deliver working, stable things. To do that, we need to understand what we are building, in and out, and that’s impossible to do in bloated, over-engineered systems.</p>

<h2 id="programming-is-the-same-mess">Programming is the same mess</h2>

<p>It just seems that nobody is interested in building quality, fast, efficient, lasting, foundational stuff anymore. Even when efficient solutions have been known for ages, we still struggle with the same problems: package management, build systems, compilers, language design, IDEs.</p>

<p>Build systems are inherently unreliable and periodically require full clean, even though all info for invalidation is there. Nothing stops us from making build processes reliable, predictable and 100% reproducible. Just nobody thinks its important. NPM has stayed in “sometimes works” state for years.</p>

<blockquote>
  <p><a href="https://twitter.com/przemyslawdabek/status/940547268729606145">@przemyslawdabek</a>: It seems to me that <code class="highlighter-rouge">rm -rf node_modules</code> is indispensable part of workflow when developing Node.js/JavaScript projects.</p>
</blockquote>

<p>And build times? Nobody thinks compiler that works minutes or even hours is a problem. What happened to “programmer’s time is more important”? Almost all compilers, pre- and post-processors add significant, sometimes disastrous time tax to your build without providing proportionally substantial benefits.</p>

<figure><a href="https://xkcd.com/303/" target="_blank"><img src="compiling.gif" height="360" /></a></figure>

<p>You would expect programmers to make mostly rational decisions, yet sometimes they do the exact opposite of that. E.g. choosing Hadoop <a href="https://www.chrisstucchio.com/blog/2013/hadoop_hatred.html">even when it’s slower than running the same task on a single desktop</a>.</p>

<p>Machine learning and “AI” moved software to guessing in the times when most computers are not even reliable enough in the first place.</p>

<blockquote>
  <p><a href="https://twitter.com/freetonik/status/1039826129190875136">@rakhim</a>: When an app or a service is described as “AI-powered” or “ML-based”, I read it as “unreliable, unpredictable, and impossible to reason about behavior”. I try to avoid “AI” because I want computers to be the opposite: reliable, predictable, reasonable.</p>
</blockquote>

<p>We put virtual machines inside Linux, and then we put Docker inside virtual machines, simply because nobody was able to clean up the mess that most programs, languages and their environment produce. We cover shit with blankets just not to deal with it. “Single binary” is still a HUGE selling point for Go, for example. No mess == success.</p>

<figure><a href="https://xkcd.com/1987/" target="_blank"><img src="python_environment_2x.gif" height="594" /></a></figure>

<p>And dependencies? People easily add overengineered “full package solutions” to solve the simplest problems without considering their costs. And those dependencies bring other dependencies. You end up with a tree that is something in between of horror story (OMG so big and full of conflicts) and comedy (there’s no reason we include these, <a href="https://medium.com/@jdan/i-peeked-into-my-node-modules-directory-and-you-wont-believe-what-happened-next-b89f63d21558">yet here they are</a>):</p>

<figure><img src="dependencies.gif" height="440" /></figure>

<p>Programs can’t work for years without reboots anymore. Sometimes <a href="https://docs.gitlab.com/ee/administration/operations/unicorn.html#unicorn-worker-killer">even days are too much to ask</a>. Random stuff happens and nobody knows why.</p>

<p>What’s worse, nobody has time to stop and figure out what happened. Why bother if you can always buy your way out of it. Spin another AWS instance. Restart process. Drop and restore the whole database. Write a watchdog that will restart your broken app every 20 minutes. Include same resources <a href="https://blog.timac.org/2017/0410-analysis-of-the-facebook-app-for-ios-v-87-0/">multiple times, zip and ship</a>. Move fast, don’t fix.</p>

<p>That is not engineering. That’s just lazy programming. Engineering is understanding performance, structure, limits of what you build, deeply. Combining poorly written stuff with more poorly written stuff goes strictly against that. To progress, we need to understand what and why are we doing.</p>

<h2 id="were-stuck-with-it">We’re stuck with it</h2>

<p>So everything is just a pile of barely working code added on top of previously written barely working code. It keeps growing in size and complexity, diminishing any chance for a change.</p>

<p>To have a healthy ecosystem you <em>need</em> to go back and revisit. You <em>need</em> to occasionally throw stuff away and replace it with better stuff.</p>

<figure><img src="design_process.jpg" height="657" /></figure>

<p>But who has time for that? We haven’t seen new OS kernels in what, 25 years? It’s just too complex to simply rewrite by now. Browsers are so full of edge cases and historical precedents by now that nobody dares to write layout engine from scratch.</p>

<p>Today’s definition of progress is either throw more fuel into the fire:</p>

<blockquote>
  <p><a href="https://twitter.com/sahrizv/status/1018184792611827712">@sahrizv</a>: 2014 - We must adopt #microservices to solve all problems with monoliths.<br />2016 - We must adopt #docker to solve all problems with microservices.<br />2018 - We must adopt #kubernetes to solve all problems with docker</p>
</blockquote>

<p>or reinventing the wheel:</p>

<blockquote>
  <p><a href="https://twitter.com/dr_c0d3/status/1040092903052378112">@dr_c0d3</a>: 2000: Write 100s of lines of XML to “declaratively” configure your servlets and EJBs.<br />2018: Write 100s of lines of YAML to “declaratively” configure your microservices.<br />At least XML had schemas…</p>
</blockquote>

<p>We’re stuck with what we have, and nobody will ever save us.</p>

<h2 id="business-wont-care">Business won’t care</h2>

<p>Neither will users. They are only learned to expect what we can provide. We (engineers) say every Android app takes 350 MB? Ok, they’ll live with that. We say we can’t give them smooth scrolling? Ok, they’ll live with a phone that stutter. We say “if it doesn’t work, reboot”? They’ll reboot. After all, they have no choice.</p>

<p>There’s no competition either. Everybody is building the same slow, bloated, unreliable products. Occasional jump forward in quality does bring competitive advantage (iPhone/iOS vs other smartphones, Chrome vs other browsers) and forces everybody to regroup, but not for long.</p>

<p>So it’s our mission as engineers to show the world what’s possible with today’s computers in terms of performance, reliability, quality, usability. If we care, people will learn. And there’s nobody but us to show them that it’s very much possible. If only we care.</p>

<h2 id="its-not-all-bad">It’s not all bad</h2>

<p>There are some bright spots indicating that improving over state-of-the-art is not impossible.</p>

<p>Work <a href="https://twitter.com/mjpt777">Martin Thompson</a> has being doing (<a href="https://github.com/LMAX-Exchange/disruptor">LMAX Disruptor</a>, <a href="https://github.com/real-logic/simple-binary-encoding">SBE</a>, <a href="https://github.com/real-logic/aeron">Aeron</a>) is impressive, refreshingly simple and efficient.</p>

<p><a href="https://github.com/google/xi-editor">Xi editor</a> by Raph Levien seems to be built with the right principles in mind.</p>

<p><a href="https://www.youtube.com/user/jblow888">Jonathan Blow</a> has a language he alone develops for his game that can compile 500k lines per second on his laptop. That’s cold compile, no intermediate caching, no incremental builds.</p>

<p>You don’t have to be a genius to write fast programs. There’s no magic trick. The only thing required is not building on top of a huge pile of crap that modern toolchain is.</p>

<h2 id="better-world-manifesto">Better world manifesto</h2>

<p>I want to see progress. I want change. I want state-of-the-art in software engineering to improve, not just stand still. I don’t want to reinvent the same stuff over and over, less performant and more bloated each time. I want something to believe in, a worthy end goal, a future better than what we have today, and I want a community of engineers who share that vision.</p>

<p>What we have today is not progress. We barely meet business goals with poor tools applied over the top. We’re stuck in local optima and nobody wants to move out. It’s not even a good place, it’s bloated and inefficient. We just somehow got used to it.</p>

<p>So I want to call it out: where we are today is bullshit. As engineers, we can, and should, and will do better. We can have better tools, we can build better apps, faster, more predictable, more reliable, using fewer resources (orders of magnitude fewer!). We need to understand deeply what we are doing and why. We need to deliver: reliably, predictably, with topmost quality. We can—and should–take pride in our work. Not just “given what we had…”—no buts!</p>

<p>I hope I’m not alone at this. I hope there are people out there who want to do the same. I’d appreciate if we at least start talking about how absurdly bad our current situation in the software industry is. And then we maybe figure out how to get out.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Designing good DSL</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/dsl/" />
      <id>https://tonsky.me/blog/dsl/</id>
      <published>2018-07-16T00:00:00+00:00</published>
      <updated>2018-07-16T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          A look at common mistakes in DSL designs and how to fix them
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>DSLs are great tool to reduce complexity and define problems in a compact and succinct way. In case you need to design your own, these are a few common traps to avoid.</p>

<h2 id="make-it-verbose">Make it verbose</h2>

<p>Most well-known example of non-verbose DSL is regular expressions:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>([A-Z][a-z]*[,.!?]\s+)*
</code></pre></div></div>

<p>Even though regular expressions are quite popular, it’s not a good design to copy.</p>

<p>First, most of its syntax beyond the very basics like <code class="highlighter-rouge">"X+"</code> or <code class="highlighter-rouge">"[^X]"</code> is impossible to remember. It’d be nice to know what <code class="highlighter-rouge">"(?&lt;!X)"</code> does without having to look it up first.</p>

<p>Second: how do I google something like that?</p>

<p>And third: it’s really hard to read. There are no clear boundaries, so it’s hard to understand what is part of what. I always struggle even on simple cases like <code class="highlighter-rouge">"https?"</code> (it’s either <code class="highlighter-rouge">"http"</code> or <code class="highlighter-rouge">"https"</code> but it’s really hard to see that at first sight). And when things get complex—and they do get complex quick—you’ll spend more time parsing regex in your head than you would spend writing it anew. I mean, try reading this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[a-z]{3,10}://([^/?#]*)([^?#]*)(?:\?([^#]*))?(?:#(.*))?
</code></pre></div></div>

<p>There’s nothing tricky going on, but it’s way too hard to read than it needs to be. That’s why they call Perl write-only language.</p>

<p>Another non-verbose DSL example is Java date and time format string:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"YYYY-MM-DD'T'HH:mm:ss.SSSZ"
</code></pre></div></div>

<p>More readable (the domain is way simpler) but also less widespread, so you still have to look it up every time. Not a problem while writing, but consider this: you just walking by that code and want to make simple modification (change short month to full month) or even fool-proof that it uses padded 24-hour for hours. Now, is <code class="highlighter-rouge">"HH"</code> 24-hour format or 12-hour? Is <code class="highlighter-rouge">"MM"</code> the format of month you really want here? Is it even a month, or minutes? It’s all still write-only and ungooglable.</p>

<p>Things get worse if we move to Clojure land. Clojure started as a language that assigned contextual meaning to a few language-defined syntax structures: vector might be a let-binding in <code class="highlighter-rouge">let</code> expression, function arguments list in <code class="highlighter-rouge">fn</code> and just a data structure. Again, more or less fine in a language because language is the same for all its users, finite and fixed. Learn it once and move along (still, mature developers keep discovering that e.g. <code class="highlighter-rouge">case</code> expression treats lists specially etc).</p>

<p>It got worse when library authors treated it as a design guideline. 
E.g. Datomic rules are specified like this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[(descendant? ?p ?c)
  [?p :parent ?c]]
 [(descendant? ?p ?c)
  [?p :parent ?x]
  (descendant? ?x ?c)]]
</code></pre></div></div>

<p>No words at all, just three-level deep mix of lists and vectors. If you don’t a priori know what’s going on it’s hard to even formulate a question about THAT. Also, as a user, I have to admit it’s really annoying placing all these brackets and parents right every time.</p>

<p>Core.async has the same problem. Here’s how you specify get operation in <code class="highlighter-rouge">alt!</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(alt! [c t] ...)
</code></pre></div></div>

<p>And this is put (value to channel):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(alt! [[c v]] ...)
</code></pre></div></div>

<p>I mean, this doesn’t correspond to anything in core language or even in core.async itself! It’s just a structure-based syntax for the sake of structure-basedness. Strange that the very same <code class="highlighter-rouge">alt!</code> has named options—compare how clearer those are!</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(alt! [c t]     ...
      [[c v]]   ...
      :default  nil
      :priority true) 
</code></pre></div></div>

<p>How to solve? Simple:</p>

<blockquote>
  <p>Always give alternative options/behaviors/branches long, descriptive names.</p>
</blockquote>

<p>E.g. core.match does this right:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(match [x]
  ([1 2] :seq)    ...
  (:or 1 2 3)     ...
  (_ :guard odd?) ...
  :else           ...)
</code></pre></div></div>

<p>Notice those <code class="highlighter-rouge">:seq</code> <code class="highlighter-rouge">:or</code> and <code class="highlighter-rouge">:guard</code>. Those are the explicit words marking different behaviour, not some implicit shape-defined structure.</p>

<p>Clojure.spec does good job too. It still uses short non-descriptive <code class="highlighter-rouge">+</code> and <code class="highlighter-rouge">?</code> (those are borrowed from regexes) but rest is perfectly readable and googlable words: <code class="highlighter-rouge">alt, cat, keys, req, coll-of, map-of, every, tuple</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(spec/alt
 :arity-1 ::args+body
 :arity-n (spec/cat
           :bodies (spec/+ (spec/spec ::args+body))
           :attr   (spec/? map?)))
</code></pre></div></div>

<p>This is how datetime formatting could be done, aided by this principle (example from <a href="https://github.com/tonsky/tongue">Tongue</a>):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{hour12}:{minutes-padded}{dayperiod} {month-numeric}/{day}/ {year-2digit}
</code></pre></div></div>

<p>Verbose, yes, but why would you care about just a few more characters here, when readability is at stake? By making it verbose, even without any prior experience with Tongue, anyone can fool-proof that this code will output something like <code class="highlighter-rouge">"1:05PM 7/13/18"</code> and not <code class="highlighter-rouge">"13:5PM 07/13/2018"</code>. Or even add 0-padding to hours, day and month and maybe even change 12-hour to 24-hour format if needed. Without even looking at the docs! Can you say the same about <code class="highlighter-rouge">"H:mm a d/M/y"</code>?</p>

<p>As for regexes, there’re <a href="https://github.com/VerbalExpressions">VerbalExpressions</a>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var tester = VerEx()
    .startOfLine()
    .then('http')
    .maybe('s')
    .then('://')
    .maybe('www.')
    .anythingBut(' ')
    .endOfLine();
</code></pre></div></div>

<h2 id="dont-invent-second-syntax">Don’t invent second syntax</h2>

<p>Sometimes your DSL starts simple and then you figure there’s no way to handle complex cases. So you extend it with advanced ways to do stuff. E.g. Datomic Pull syntax let you simply list attributes you need, attribute = keyword:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[:artist/name :artist/gid ...]
</code></pre></div></div>

<p>But that way there’s no way to specify additional options: nesting, limits, etc. So even though attributes started as keywords in a list, sometimes they might be specified as a map:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{:artist/tracks [:track/name :track/gid ...]}
</code></pre></div></div>

<p>Or a list can be used instead of keyword:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(:artist/endYear :default "N/A")
</code></pre></div></div>

<p>Now even I am confused how to combine default and nesting in a single expression.</p>

<p>Sometimes you start with all-powerful solution and then figure it’s really too much writing for simple cases. So you add shortcuts. E.g. Datomic query let you shorthand this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(d/q {:find  [?a]
      :where [[?a :artist/name "Beatles"]]})
</code></pre></div></div>

<p>to this (less brackets):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(d/q [:find  ?a
      :where [?a :artist/name "Beatles"]])
</code></pre></div></div>

<p>Both ways, now your language has two+ ways of saying the same thing.</p>

<p>Having more than one way to do something is not a virtue, it’s a curse. Your users now have to learn two syntaxes. They need twice as much examples. Answers found on internet might not work because they use different syntax, etc.</p>

<p>My suggestion:</p>

<blockquote>
  <p>One way to do it + an escape hatch.</p>
</blockquote>

<p>You cover most of your users’ needs (that’s the primary value of your DSL anyway) and let users figure the rest in plain old code—best of both worlds.</p>

<h2 id="dont-be-too-liberal">Don’t be too liberal</h2>

<p>Almost the same as the previous one, but on a smaller scale. Sometimes DSLs let you get away with small variations: e.g. in Datomic you can specify <code class="highlighter-rouge">default</code> and <code class="highlighter-rouge">limit</code> as either keyword, symbol or a string—all are fine (apparently, you can even change order):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(:artist/tracks :limit 10)
(:artist/tracks "limit" 10)
(limit :artist/tracks 10)
</code></pre></div></div>

<p>Hiccup lets you drop empty attributes map:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[:div {} "Hello, world"]
[:div "Hello, world"]
</code></pre></div></div>

<p>Core.match lets you drop vector in case you’re matching a single value:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(match [x]
  [:a] ...
  :a   ...) // the same
</code></pre></div></div>

<p>The thing with special cases, same as with multiple syntaxes, is that you have to learn them, remember about them and recognize them. That’s a problem: it eats up cognitive resources better spent elsewhere.</p>

<p>Also, people in your/other teams will have <em>preferences</em> or would simply not care about consistency. Hence:</p>

<blockquote>
  <p>The only way to force everybody to always do the same thing is to ban any variations.</p>
</blockquote>

<p>Being DSL designer, it’s your responsibility alone.</p>

<h2 id="keep-it-small">Keep it small</h2>

<p>Rule of thumb:</p>

<blockquote>
  <p>Your DSL should be entirely memorizable.</p>
</blockquote>

<p>That makes using it quick (once you’ve learned it), and this is where the value comes from. If you don’t use it too often or there’s too much syntax, you’ll be required to look at documentation each time before using or reading it. That slows things down, making using DSL an effort and eventually leading to DSL being replaced with a simpler solution.</p>

<h2 id="dont-try-to-help-too-much">Don’t try to help too much</h2>

<p>Many DSLs were designed to reduce amount of non-DSL code to the absolute zero. They try to help too much. Your stance here should be:</p>

<blockquote>
  <p>Do in DSL what you know how to do well, leave rest for the users to figure out.</p>
</blockquote>

<p>E.g. routing libraries might extract parameters but shouldn’t try to coerce them to other types—it’s really simple to do in your own code. Your users will have full programming language to handle those tricky/rare/exceptional cases.</p>

<p>Sometimes not doing stuff in DSL and leaving specific cases to users leads to less overall complexity.</p>

<h2 id="conclusion">Conclusion</h2>

<p>That’s more or less all I can think of right now. Designing DSLs is a fun and rewarding activity, but as with any design, it’s really hard to get right. I wish you luck on that tricky path, and let me know if it helps.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Library focus</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/library-focus/" />
      <id>https://tonsky.me/blog/library-focus/</id>
      <published>2018-07-11T00:00:00+00:00</published>
      <updated>2018-07-11T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Why you shouldn’t write libraries as a part of a bigger software project
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>Software projects rely on libraries heavily. Usually it’s pretty simple: you have a need, you pick a library, you integrate it and get results. Most of the time it’s advantegeous—economically—because it’s faster than rolling your own implementation.</p>

<p>Clojure, though, faces an unique challenge here: many problems that have been addressed by libraries can be trivially solved in your own code too, and it can be done in a time that is comparable to the time that’ll take you to figure out a library. I’m not exaggerating—it’s really <em>that simple</em>.</p>

<p>Sure, there are libraries that do heavy lifting—stuff like DataScript or Instaparse, those will take you more than a day to write. But a good half of all libraries, or even more, <em>can</em> be reproduced in day’s time. Maybe not for all use cases, but for all <em>your cases</em> at least. If you think of it, all clojure.test does is just asserting for you, Component runs functions that you give it to run, compojure/bidi/other routers do pretty basic regexp matching on strings, etc.</p>

<p>So, if you <em>can</em> solve your problems by writing your own code, and there’re no economic reasons not to, why shouldn’t you? You’ll get more freedom and better fit for your unique problems, right?</p>

<p>Well, you shouldn’t do it because you’re badly positioned to do so. Libraries and products need different focus. If you’re writing a production project, <em>there’re no powers in play that’ll stop you from compromising greater but further good to the immediate needs.</em> You’ll inevitably end up with incoherent, incomplete home-grown “library” that’s pain to use (as the rest of your code is) and is tightly coupled to your project.</p>

<p>Code is probably the simplest to isolate, but the assumptions, the features you decided to focus on will create the unfortunate coupling and compromised vision. Sometimes you’ll skip on crucial parts because there’s no time, sometimes you’ll focus on parts that shouldn’t be solved in there (but were very convenient—and quick—to solve there nevertheless). And of course you’ll never add stuff in advance, so it’ll never be finished, not really, and will change all the time.</p>

<p>So no, you can’t build a project and publish parts of it open-source while at it, not in a valuable way. It’s either one or the other.</p>

<p>I’m only writing about this because the difference’s so subtle it’s almost magical: the very same people, perfectly capable software engineers, when put in a bigger project context, almost physically can’t produce anything comparable to a library code in terms of clarity, isolation and reusability.</p>

<p>So yeah, choosing a library over rolling your own implementation has a benefit: a benefit of author’s focus that’s different from your immediate needs.</p>

<p>And no, don’t plan a project’s architecture on a library you plan to write first that’ll make rest of the development easier. That’ll never fly.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Speed is a feature</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/speed/" />
      <id>https://tonsky.me/blog/speed/</id>
      <published>2018-04-04T00:00:00+00:00</published>
      <updated>2018-04-04T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          When speed is a crucial UX factor
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>Jane Street engineers have built their own intergrated code review UI that unifies local directories, local Mercurial repos, remote Mercurial repos and pull-requests/task management. <a href="https://blog.janestreet.com/putting-the-i-back-in-ide-towards-a-github-explorer/">Details</a>.</p>

<figure><img src="todo.png" /></figure>

<p>What I find particulary interesting is this line:</p>

<blockquote>
  <p>One of the things we found with our system is that it didn’t really click until we had a sub-100ms code review server.</p>
</blockquote>

<p>So they’ve designed couple of features for a very narrow and specific use-case, polished the integration, removed all other barries and otherwise did everything right and, apparently, brought a lot of value. Yet nobody considered it valuable enough until they got the response time right.</p>

<p>When they did crossed that 100ms barrier, though, a qualitative change happened. People changed their views of a tool from something they have to cope with to something that’s fun, valuable and eventually become their second nature. Now they can’t imagine how they lived otherwise.</p>

<p>Now imagine: how many programs and services make us wait more than 100ms? I’d say more or less all of them, starting with almost every website, with a few exceptions. You don’t think about “requesting” Google when you type your search query and it auto-completes after each letter. But you do think about rebooting your computer. Or booting up your text editor. Or even loading a Medium article (6 sec last time I checked). Because they’re all so slow you have to adjust and build your habits around that waiting time. Heck, Jane Street built the integration because waiting on Web UI to load was an eternity.</p>

<p>Millions of programs have that unfulfilled potential of becoming your second nature, something you don’t even think about when interacting with. They’re waiting to be enabled to “click”. Speed is a feature.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>JavaScript v. backward compatibility</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/compatibility/" />
      <id>https://tonsky.me/blog/compatibility/</id>
      <published>2018-03-12T00:00:00+00:00</published>
      <updated>2018-03-12T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          For some unclear reason, many JS developers are opposed to the idea of backward compatibility
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <blockquote>
  <p>Inside the carton is a push-button unit fastened to a small wooden box. A glass dome covers the button. If you push the button, somewhere in the world someone you don’t know will die. In return you will receive a payment of $50,000. It could be anyone. All we guarantee is that you don’t know them. And, of course, that you wouldn’t have to watch them die. For $50,000.</p>
</blockquote>

<p>The question is: would you push that button? For $50,000? For $1M? If you read something like that in a short story or see it in a movie, you’d know there’s always a catch somewhere. Yet in a real world many JavaScript developers seem eager to push the button. Even if there’s no money. They’d just push the button over and over with no reward in return.</p>

<figure><img src="http://tonsky.me/blog/compatibility/warnings.png" /></figure>

<p>Well, it’s not exactly someone would die, of course. Let me correct:</p>

<blockquote>
  <p>Inside the carton is a push-button unit fastened to a small wooden box. A glass dome covers the button. If you push the button, somewhere on the Internet some websites would break. It could be any site. It would have real users, real people using them, relying on them. But we guarantee it wouldn’t be your site. In return you will receive a convenient method that you could’ve implemented in 20 lines of code or imported from a library.</p>
</blockquote>

<p>Is that a good price to pay? Are you willing to pay it? Does it matter what you’ll get in return? I deliberately don’t link the issue because it’s trivial. Does it still worth breaking part of the Internet?</p>

<p>If your answer is “yes”, I have bad news for you. Let me rephrase: you can get X in a backward-compatible, clean and safe way right now, with no downsides, but you still want it to be implemented in a way that breaks live websites with live users. Really?</p>

<figure><img src="http://tonsky.me/blog/compatibility/goodbye.png" /></figure>

<p>I’m not sure why JavaScript developers are so opposed to the idea of backward compatibility. Imagine you come to a doctor and she says: we can put your arm in plaster and it’ll heal itself, will be as good as new, or we can cut it off. Apparently, there’re lots of JavaScript developers who would choose to cut off the hand. More specifically, they would choose to cut off someone else’s hand. And there’s nothing wrong with theirs, they just like chopping off other people’s hands. Because that’s how they see language evolution should happen.</p>

<figure><img src="http://tonsky.me/blog/compatibility/progress.png" /></figure>

<p>Isn’t it schizophrenic to think that language specification is permanent but websites built with it aren’t?</p>

<figure><img src="http://tonsky.me/blog/compatibility/permanent.png" /></figure>

<p>Maybe you just need experience to be able to see outside of your bubble. Or even to realize there’s a bubble. If you’re 22 years old web-developer who changes jobs every 18 months, everything older than 2 years seems like old crap nobody cares about, because you only talk to your friends who are also 22 years old and they don’t care so obviously nobody does. You’ve heard scary stories about IE 6, that it was terrible and didn’t support grid layout and obviously people were way stupider back then if they couldn’t figure out grid layout so why would anyone care about that old crap anyways? Anything but move fast and break things is degeneracy, oblivion, and death.</p>

<figure><img src="http://tonsky.me/blog/compatibility/degeneracy.png" /></figure>

<p>Let’s stop here for a moment. I always wanted to understand: what, in your opinion, is wrong with Java anyways? Last time I checked it was twice as fast as JavaScript, had static typing, dynamic linking, real multithreading, vast standard library, reliable package manager, tons of languages to compile from (including dynamic ones and yes, JS), ~100ms startup time (same as Node), perfect record of backward compatibility, language changes and API additions every major release, huge internal optimizations yet somehow it manages not to break its APIs and not to piss every developer on the planet. What’s wrong with that? A bit boring, not enough drama? Relationship not abusive enough? Well, if you call that degeneracy, I choose degeneracy.</p>

<p>Reality check: Java does not have a bad reputation. JavaScript does. People laugh at JavaScript, its ecosystem, how it handles things and how childish their problems are. No, I’m not a Java developer, but I wish I could write websites in Java. Would’ve be at least twice as fast.</p>

<p>Backward compatibility is not always hard to pull off, by the way. Changing behavior is hard. Removing stuff is hard. But adding stuff with 100% guaranteed backward compatibility? Seriously, that’s easy <em>anywhere</em> but in JS land.</p>

<figure><img src="http://tonsky.me/blog/compatibility/adding.png" /></figure>

<p>I mean, how many experts do you need to understand that IF you can’t put stuff on prototypes in a backward-compatible way, either in libraries or language specification, THEN the solution is NOT to continue to do so. Stop. Just STOP. There’re other ways to extend, you know?</p>

<p>But why should <em>you</em>, the developer, care? Isn’t it just a problem of those old websites? Can’t they <em>just</em> keep up? Can’t <em>they</em> alter their websites every time language specification changes?</p>

<figure><img src="http://tonsky.me/blog/compatibility/developers.png" /></figure>

<p>Hmm, let me think. Can you? Yes, <em>you</em>, you personally. Imagine every employer you ever worked for suddenly shows up at your door and asks you to update every website you’ve ever built and redo it with the grid and flexbox and adaptive pictures and whatnot. Ok I guess this example doesn’t sound so scary to 22-year-olds, but imagine the same thing happens in eight years from now and they (every employer you had up to that moment, which would be <em>a lot</em>) ask you to implement constraint layout or whatever shit will be popular at the moment. Also imagine it’ll keep happening until the end of your life, with 6-12 month intervals, because shit keeps changing constantly. Sounds realistic?</p>

<p>That’s why we have backward compatibility. So situations like that don’t happen. You don’t expect publishers of XVI century books to reprint all their books every time language norms change, do you? Even if they wanted to, most of them are dead by now.</p>

<figure><img src="http://tonsky.me/blog/compatibility/publishers.png" /></figure>

<p>Maybe it’s a question of perspective. If websites are just job for you, it ends when you get paid. Not much to care about in that case. But for the rest of us, for people who’re actually using the Internet, including (probably) your website, including (probably) you, we see it as an informational resource, a data network for the whole Earth for all future generations. And yes, we’re pissed off when stuff doesn’t work. And no, it’s not our problem, and it’s not website developer’s problem, it’s a fail of engineering community as a whole if you can’t figure out how to make things that last at least 8 years.</p>

<p>Just EIGHT YEARS! I can read books that are <em>centuries</em> old just fine. Inception came out 8 years ago. Imagine you couldn’t watch Inception today because of some technical mumbo-jumbo?</p>

<p>It’s <em>your</em> personal responsibility to build a technology that doesn’t break every time wind changes. Get back to the drawing board and start thinking. Stuff ain’t that hard. It’s been done before. And no, “every developer, live or dead, should sit tight and update every website they have ever built until the end of times” is not an answer.</p>

<h2 id="upd-emergency-update">UPD: Emergency update</h2>

<p>People seem to misread what I’m saying and still try to make it about MooTools and how they are the bad guys here. They are not. In fact, it’s irreleveant. It’s not about MooTools, how old it is or how unpopular it is. If there existed just one website that had just one line of hand-crafted JS code that would break with that update it’s totally not worth it. Because there’re clean ways to extend the language, and there’re dirty ways, and dirty ones have no benefits. Why choose them if you can make <em>everyone</em> happy?</p>

<p>JS standard lets developers put stuff on prototypes, that’s game over, NO LANGUAGE UPDATE should EVER put stuff there, period. It’s not MooTools who should stop doing that, it’s TC39. Because stuff will break. It’s a breaking change. Nobody is in control of this situation. Given that you can get <em>exactly</em> the same results without the breaking change, why break? Pick a different way, make sure you’re in control, make sure it’s safe, and <em>then</em> start evolving JS.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Hiccup, Macros, API design, and magic</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/hiccup/" />
      <id>https://tonsky.me/blog/hiccup/</id>
      <published>2018-01-31T00:00:00+00:00</published>
      <updated>2018-01-31T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Small changes in usage conditions could require full library redesign
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>Every web developer <del>is unhappy in their own way</del> needs a way to generate HTML.</p>

<p>In Clojure, the most popular approach is to use <a href="http://github.com/weavejester/hiccup">Hiccup</a>. Hiccup is a library that ditches this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(str "&lt;div id='timer'&gt;"
       "Time is &lt;a href='#' class='time'&gt;"
       time
       "&lt;/a&gt; sec"
     "&lt;/div&gt;")
</code></pre></div></div>

<p>in favor of this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(hiccup.core/html
  [:div#timer {}
    "Time is " [:a.time {:href "#"} time] " sec"])
</code></pre></div></div>

<p>Basically, it gives you convenience. It doesn’t change HTML semantics in any way. It’s an alternative, much more concise, Clojure-friendly syntax to write exactly the same thing.</p>

<p><em>(Yes, on a grand scheme of things, more convenient syntax for HTML is like having three bullet holes in your back but taking an aspirin to treat a headache. It helps, sort of. But in practice, we all are stuck with HTML, so might at least take the aspirin. When I first tried it, I was surprised how much I actually like the thing, and I never wanted to go back to verbose HTML)</em></p>

<h2 id="how-hiccup-works">How Hiccup works</h2>

<p>Naïve implementation would go over all those nested vectors, dispatch by children type, walk attributes map and convert all that to strings one-by-one, <code class="highlighter-rouge">clojure.string/join</code>-ing everything in the end.</p>

<p>Hiccup did something smarter. <code class="highlighter-rouge">hiccup.core/html</code> is a macro that analyzes the form inside and replaces everything that is known to be a constant at compile time with the compiled strings, at no runtime cost. <code class="highlighter-rouge">html</code> will convert most of your code inside into a huge string catenation:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(macroexpand 
 '(hiccup.core/html
    [:div#timer {}
      "Time is " [:a.time {:href "#"} time] " sec"]))

=&gt; (clojure.core/str
     "&lt;div"
     " id=\"timer\""
     "&gt;"
     "Time is "
     "&lt;a"
     " class=\"time\" href=\"#\""
     "&gt;"
     ((var hiccup.compiler/render-html) time)
     "&lt;/a&gt;"
     " sec"
     "&lt;/div&gt;")
</code></pre></div></div>

<p>Great, right? We got almost constant performance at runtime almost for free (well, at the cost of James Reeves time). And it <em>is</em> great. And smart. And it gives you a significant performance gain. The approach proved highly successful, and many libs copied it.</p>

<p>But let’s talk some limitations.</p>

<h2 id="limitations">Limitations</h2>

<p><code class="highlighter-rouge">hiccup.core/html</code> is a macro. It means it works with syntactic forms, not runtime values. It also means it cannot see inside function calls.</p>

<p>See that <code class="highlighter-rouge">render-html</code> call around <code class="highlighter-rouge">time</code>? It’s because the compiler has no idea what’s inside (string? more hiccup vectors?), so it has to <em>play safe</em> by switching into interpreted (or runtime, or naïve) mode, losing all performance gains for that particular part of the code.</p>

<p>Another limitation comes from the fact that tags are just vectors, meaning there’s no way for Hiccup compiler to tell normal vectors from stuff we expect to be rendered as tags. It knows that end result should contain tags only, but it doesn’t mean every vector in a form is a tag. Consider this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(hiccup.core/html
  (let [vec [:div "b" "c"]]
    [:div "Count " (count vec)]))
</code></pre></div></div>

<p>In that case, <code class="highlighter-rouge">[:div "Count " (count vec)]</code> should be converted to a tag, but <code class="highlighter-rouge">[:div "b" "c"]</code> shouldn’t. Again, the only option for compiler here is to play safe and only look at the actual return value at runtime, effectively falling back to the naïve algorithm.</p>

<p>Short summary. Pre-compilation in a macro could give you significant performance gains, but only in certain cases, and compiler <em>has to</em> play it safe most of the time to stay correct. Not perfect, but still better than always taking the slow path, right?</p>

<h2 id="going-to-the-browser">Going to the browser</h2>

<p>Let’s look at another library: <a href="https://github.com/r0man/sablono">Sablono</a>.</p>

<p>Sablono is a compiler for Hiccup-style markup that produces React elements instead of HTML string. The idea is exactly the same, and as far as I can tell, initial compiler code was copied over from Hiccup and adjusted as needed.</p>

<p>The difference is, Sablono is supposed to be used in the browser, rendering React user interfaces. That means interpreting many potentially complex, highly nested markups with lots of components at 60 frames per second. Also, remember that JS is significantly slower than JVM (at least 2×), browsers run on consumer devices, not high-end servers, and people have low tolerance for lags and delays in their UIs.</p>

<p>What does it change? Well, if for Hiccup not getting every bit of performance was a minor inconvenience, in UI it’s critical to get every possible bit of performance from code and not waste it unless it’s absolutely unavoidable.</p>

<p>It means that tables have turned: the compiler is not a performance optimization anymore. The compiler is a baseline now, and runtime interpretation is a performance degradation and, essentially, a bug.</p>

<p>That makes <code class="highlighter-rouge">html</code> macro very inconvenient to use. You now have to somehow tell parts it could compile from parts that are opaque to it. And no, there’s no indication for it. Only your gut feeling and vague tribal knowledge passed from one frontend developer to the next. No guarantees either: next compiler version might “uncompile” some of your code if compiler author finds out that it was never safe to compile that particular form in the first place. That lead to a couple of “best practices” articles advising you where to wrap and where to double-wrap your tags in <code class="highlighter-rouge">html</code> macro to make sure everything will be as performant as possible.</p>

<p>Pretty fascinating how with a subtle context change the whole approach comes from totally fine to completely unacceptable. Both libraries <em>work the same</em> and are required to <em>do exactly the same thing</em>, but conditions of their operation are slightly different, and that alone made entire API useless.</p>

<h2 id="alternatives">Alternatives</h2>

<p>Ok, what’s the solution?</p>

<p>One is to <a href="https://medium.com/@rauh/a-new-hiccup-compiler-for-clojurescript-8a7b63dc5128">remove runtime mode altogether</a>. It would work but still leaves you guessing where to put that <code class="highlighter-rouge">html</code> tag. Would the compiler be smart enough to compile that bit? Write, test, exception—nah, have to wrap it too.</p>

<p>It’s a working approach, but I personally don’t like the “guessing” part and the feeling of uncertainty it creates. Also: what if a new release of the compiler changes the formula and somewhere deep inside your app some rarely-seen dialogue will silently stop working? Seems like a time bomb waiting to explode.</p>

<p>Another one is to explicitly mark tags. For example, in Om:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(om.dom/div nil
  (om.dom/h3 nil (str "Props: " props))
  (om.dom/h3 nil (str "Shared: " shared))
  (om.dom/button #js {:onClick #(...)}
    "Increment!")))))
</code></pre></div></div>

<p>Each tag has to be wrapped in its own function or macro. This is the most straightforward, reliable, unsurprising approach there could be, and it only comes at the small cost of some extra typing, and at no performance cost at all.</p>

<h2 id="what-have-we-learned">What have we learned?</h2>

<ul>
  <li>Macros aren’t magic.</li>
  <li>Small changes in usage conditions could lead to a full library redesign.</li>
  <li>There’s more to API than input, output and method names.</li>
  <li>Reliable first, predictable second, convenient last.</li>
</ul>

<h2 id="one-more-thing">One more thing</h2>

<p>Since our topic today is subtle aspects of API design, let me suggest another questionable hypothesis.</p>

<p>The greatest gift of Hiccup syntax was its use of square brackets instead of parentheses. You see, Clojure is all about parentheses, it’s full of them, they are everywhere. Clojure code <em>is</em> parentheses. Square brackets for tags moved markup into another, separate information layer.</p>

<p>Having tags look different helped. <em>A lot</em>. It would be great if next markup solution kept that. So far I’m thinking reader tags for Rum v.2:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#rum/tag [:div#timer
            "Time is " #rum/tag [:span.time time] " sec"]
</code></pre></div></div>

<p>M? What do you think?</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Cursor keys belong at the center of your keyboard</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/cursor-keys/" />
      <id>https://tonsky.me/blog/cursor-keys/</id>
      <published>2018-01-22T00:00:00+00:00</published>
      <updated>2018-01-22T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Remap `CapsLock` + `IJKL` to act as cursor keys and teach yourself to use it
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p><em>TL;DR Remap <code class="highlighter-rouge">CapsLock</code> + <code class="highlighter-rouge">IJKL</code> to act as cursor keys and teach yourself to use it</em></p>

<p>Have you ever wondered if default keyboard layout is optimal for today’s tasks? Modern keyboards inherit their design all the way back from early typewriters. Typewriters were optimized for, well, typing. That makes modern keyboards best optimized for typing too. With your hands in the <em>default position</em> every letter and punctuation are easy to access.</p>

<figure><img src="https://tonsky.me/blog/cursor-keys/rss/normal_position.png" /></figure>

<p>But on modern computers you also need to move the cursor around. Typewriter didn’t have a cursor, so there were no buttons for it nor was there a good place saved for them. So, on computers cursor keys are put far away from the center.</p>

<figure><img src="https://tonsky.me/blog/cursor-keys/rss/far_away.png" /></figure>

<p>But it’s not <em>that</em> far, is it? Not in absolute terms, no. But to get there, you have to move your palm, which is quite effortful. If you don’t register that as a significant effort it’s only because you’re used to it. It doesn’t mean it’s not there. In case you’ve ever heard that programmers are not happy with using the mouse—it’s the same reason actually. The mouse itself is fine, it’s just too far away what makes it inconvenient. Distance matters.</p>

<p>Not only are cursor keys far away, you end up needing them <em>a lot</em>. My estimate is that typing/cursor movements are at 30%/70% ratio, at least if you work with text (programming, writing, etc).</p>

<p>So on a modern keyboard <em>cursors keys</em> belong in the center, not the letters. A perfect keyboard would look something like this:</p>

<figure><img src="https://tonsky.me/blog/cursor-keys/rss/center.png" /></figure>

<p>There’s actually a precedent to support my claim: a text editor called Vim. Quite old, but extremely popular amongst programmers, sometimes to the point of fanaticism. And the feature Vim users praise the most is the ability to move the cursor without changing hand position (<code class="highlighter-rouge">HJKL</code> keys). They actually like it so much they write plugins for every other program in the world to support same shortcuts via “Vim modes”. Talk about dedication.</p>

<figure><img src="https://tonsky.me/blog/cursor-keys/rss/vim.png" /></figure>

<h2 id="the-solution">The solution</h2>

<p>So we want the benefits of having cursor keys at the center of the keyboard, we want it to work system-wide (versus being limited to a single app), and we definitely don’t want to buy a new keyboard for that. Especially the one with an uncommon layout.</p>

<p>This is what I did: I scripted <code class="highlighter-rouge">CapsLock+IJKL</code> to act as cursor keys system-wide.</p>

<figure><img src="https://tonsky.me/blog/cursor-keys/rss/remap.png" /></figure>

<p>Keyboard geeks know that CapsLock key is special: an absolutely useless key sitting on a home row, almost at the center, super easy to reach. How lucky are we to have it? And <code class="highlighter-rouge">IJKL</code> form nice “reverse T” shape that is natural to use.</p>

<h2 id="how-to-for-macos">How-to for macOS</h2>

<p>Install <a href="https://pqrs.org/osx/karabiner/index.html" target="_blank">Karabiner Elements</a> (free):</p>

<figure><img src="karabiner_install.png" /></figure>

<p>Run it:</p>

<figure><img src="karabiner_run.png" /></figure>

<p>Import my config by <a href="karabiner://karabiner/assets/complex_modifications/import?url=https://s.tonsky.me/karabiner/capslock_ijkl_fn.json">clicking on this link</a> (it’s the official way to install complex modfications):</p>

<figure><img src="karabiner_import.png" /></figure>

<p>Side note: if you plan to use Caps as Ctrl, use <a href="karabiner://karabiner/assets/complex_modifications/import?url=https://s.tonsky.me/karabiner/capslock_ijkl_ctrl.json">this link instead</a>.</p>

<p>After that, one more step is required. Enable it:</p>

<figure><img src="karabiner_enable.png" /></figure>

<p>In the end it should look like this:</p>

<figure><img src="karabiner_result.png" /></figure>

<p>From now on when you <em>hold</em> Caps Lock and press any of <code class="highlighter-rouge">IJKL</code> it’ll move your cursor as if you’d press arrow keys. In any context. You can also combine it with modifiers (Shift/Cmd/Alt/Ctrl).</p>

<p>Bonus: I also map <code class="highlighter-rouge">CapsLock+H</code> to <code class="highlighter-rouge">Backspace</code> which I find very handy as well.</p>

<h2 id="how-to-for-windows">How-to for Windows</h2>

<p>For Windows I had success using <a href="https://www.autohotkey.com/" target="_blank">AutoHotKey</a> (free) with this config:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SetCapsLockState, AlwaysOff

CapsLock &amp; j::Send, {blind}{Left}
CapsLock &amp; k::Send, {blind}{Down}
CapsLock &amp; l::Send, {blind}{Right}
CapsLock &amp; i::Send, {blind}{Up}
CapsLock &amp; h::Send, {blind}{Backspace}
</code></pre></div></div>

<h2 id="important-overriding-your-habits">Important: Overriding Your Habits</h2>

<p>I wish it was all you need to do. It is not. The last thing to reconfigure is yourself.</p>

<p>You already know how to type, and that’s the problem. Old typing habits will get in your way.</p>

<p>The first thing you need to know: people don’t automatically pick up better habits. If you already know how to do something, and new way comes to your attention, you won’t automatically switch. Even if the new way is better. Instead, after you’ve initially learned <em>some</em> way to achieve something, your default behavior becomes to always go with it. This is called local optima. Nothing wrong with it, it’s just how we humans work.</p>

<p>Unfortunately, getting out of local optima is not a question of repetition or “getting better with time”. Even if you type million times a day you’ll still do it the old way, leading to no change. Improvement requires conscious effort.</p>

<p>The best way to trick yourself into learning a new habit is to burn the bridges. If the old habit is not an option, you’ll be forced to learn a new one instead. That’s why I’ve disabled arrow keys in my Karabiner config:</p>

<figure><img src="karabiner_disabled.png" /></figure>

<p>With this done, you would force yourself to use new typing method and you’ll automatically start learning. Be prepared: at first, it will feel ridiculous because you won’t be able to do very basic things like moving cursor one symbol left or right. It’ll feel like having to learn how to walk all over again. You’ll need to focus on things that you now get for granted. You’ll have to think, plan and coordinate your fingers in order to get basic things done.</p>

<p>It is frustrating, it is annoying as hell, but there’s no way around it. Don’t worry: it won’t take long. After a day or two you’ll be able to do most things, and after a week you’ll be able to move the cursor without thinking about it at all. Congratulations: you just learned a new habit!</p>

<p>After a week it’s safe to enable cursor keys and backspace back. At this moment you might try to use the old way just to see how ridiculously inconvenient it was. But you needed to develop new habit first to really appreciate and <em>feel</em> it.</p>

<p>If you’re curious, learning new keyboard or an alternative layout takes about the same amount of time and effort. Still worth it.</p>

<h2 id="whats-next">What’s next?</h2>

<p>You now have a superpower. Go write something awesome!</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>My web app died from performance bankruptcy</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/chrome-intervention/" />
      <id>https://tonsky.me/blog/chrome-intervention/</id>
      <published>2017-11-05T00:00:00+00:00</published>
      <updated>2017-11-05T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Chrome team breaks existing web to make Chrome perform better
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p><em>TL;DR Chrome team breaks web to make Chrome perform better.</em></p>

<p>There’s a widely-used piece of DOM API called <code class="highlighter-rouge">addEventListener</code>. Almost every web site or web app that does anything dynamic with JS probably depends on this method in some way.</p>

<p>Up until 2016 the convention was that you just pass an event type, a callback and an optional “useCapture” boolean flag:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>target.addEventListener(type, listener[, useCapture]);
</code></pre></div></div>

<p>Then Google <a href="https://github.com/whatwg/dom/pull/82">came along</a> and decided that this API is not extensible enough (which is true). What if one wanted more options? Surely, there must be a map of options, not just a single positional boolean argument. To which, again, I can’t agree more. So they added a second form:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>addEventListener(type, listener[, useCapture]);
addEventListener(type, listener[, options]);
</code></pre></div></div>

<p>Which means you can’t practically use the new form without feature detection. At all. Never ever. Old browsers can’t be made to understand <code class="highlighter-rouge">options</code> form. Period.</p>

<p>But that’s fine. That’s all right. That’s why we have feature detection.</p>

<h2 id="dom-apis-arent-meant-to-be-used">DOM APIs aren’t meant to be used</h2>

<p>Ok, so there must be some sort of feature detection API accompanying this change, right? Well, if you thought so, you clearly have never worked with web APIs. Even though web developers are <em>supposed</em> to <em>always</em> use feature detection, they’re also supposed to rely on a complex, brittle and accidental effects to check for it.</p>

<p>This is the code <a href="https://github.com/WICG/EventListenerOptions/issues/16">you’re supposed to be using</a>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>var supportsPassive = false;
try {
  var opts = Object.defineProperty({}, 'passive', {
    get: function() {
      supportsPassive = true;
    }
  });
  window.addEventListener("test", null, opts);
} catch (e) {}
</code></pre></div></div>

<p>Basically, you’re constructing a special object with a side-effect-producing getter and hope for the browser to access it when you install a fake event listener. Surely, what could go wrong?</p>

<p>To be fair, there’s <a href="https://github.com/whatwg/dom/issues/491">an open discussion</a> for adding better feature detection around this. But the timing is as messy as the API itself. If feature detection will ever be implemented, we’d have three browser classes:</p>

<ul>
  <li>the ones that don’t support <code class="highlighter-rouge">options</code> at all,</li>
  <li>the ones that do support it but don’t support feature detection for it (so you’ll have to resort to the getter+fake event hack anyway),</li>
  <li>and the ones that support both feature detection and the API.</li>
</ul>

<p>Think about it: a feature detection API that itself needs to be detected <nobr>¯\_(ツ)_/¯</nobr>.</p>

<h2 id="making-chrome-fast">Making Chrome fast</h2>

<p>But that’s not the end of the story. Chrome team proposed the API change to add <code class="highlighter-rouge">passive</code> option because it allowed them to speed up scrolling on mobile websites.</p>

<p>The gist of it: if you mark <code class="highlighter-rouge">onscroll</code>/<code class="highlighter-rouge">ontouch</code> event listener as <code class="highlighter-rouge">passive</code>, Mobile Google can scroll your page faster (let’s not go into details, but that’s how things <em>are</em>). Old websites continue to work (slow, as before), and new websites have <em>an option</em> to be made faster at the cost of an additional feature check and one more option. It’s a win-win, right?</p>

<p>Turned out, Google wasn’t concerned about your websites at all. It was more concerned about its own product performance, Google Chrome Mobile. That’s why on February 1, 2017, they made all top-level event listeners passive by default. They call it “<a href="https://developers.google.com/web/updates/2017/01/scrolling-intervention">an intervention</a>”.</p>

<p>Now, this is a terrible thing to do. It’s very, very, very bad. Basically, Chrome broke half of user websites, the ones that were relying on touch/scroll events being cancellable, at the benefit of winning some performance for websites that were not yet aware of this optional optimization.</p>

<p>This was <em>not</em> backward compatible change by any means. All websites and web apps that did any sort of draggable UI (sliders, maps, reorderable lists, even slide-in panels) were <em>affected</em> and essentially <em>broken</em> by this change.</p>

<p>Yet, if things become faster, they can always praise Mobile Chrome for the improvement. And if something breaks, people would probably blame website anyways. RByers (a Google Team engineer who advocated for the intervention) <a href="https://github.com/WICG/interventions/issues/18#issuecomment-309058348">commented on Jun 16</a>:</p>

<blockquote>
  <p>Our data suggests we made the right trade-off for the web platform as a whole and for Chrome as a product. I understand that your perspective is the opposite and I’m sorry about that - I really wish there was a way to make everyone happy, that’s just not reality.</p>
</blockquote>

<p>Also, notice how harsh timeline on this update was. The <code class="highlighter-rouge">passive</code> option was released on June 1, 2016 (Chrome 51). Passive made default was out on February 1, 2017 (Chrome 56). That’s just 8 months! They couldn’t even agree on feature detection API in that time! Before June 2016 you didn’t even have an API for marking listeners passive! And just 8 months later your app is already silently broken and punished for not using new API that others browsers barely started to roll out!</p>

<h2 id="excerpts-from-intervention-discussion">Excerpts from intervention discussion</h2>

<p>RByers <a href="https://github.com/WICG/interventions/issues/18#issuecomment-249916777">commented on Sep 27, 2016</a>:</p>

<blockquote>
  <p>Of course we’d need some transition path over many years to avoid breaking the web too badly in order to get there.</p>
</blockquote>

<p>RByers <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=639227#c27">commented on Feb 9</a>:</p>

<blockquote>
  <p>I’m deeply sorry for the frustration this has caused you. We’ve long tried the “opt-in” approach but have learned that on average developers don’t make the effort to opt-in to better performance.</p>
</blockquote>

<p>RByers <a href="https://github.com/WICG/interventions/issues/18#issuecomment-250315841">commented on Sep 29, 2016</a>:</p>

<blockquote>
  <p>Given the huge positive response <a href="https://www.youtube.com/watch?v=NPM6172J22g">that video</a> has gotten from users, we’re willing to accept a little bit of hacks / compat pain here.</p>
</blockquote>

<p>mixonic <a href="https://github.com/WICG/interventions/issues/18#issuecomment-279194353">commented on Feb 12</a>:</p>

<blockquote>
  <p>The video in question as 14k views and 36 “thumbs up”. I really, really hope this isn’t being used to make a decision about whether this intervention is appropriate.</p>
</blockquote>

<p>RByers <a href="https://github.com/WICG/interventions/issues/18#issuecomment-280532958">commented on Feb 17</a>:</p>

<blockquote>
  <p>We really don’t have more than anecdote (and our metrics) on the “support” side, and no precise way to quantify the breakage. I’d love to have a more quantifiable way to make these sorts of trade offs.</p>
</blockquote>

<p>RByers <a href="https://github.com/WICG/interventions/issues/18#issuecomment-279163417">commented on Feb 11</a>:</p>

<blockquote>
  <p>So far we’ve gotten a ton of feedback that users care about this.</p>
</blockquote>

<p>RByers linked to <a href="https://twitter.com/RickByers/status/719736672523407360">this tweet</a> with exactly 6 responses:</p>

<blockquote>
  <p><a href="https://twitter.com/adslaton/status/726094587056541699">adslaton</a>: thank you for the demo against our site. We will take a look at what you have documented and apply updates.</p>
</blockquote>

<blockquote>
  <p><a href="https://twitter.com/adamdbradley/status/719739381704040448">adamdbradley</a>: how did you do that test to see the differences?</p>
</blockquote>

<blockquote>
  <p><a href="https://twitter.com/jordwalke/status/720073223430217729">jordwalke</a>: I strongly, but super-respectfully suggest against this. It masks serious issues. I do not believe this is how the web wins.</p>
</blockquote>

<blockquote>
  <p><a href="https://twitter.com/rickbiastwit/status/832399971026505729">rickbiastwit</a>: and it’s not cool to break tons of drag/drop, scroll/zoom browser default behaviour prevention only to achieve nearly nothing</p>
</blockquote>

<blockquote>
  <p><a href="https://twitter.com/rickbiastwit/status/832399551847804928">rickbiastwit</a>: chrome scroll intervention demo is definitely misleading. I tried on top end devices, no perceivable difference, enabled or not.</p>
</blockquote>

<p>If you call it “a ton of positive feedback”, well, khm, you definitely see a reality in a different light.</p>

<h2 id="a-moral">A moral</h2>

<ul>
  <li>Web APIs aren’t pretty.</li>
  <li>There’s no “clean” way of using DOM APIs. Even freshly designed, freshly released features <em>require</em> you to rely on hacks for feature detection.</li>
  <li>Libraries wouldn’t simply “abstract away” all the unpleasant details of the underlying experience. E.g. React still <a href="https://github.com/facebook/react/issues/6436">has no way</a> to force event listeners not being passive.</li>
  <li>Making code work in older browsers is an easy task because older browsers do not change. Once hacks are implemented for them, they’ll continue to work forever.</li>
  <li>Code that works for you right now might stop working in <em>future</em> browsers. Constant effort is required maintaining your code against changes browser vendors drop on you.</li>
  <li>Breaking changes might happen pretty fast. Current version of Chrome is 62. Your code might being broken by the time Chrome 67 arrives. It almost certainly wouldn’t work in Chrome 100.</li>
  <li>Browser vendors have their own agenda. It mostly includes making their browsers look fast, sometimes at the cost of your websites become broken.</li>
</ul>

<p>RByers <a href="https://github.com/WICG/interventions/issues/18#issuecomment-278658295">commented on Feb 9</a>:</p>

<blockquote>
  <p>But in Chrome we’re fundamentally unwilling to allow the mobile web to continue to die from performance bankruptcy. Other browsers are less aggressive, and people who prefer to be more conservative (preferring maximal compatibility over being part of moving the web forward aggressively) should prefer to use a more conservative browser.</p>
</blockquote>

<p>As a user, I certainly do not care about “being part of moving the web forward aggressively”. Why should I? I like my stuff working, not broken. Nobody ever wants it the other way around.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>You don’t want many options</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/options/" />
      <id>https://tonsky.me/blog/options/</id>
      <published>2017-09-17T00:00:00+00:00</published>
      <updated>2017-09-17T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Don’t get excited about libraries that offer many options
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>A nice little library came up the other day: <a href="https://github.com/tolitius/cprop"><code class="highlighter-rouge">cprop</code></a>. Simply put, it’s a swiss army knife of configuration management: it can load configs from classpath, files, DB or environment, it merges configs, provides defaults, does type coercion etc.</p>

<p>Should you use it? It’s easy to say yes, but I say no.</p>

<h2 id="yes-path">“Yes” path</h2>

<p>Choosing something like <code class="highlighter-rouge">cprop</code> is usually a no-brainer. After all, you need <em>something</em> to manage configs, and library like that is obviously future-proof. If you don’t need everything at the start, you might decide to use it <em>just</em> for simple things like port numbers and <em>only</em> load them from the environment and nothing more. Using existing library is still better than rolling your own solution.</p>

<p>But projects are long endeavors. Somewhere down the road, you might have a situation: a demand will come up that is most easily addressed by using some other part of <code class="highlighter-rouge">cprop</code>. What would you do?</p>

<p>Let’s see: <code class="highlighter-rouge">cprop</code> is already in the project, it has the perfect solution, its authors already made all the design decisions and implemented all the code which is just sitting there, waiting, ready to be used. Using more of <code class="highlighter-rouge">cprop</code> <em>at that point</em> will be the absolutely rational, most effective decision you can make.</p>

<p>The downside though is that eventually you’ll end up with a really complex configuration system. It’s nobody’s fault, it’s just how project dynamics work.</p>

<h2 id="no-path">“No” path</h2>

<p>Alternatively, if you choose a much more focused library or decided to roll your own minimal solution, when that demand comes up there’ll be nothing to address it.</p>

<p>This moment is important: you’ll realize that making config more complicated is <em>not free</em> anymore. Because of that, you might decide not to extend your configuration system but build a workaround or introduce a convention. Your config might, as a result, stay simple.</p>

<p>This is backpressure: your home-grown configuration system <em>resists</em> being extended, and <em>it’s a good thing</em>. It keeps you from turning everything into a complicated mess or at least postpones that moment. Value it. Look for ways to restrain complexity creep and don’t get excited about the plethora of options.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
  
  
    <entry>
      <title>Readable Clojure</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/readable-clojure/" />
      <id>https://tonsky.me/blog/readable-clojure/</id>
      <published>2017-05-24T00:00:00+00:00</published>
      <updated>2017-05-24T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Some advices to writing Clojure code
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <style>
	.osx { height: 371px; }
	.osx > img { border-radius: 5px; }
</style>

<p>This is how you can make Clojure code more pleasant to work with:</p>

<ul>
  <li><a href="#dont-use-use">Don’t use “use”</a></li>
  <li><a href="#use-consistent-unique-namespace-aliases">Use consistent, unique namespace aliases</a></li>
  <li><a href="#use-long-namespace-aliases">Use long namespace aliases</a></li>
  <li><a href="#choose-readabilityover-compactness">Choose readability over compactness</a></li>
  <li><a href="#dont-rely-on-implicit-nil-to-false-coercion">Don’t rely on implicit nil-to-false coercion</a></li>
  <li><a href="#avoid-higher-order-functions">Avoid higher-order functions</a></li>
  <li><a href="#dont-spare-names">Don’t spare names</a></li>
  <li><a href="#dont-use-firstsecondnth-to-unpack-tuples">Don’t use first/second/nth to unpack tuples</a></li>
  <li><a href="#dont-fall-for-expanded-opts">Don’t fall for expanded opts</a></li>
  <li><a href="#use--as-prefix-for-references">Use * as prefix for references</a></li>
  <li><a href="#align-let-bindings-in-two-columns">Align let bindings in two columns</a></li>
  <li><a href="#use-two-empty-lines-between-top-level-forms">Use two empty lines between top-level forms</a></li>
</ul>

<h2 id="dont-use-use">Don’t use “use”</h2>

<p>And don’t <code class="highlighter-rouge">:refer</code> anything either. Every var you bring from another namespace should have a namespace qualifier. Makes it easier to track vars to their source.</p>

<figure class="osx"><img src="use.gif" /></figure>

<p>You’ll also save yourself from name collisions down the way.</p>

<h2 id="use-consistent-unique-namespace-aliases">Use consistent, unique namespace aliases</h2>

<p>If you gave namespace an alias, stick to it. Don’t require</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[clojure.string :as str]
</code></pre></div></div>

<p>in one file but</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[clojure.string :as string]
</code></pre></div></div>

<p>in another.</p>

<p>That way you’ll be able to actually remember your aliases. Oh, and <code class="highlighter-rouge">grep</code> starts to work.</p>

<figure class="osx"><img src="aliases_1.gif" /></figure>

<p>Keep aliases unique too. If <code class="highlighter-rouge">d/entity</code> could mean both <code class="highlighter-rouge">datomic.api/entity</code> or <code class="highlighter-rouge">datascript.core/entity</code>, you lose all the benefits of this rule.</p>

<figure class="osx"><img src="aliases_2.gif" /></figure>

<h2 id="use-long-namespace-aliases">Use long namespace aliases</h2>

<p>Aliases should be readable on their own. Therefore</p>

<ul>
  <li>don’t use single-letter aliases,</li>
  <li>don’t be clever or inventive,</li>
  <li>when shortening, only remove the most obvious parts (company prefix, project name, <code class="highlighter-rouge">clojure.*</code>, <code class="highlighter-rouge">core</code> suffix etc),</li>
  <li>leave everything else intact:</li>
</ul>

<figure class="osx"><img src="long_aliases.gif" /></figure>

<p>Now you can read your code starting from any place and don’t have to remember what maps to what. Compare</p>

<figure class="osx"><img src="short_aliases_1.gif" /></figure>

<p>with</p>

<figure class="osx"><img src="short_aliases_2.gif" /></figure>

<p>The former looks terser, but it’s hard to tell what’s going on. The latter is a bit longer but immediately communicates which systems are in play.</p>

<p>Another benefit: you’ll naturally tend to use aliases less often if they are long and clumsy, so long aliases will force you to organize your code better.</p>

<h2 id="choose-readabilityover-compactness">Choose readability over compactness</h2>

<p>Clojure has a plethora of ways to write dense code. Don’t use them just because they are there. Always put readability and code clarity first. Sometimes it means even going against Clojure idioms.</p>

<p>An example. To understand this piece of code you need to know that <code class="highlighter-rouge">possible-states</code> is a set:</p>

<figure class="osx"><img src="set_1.gif" /></figure>

<p>By contrast, to understand following code you don’t need any context:</p>

<figure class="osx"><img src="set_2.gif" /></figure>

<p>Also, notice how the latter reads almost like plain English.</p>

<p>My (incomplete) set of personal rules:</p>

<ul>
  <li>use <code class="highlighter-rouge">contains?</code> instead of using sets as functions,</li>
  <li>use <code class="highlighter-rouge">get</code> instead of using map as a function,</li>
  <li>prefer <code class="highlighter-rouge">(not (empty? coll))</code> over <code class="highlighter-rouge">(seq coll)</code>,</li>
  <li>explicitly check for <code class="highlighter-rouge">nil?</code>/<code class="highlighter-rouge">some?</code> (more on that below).</li>
</ul>

<h2 id="dont-rely-on-implicit-nil-to-false-coercion">Don’t rely on implicit nil-to-false coercion</h2>

<p>Unfortunately, Clojure mixes two very different domains: nil/existence checking and boolean operations. As a result, you have to constantly guess author’s intents because they’re not expressed explicitly in the code.</p>

<p>I advise using real boolean expressions and predicates in all boolean contexts. Explicit checks are easier to read and communicate intent better. Compare implicit</p>

<figure class="osx"><img src="nil_1.gif" /></figure>

<p>and explicit</p>

<figure class="osx"><img src="nil_2.gif" /></figure>

<p>The more serious reason is that nil-as-false idiom fails when you want <code class="highlighter-rouge">false</code> to be a possible value.</p>

<figure class="osx"><img src="nil_3.gif" /></figure>

<p>Problems like this are common when working with boolean attributes/parameters and default values.</p>

<p>Some advice to follow:</p>

<ul>
  <li>wrap plain objects with <code class="highlighter-rouge">some?</code> in <code class="highlighter-rouge">when</code>/<code class="highlighter-rouge">if</code>,</li>
  <li>prefer <code class="highlighter-rouge">when-some</code>/<code class="highlighter-rouge">if-some</code> over <code class="highlighter-rouge">when-let</code>/<code class="highlighter-rouge">if-let</code>,</li>
  <li>be careful with <code class="highlighter-rouge">or</code> when choosing a first non-nil value,</li>
  <li>for <code class="highlighter-rouge">filter</code>/<code class="highlighter-rouge">remove</code> predicates, provide proper boolean values through <code class="highlighter-rouge">some?</code>/<code class="highlighter-rouge">nil?</code>.</li>
</ul>

<h2 id="avoid-higher-order-functions">Avoid higher-order functions</h2>

<p>I found code that builds functions with <code class="highlighter-rouge">comp</code>, <code class="highlighter-rouge">partial</code>, <code class="highlighter-rouge">complement</code>, <code class="highlighter-rouge">every-pred</code>, <code class="highlighter-rouge">some-fn</code> to be hard to read. Mainly because it <em>looks different</em> from the normal function calls: no parens, application order is different, you can’t see arguments.</p>

<p>It requires effort to figure out what exactly will happen:</p>

<figure class="osx"><img src="fn_1.gif" /></figure>

<p>Even as experienced Clojure programmer I haven’t developed a skill to parse such structures easily.</p>

<p>What I find easy to read, though, is anonymous function syntax. It looks exactly like a normal function call, you can see where parameters go, what’s applied after what — it’s instantly familiar:</p>

<figure class="osx"><img src="fn_2.gif" /></figure>

<h2 id="dont-spare-names">Don’t spare names</h2>

<p>Some facilities in Clojure (threading macros, anonymous functions, destructuring, higher-order functions) were designed to let you skip <em>names</em>:</p>

<figure class="osx"><img src="names_1.gif" /></figure>

<p>This is great but sometimes impedes readability. Without names, you are forced to keep all the intermediate results in your head.</p>

<p>To avoid that, add meaningful names where they could be omitted:</p>

<figure class="osx"><img src="names_2.gif" /></figure>

<p>You <em>can</em> omit names in threading macros (<code class="highlighter-rouge">-&gt;</code>, <code class="highlighter-rouge">-&gt;&gt;</code> etc) but only if object/objects passed through do not change their type. Most cases of filtering, removing, modifying elements in a collection are fine.</p>

<p>E.g. here because it’s still users all the way until the end, intermediate names can be omitted:</p>

<figure class="osx"><img src="names_3.gif" /></figure>

<h2 id="dont-use-firstsecondnth-to-unpack-tuples">Don’t use first/second/nth to unpack tuples</h2>

<p>Although this works:</p>

<figure class="osx"><img src="tuples_1.gif" /></figure>

<p>you’re missing an opportunity to use destructuring to</p>

<ul>
  <li>improve readability,</li>
  <li>assign names to tuple elements</li>
  <li>and show the shape of the data:</li>
</ul>

<figure class="osx"><img src="tuples_2.gif" /></figure>

<h2 id="dont-fall-for-expanded-opts">Don’t fall for expanded opts</h2>

<p>The expanded opts idiom does only two things:</p>

<ul>
  <li>it is extremely cool,</li>
  <li>and it saves you two curly brackets at the call site.</li>
</ul>

<figure class="osx"><img src="opts_1.gif" /></figure>

<p>The downsides are much more serious. <code class="highlighter-rouge">start</code> will be extremely painful to call if you construct map of options dynamically or if you need to do it through <code class="highlighter-rouge">apply</code>:</p>

<figure class="osx"><img src="opts_2.gif" /></figure>

<p>Because of that, I recommend to always accept options as a map:</p>

<figure class="osx"><img src="opts_3.gif" /></figure>

<h2 id="use--as-prefix-for-references">Use * as prefix for references</h2>

<p>References and their content are different, so they need different names. At the same time, they are not <em>that</em> different to invent unique combination of names each time.</p>

<p>I suggest simple convention: prepend <code class="highlighter-rouge">*</code> (star) to reference names.</p>

<figure class="osx"><img src="refs.gif" /></figure>

<p>The star was chosen because it resembles C/C++ pointers.</p>

<h2 id="align-let-bindings-in-two-columns">Align let bindings in two columns</h2>

<p>Compare this:</p>

<figure class="osx"><img src="let_1.gif" /></figure>

<p>to this:</p>

<figure class="osx"><img src="let_2.gif" /></figure>

<p>I do it by hand, which I consider to be a small price for readability boost that big. I hope your autoformatter can live with that.</p>

<h2 id="use-two-empty-lines-between-top-level-forms">Use two empty lines between top-level forms</h2>

<p>Put two empty lines between functions. It’ll give them more space to breathe.</p>

<figure class="osx" style="height: 750px"><img src="space.gif" /></figure>

<p>Seems unimportant, but trust me: once you try it, you’ll never want to go back.</p>


      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Blind Spot in Dependency Management</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/blind-spot-in-dependency/" />
      <id>https://tonsky.me/blog/blind-spot-in-dependency/</id>
      <published>2016-07-01T00:00:00+00:00</published>
      <updated>2016-07-01T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Why changelogs are important and how come we don’t talk about it
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>Let’s talk about one overlooked aspect of dependency management.  I know what you would say, wait a minute, dependency management, the whole domain is a trivial problem that tricks everybody into overthinking overcomplicated solutions.</p>

<p>And I’d agree with you. Not.</p>

<p>But that’s not the point. What worries me is that while a lot of effort goes into fetching the right version of a library, close to none is spent on convincing me <em>why</em> I should want it in the first place.</p>

<p>Some tools fail to even fulfill the first part of the promise and will only fetch you <em>some</em> version, effectively removing the second problem for you (if you don’t control what version you are getting you won’t be troubled choosing one).</p>

<p>Yet, some of us have slightly higher standards than that. Let’s assume that our tool is smart enough to fetch exactly what we’ve told it to. All is fine for a while, until, two years in a project, you ask yourself if something positive has happened with the libraries you started using back then. Maybe you’re lucky and your tool can even compile a list of outdated versions for you:</p>

<figure class="window"><img src="https://tonsky.me/blog/blind-spot-in-dependency/rss/lein_ancient.png" /></figure>

<p>But that’s not the problem. How do you decide, in each particular case, if you should type “yes” or “no” there? Guessing? Hard guessing? Is there a threshold? If you’re more than 3 minor versions behind, you upgrade, otherwise, you let it be? Scientifically controlled and totally fair coin toss?</p>

<p>Sometimes it’s easy. Don’t touch what’s working, they say. But you only think it is.</p>

<p>Say, you need a specific bug fixed, and people behind the library use an issue tracker, and you even happen to know the ticket id. Now, if that issue tracker is something punk and unpopular, like Github, strangely, it won’t help you at all. You can’t figure out in which version it was fixed given an issue or pull request id. Even if you’re a very responsible maintainer and do everything right. Lesson #1: don’t host your libraries on Github, kids.<a id="f1" href="#fn1" class="footnote">1</a></p>

<p>Luckily, solid time-tested full-package solutions like JIRA give you a “fix version” number (if you can find it on issue page). Problem is, you can’t <em>just</em> upgrade to that version. You bug was fixed in 4.7.8, you’re on 4.3.2, god knows <em>what else</em> will that upgrade bring.<a id="f2" href="#fn2" class="footnote">2</a> If I were you, I’d pass on that. I once tried to bump AWS client from 1.8 to 1.10, and they renamed, like, every class inside. I’d rather start a new project from scratch than upgrade my libraries.</p>

<p>“That’s why JIRA can generate you a changelog!”</p>

<p>Can it?</p>

<figure><img src="https://tonsky.me/blog/blind-spot-in-dependency/rss/jira.jpg" /></figure>

<p>Sure it can. Good luck drilling through it. Also good luck finding out about changes people made outside of tickets.</p>

<p>“That’s why there’s a commit log!”</p>

<p>Is there?</p>

<figure><img src="https://tonsky.me/blog/blind-spot-in-dependency/rss/github.jpg" /></figure>

<p>It’d be better if there wasn’t. Thing is, many people treat commit log as an actual log. A diary of theirs. They will write down their life events, current mood, messages to team members, emoticons in there.<a id="f3" href="#fn3" class="footnote">3</a> You’ll be reading about all the wrong paths taken, bad merges and attempts to fix them (no, you don’t want to see a visual tree of git commits in an actively developed project), and, best of all, typos. It also appears they can’t hold it, and their commit rate might approach several commits per minute. Good luck filtering the noise out.<a id="f4" href="#fn4" class="footnote">4</a></p>

<p>Which leads us to the obvious answer: <em>Changelog!</em> Changelog. Pause right there and think for a second. What if there was a place specifically designed to communicate what has changed between releases? A changelog. The changelog.</p>

<p>I like reading changelogs! It’s like opening a present. Except when it’s a new version of OS X where biggest change is a new name and rest of the stuff I don’t use anyways. What’s the point of all that effort if my trackpad would reconnect to my macbook only after a hard reboot since 10.7? At least they used to freshen up UI before.</p>

<p>So changelogs are a good thing. And they already exist. People are doing them, right? Except when they aren’t.</p>

<p>That’s what concerns me. The lack of changelogs, and the lack of discussions about the lack of changelogs. I want to make conscious decisions about my project’s dependencies. I don’t want a pig in a poke. With my luck, I can’t rely on luck either.  I want to read, understand, track and evaluate every change until I’m like through 30 of them. Then I’ll blindly update rest of the libs and hope for the best anyways. But these 30, they are important. I want them to be quality changes. Is it too much to ask?</p>

<p>Sorry for so much ranting so far. Let me try to add some utility to this article and give an advice on good changeloggin:</p>

<p><em>Rule 1.</em> Good changelog is not a JIRA search page.</p>

<p><em>Rule 2.</em> Good changelog is not a commit log.</p>

<p><em>Rule 3.</em> It’s not a commit log on Github. Did I mention that Github is terrible for that kind of stuff?</p>

<p>Ok, all kidding aside.</p>

<p><em>Rule 4.</em> Put all the useful stuff in there. I know, sounds obvious, but you’d be surprised how often people don’t do that.</p>

<p><em>Rule 5.</em> Don’t put any useless stuff in there (also see Rule 4).</p>

<p><em>Rule 6.</em> If you move fast and break things, put breaking changes in the changelog and fix them in the next version (or not).</p>

<p><em>Rule 7.</em> Draw in bold strokes. Give a high-level overview. Put that in changelog too.</p>

<p><em>Rule 8.</em> Prioritize. Highlight important changes (hint: you can’t highlight every change). Do you know where you should put it?</p>

<p><em>Rule 9.</em> Have mercy. If you put people in a complicated situation with your changes, help them out. Provide a clear migration path.</p>

<p><em>Rule 10.</em> For controversy, explain your reasons (if you have them).</p>

<p><em>Rule 11.</em> Don’t overwhelm the reader. Imagine they have to upgrade from three-years-old version to the latest one (because it took you three years to fix that issue). Think about them, and cross your fingers they won’t find your email address.</p>

<p><em>Rule 12.</em> Advanced use only: give them reasons <em>not</em> to upgrade to that version.</p>

<p><em>Rule 13.</em> If you forget something, so be it. It comes without warranties, right?</p>

<p><em>Rule 14.</em> Have a changelog. This is probably the most important rule of them all. I just realized all other rules are meaningless without this one.</p>

<p><em>Rule 15.</em> Put it in your repo. Don’t post it in user group. Well, you can, but don’t <em>just</em> post it in user group. Three-years-old bug, remember?</p>

<p><em>Rule 16.</em> Call it <code class="highlighter-rouge">CHANGELOG</code> so people will know it’s important.</p>

<p>That’s it. Simple, right?</p>

<p>Dependency management software is pretty good. It is. You need to understand it (I know, totally unfair), but most of the time it gets the job done. Inside a single technology, people usually agree on version numbers, central repo, build tools—most of the technicalities.</p>

<p>What people don’t agree on is that every new version should come with a human-readable list of changes. Upgrading your stack shouldn’t be a blind game of luck. Maybe one day we’ll see a tool like <code class="highlighter-rouge">lein ancient</code> that will print you all the changes before asking you if you want to upgrade.<a id="f5" href="#fn5" class="footnote">5</a> And that list would be short, precise, well-written piece of poetry.</p>

<p>Not.</p>

<div class="footnotes-br"></div>

<ol class="footnotes">
<li id="fn1">Seriously, Github. Please figure that out. People try to use you for work stuff. People use versions. People need versions (except for Go folks, they gave up on them. They’re more than welcome to host on Github) <a href="#f1" class="">↩︎</a></li>
<li id="fn2">Where is your semantic versioning now, huh? <a href="#f2" class="">↩︎</a></li>
<li id="fn3">Nothing wrong with emoticons, of course. <a href="#f3" class="">↩︎</a></li>
<li id="fn4">Did I mentioned that Github won’t show you tags on commits page? Good luck figuring out when that release happened. <a href="#f4" class="">↩︎</a></li>
<li id="fn5">I know, I’m an idealist. People would never agree on a single format of anything, be it beer glass units, paper size or AC outlet. Unless it’s a cigarette lighter receptacle. Strangely enough, there’s only one standard for cigarette lighter receptacle in the world. <a href="#f5" class="">↩︎</a></li>
</ol>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>The Blessing of Interactive Development</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/interactive-development/" />
      <id>https://tonsky.me/blog/interactive-development/</id>
      <published>2016-04-11T00:00:00+00:00</published>
      <updated>2016-04-11T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          In this post I describe a couple of practice that makes the process of writing code faster, more predictable and straightforward
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <h2 id="how-do-you-write-code">How do you write code?</h2>

<p>We have plenty of literature on <em>what</em> code to write, but rarely you see a piece about the process of writing itself. Some might think it’s programmers’ own business and everybody is free to use whatever tools they like. I believe that writing process—what I use for writing, where do I start, which parts do I build in what order, all the little motions—in other words, the “getting there”—is as important as the end result. Writing habits have a direct impact on my performance and the code I produce. This is an area of software development that should be discussed, studied and trained as an important part of coding craftsmanship.</p>

<p>I like to reflect on how my own writing process has evolved over the years. It had periods of gradual improvement and moments of radical changes. From what you’re about to read, it’s not even obvious whether it improved at all—some moments might look like a step back. I can assure you that in practice I do feel a strong cumulative positive effect: after all, I work on much more complex things now compared to ten years ago, and I’m for sure doing more. Otherwise, judge for yourself.</p>

<h2 id="price-of-help">Price of help</h2>

<p>I started my career with Java and Java IDEs it was. The benefits IDEs advertise are of that kind where it’s hard to say no: they offer to spare you some pain (or, depending on a language, <em>a lot</em> of pain). And they deliver, no doubt about that. What they don’t tell you, and what is not as widely discussed, is <em>a catch</em> I started to notice only after five plus years of happy IDEing: there’s the dark side. As human mind works, if somebody or something helps you with a problem, you start to not see it as a problem. But the problem does not go away. You just lose the ability to see it.</p>

<p>When IDE mitigates the problem, you forget about it and that’s the moment when you lose the motivation to fight it. Huge codebase. Unnecessary code. Bad structure. Generated code you have no idea about. These problems are pretty serious, but they do not affect your nearest goals, we all have priorities, so you let them build up for a while. The problems are there, but you’ve lost the urge to fix them. Until, of course, it’s too late. Given the reality of software projects, good intentions and “knowing about it” do not help. What can help, what can generate enough motivation to keep your project in a good shape is the itch. You must feel the itch all the time. Paradoxically, harder working conditions push you towards better code.</p>

<p>Realizing all that, I concluded that IDE is a great tool to work with already rotten legacy projects, but a terrible aid to write new code.</p>

<h2 id="going-plain-text">Going plain text</h2>

<p>And I wanted to write new code. To clean up my mind, I took a break from IDE-driven development and moved to barehanded text editors: Vim, Textmate, Sublime Text. It’s hard to remember exact motivation for the change (lack of IDE for Erlang? Multiple languages in a project? Hardware too slow for IDEA?), but the value of it I see clearly in hindsight.</p>

<p>Working with program’s text directly, without an autopilot, lets you really feel what your program is made of. It makes you <em>aware</em>. A software project is not a big shapeless thing that let you accidentally type stuff inside anymore. You value each line—you’ve typed each line with your own hands. You know exactly what, where, when and why happens. You own every piece, without “I write this part, hope everything else will work OK too” attitude. You become less tolerant for unnecessary formalities, bloated abstractions, excess future proofing—all types of noise. Imagine turning on a bright light in a poorly lit room: what was hidden in the shadows stands out immediately. The first step to improvement is to see.</p>

<h2 id="interactive-development">Interactive development</h2>

<p>Now I’m in the era of interactive development. It builds on the fact that code we commit was not born in its final form—it was built, with trial and errors, via many iterations before it hit source control. Sound simple, but notice how little tools support code in transitional states, in spite of the fact that for developer code exists in a transitional state most of the time. The idea of interactive development is to enhance individual iterations so the resulting code will be born faster and with better quality. Following are the principles I’m using.</p>

<p><em>Build in small chunks.</em> You can’t solve anything but smallest bugs in a single try. If you write more than a couple of lines before actually running it, chances are they won’t work and you wouldn’t know why. Say hello to long debugging sessions, running around checking all sort of crazy hypotheses and trying to isolate parts to check them separately. This is backward. The straightforward way is to move in small steps: build a helper function, test it, see it works, then move on. It resembles test-driven development, but on a finer, often sub-function level: write a function declaration, check arguments are passed in right, write a loop, check it iterates, add regexp match, check it really matches. It doesn’t always mean bottom up development—you might start by adding stub interface and see if a system will adequately react to its presence. Just do a single small change, see if it works, then move on. Always check by actually running the code. Don’t try two changes at once.</p>

<p><em>Quick turn-around</em>. Testing each smallest change won’t be possible if it’d take more than a couple of seconds to run a piece of code and see results. There’re a couple of psychological limits at play: everything faster than ~100 ms human will <em>perceive</em> as immediate feedback, ~1–2 seconds is quick feedback, they feel latency but keep the attention, everything beyond that breaks attention and human will need to spend huge amount of time and effort to get back to the context they were in. For 10+ second delays, human will switch to another task altogether. Best tools will not let human lose their attention, otherwise, <em>the flow</em> gets broken and development time grows exponentially. There’s qualitative difference of development speed between systems with sub-second iteration time and systems with 2+ seconds iteration time. Funny enough, there’s not much difference between systems with 2 sec delay and 9 sec delay, or between 15 seconds and 3 minutes. It’s either really quick or “my code is compiling” and nothing gets done.</p>

<p><em>Keep the state</em>. Sounds a little bit utopian so far? Even if you can compile and run your whole project in a sub-second time, you’ll still need time to get the context right. You don’t run code in isolation, it needs particular system parts be hot and running, particular arguments prepared, stubs/fixtures (if you use them) initialized. This is where tests help—they let you <em>automate context preparation</em>. On the smaller sub-function scale, writing tests would be a waste of time, though. Tests are also no option when you work on something visual, like UI. This is the moment where you want to work in a live system. Some languages allow you to connect to working process and evaluate code there as you go (REPL). Nothing gets restarted, just create context once and work inside it as long as you need.</p>

<p><em>Don’t leave the editor</em>. This is the same “keep the context” argument, but applied to the developer. You write code in the editor, right? Switching to another window to test and see would be too expensive from attention preservation standpoint. It’s worse if you have to synchronize the content of the editor and the content of the REPL for example. Total waste of time. Instead, evaluate code and see results in the same place where you write it—in the editor. You’ll need a proper editor, of course.</p>

<p><em>Open the hood</em>. It would be simpler if everything consisted of small tightly isolated bite-size chunks. But it isn’t, and one day you’d need to work on a heavily integrated part of the system. Take some time and rework parts that will help you create context, write new code in small chunks and test it as you go. Just prepare the system to be worked from inside. If you can leave it in that state, the better, but sometimes you just do a couple of dirty hacks and revert them after you’re done with your code.</p>

<p>Here’s a quick video to give you an idea how interactive development might actually looks like, given the right tools and setup:</p>

<figure>
<iframe width="600" height="338" src="https://www.youtube.com/embed/XEMI5-MBgaM" frameborder="0" allowfullscreen=""></iframe>
(You can grab my LightTable skin <a href="https://github.com/tonsky/alabaster-lighttable-skin" target="_blank">here</a>)
</figure>

<p>What now? Even if you’re completely sold on the ideas, chances are you won’t be able to apply most of them immediately. My intention is to show you where to aim at and let you find your opportunities for yourself. Even if you can’t do everything, try to get as close as you can (e.g. unit tests + quick turnaround is pretty good, devtools console is a REPL, many compilers have fast compile times, etc). This is not an easy path, not a convenient path, not the most popular one, but I can assure you it’s worth it.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>The Web After Tomorrow</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/the-web-after-tomorrow/" />
      <id>https://tonsky.me/blog/the-web-after-tomorrow/</id>
      <published>2015-06-23T00:00:00+00:00</published>
      <updated>2015-06-23T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          This post looks at what is missing from the current state-of-the-art web architectures, where they should be improved and what tools we have at hand for that.
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p><em>Modern web does a good job of bringing you live, real-time web applications. Or does it? This post looks at what is missing from the current state-of-the-art web architectures, where they should be improved and what tools we have at hand for that.</em></p>

<h2 id="server-not-required">Server not required</h2>

<p>Traditional web architectures require DB, server and a browser, stitched together with RPC and REST calls:</p>

<figure><img src="https://tonsky.me/blog/the-web-after-tomorrow/rss/tradition.png" /></figure>

<p>But today’s JS is good at doing almost anything we traditionally expect from a server. JS can handle view logic (better than server ever could), JS has no problem talking to the DB, executing queries and parsing result sets.</p>

<p>You probably had this feeling already, when you write server code only to proxy client’s demands for the DB and pass the results back. It feels stupid. It feels redundant. All these trends — isomorphic code, compile-to-js languages, node.js — come from a desire to run the same code in two places. That very goal is wrong. You don’t <em>want</em> to run same code in two places. You may <em>need to</em>, but only to deal with the consequences of bad (old) architecture. Running exactly the same validation twice wouldn’t make data more valid.</p>

<p>UI apps used to talk directly to the DB. Then thin client was introduced; to support that, intermediate smart proxy, or server, was added to the web stack. Today clients are thick again, but we keep putting server in the middle. Just out of habit.</p>

<figure><img src="https://tonsky.me/blog/the-web-after-tomorrow/rss/evolution.png" /></figure>

<p>No, eventually DB will talk directly to the browser. Software may not be there yet, but it’s a matter of time. Until then, remember: it’s the server that is a generic component now, not the browser. Client logic is in control. JS gives orders, server/DB follows them.</p>

<h2 id="always-late">Always late</h2>

<p>Even though we can get rid of the server and handle everything in a browser, we’ll still be in the era of an ad-hoc, inconsistent, always-late web apps.</p>

<p>Take a look at the main Facebook page:</p>

<figure><img src="https://tonsky.me/blog/the-web-after-tomorrow/rss/facebook.png" /></figure>

<p>If you keep this page open for a couple of minutes, you’ll notice that different parts of it have different age. Some are static, they never update unless you refresh the page. Some are updated almost instantly. Some are refreshed periodically. Even when you look at the same data piece (e.g. user name) across the page, it can look different in different places, depending on how long ago the component containing it was last updated. Facebook is a modern, cutting-edge web app, but even it is not real-time enough. Every Facebook page is stale and inconsistent almost all the time except for the couple of seconds right after page load. This is not about Facebook, of course, every other page of every other web application is stale, too. Despite the buzz, the real-time web has not landed yet.</p>

<p>Some may argue if that needs to be fixed at all. I’m OK to refresh page once in a while. I don’t change user name that often. We love Facebook for the people and can bear couple of technology quirks.</p>

<p>I agree. For vast majority of people, it might be not the most pressing problem at the moment. But what people are used to is always a bad measure. If people have learned to adapt to something does not imply we should stop looking for improvements. Looking into crazy and seems-to-be-unreachable places might still give us useful insights.</p>

<p>Web technology stack was created under assumption that people are looking at rarely-changing, mostly static data. Generally it does a decent job of loading missing data pieces as you go. Throw in AJAX/WebSockets and periodical updates and best you’ll get is a web page stitched from the pieces of data at different stages of staleness. It’s expected. This result comes naturally from using HTTP, JS, SQL, REST the most natural way. To get beyond that, we need to forget what we’ve learned about them. We need to avoid short and well-known paths. We should not fear to do the unnatural things.</p>

<p>What we actually want is not even a request-response protocol. At the high level we want to connect data source and a client as tight as possible, with the library taking care of all the negotiation details. These are the things we are interested in:</p>

<ul>
  <li>
    <p>Consistent view of the data. What we’re looking at should be coherent at some point-in-time moment. We don’t want patchwork of static data at one place, slightly stale at another and fresh rare pieces all over the place. People percieve page as a whole, all at once. Consistency removes any possibility for contradictions in what people see, consistent app looks <em>sane</em> and builds trust.</p>
  </li>
  <li>
    <p>Always fresh data. All data we see on the client should be relevant right now. Everything up to the tiniest detail. Ideally including all resources and even code that runs the app. If I upload a new userpic, I want it to be reloaded on all the screens where people might be seeing it at the moment. Even if it’s displayed in a one-second-long, self-disposing notification popup.</p>
  </li>
  <li>
    <p>Instant response. UI should not wait until server confirms user’s actions. Effect of the action should be displayed immediately.</p>
  </li>
  <li>
    <p>Handle network failures. Networks are not a reliable communication device, yet reliable protocols can be built on top of them. Network failures, lost packets, dropped connections, duplicates should not undermine our consistency guarantees.</p>
  </li>
  <li>
    <p>Offline. Obviously data will not be up-to-date, but at least I should be able to do local modifications, then merge changes when I get back online.</p>
  </li>
  <li>
    <p>No low-level connection management, retries, deduplication. These are tedious, error-prone details with subtle nuances. App developers should not handle these manually: they will always choose what’s easier or faster to implement, sacrificing user experience. Underlying library should take care of the details.</p>
  </li>
</ul>

<p>These are all worthy goals irrespective of their technical feasibility. In the coming decades we might have, and we might have not see some of them studied, implemented or even becoming industry standard. We’ll probably see many failed and (I hope) some successful attempts to approach them. Nevertheless, the goals will stay the same.</p>

<p>The rest of this post is a speculation on where to start the quest for the Holy Grail of the Web. I don’t have all the answers. And (spoiler alert) I don’t know how to make Facebook straight-out real-time. But we have to start somewhere.</p>

<h2 id="the-quest-for-the-holy-grail-of-the-web">The Quest for the Holy Grail of the Web</h2>

<p>This is the high-level overview of the problem as I see it:</p>

<figure><img src="https://tonsky.me/blog/the-web-after-tomorrow/rss/filters.png" /></figure>

<p>The big data source on the top is all the data we have in the project. Before reaching the client, it must come through two filters. First one is a security filter. It filters out all the data user is not authorized to see, leaving out just personal, shared and public rows. The second filter leaves only the parts user is interested in. For UI it means parts which are required to render current page.</p>

<p>Everything that passes these two filters should be pushed to the client instantly, in real time. It is, by definition, everything client needs to render a page.</p>

<p>There are two tricks here. First one is efficiency. Web pages are usually pretty complex, they may track hundreds of different objects, they may track results of complex queries, they may track aggregations. And we might have thousands of live clients connected at the same time.</p>

<p>This is the most unexplored part of the Future Web landscape. You’re probably used to describe data needs in terms of queries. Query is a recipe to get the data from the storage. To get real-time, we need these queries to work the other way around. Client still defines its needs via query. This query might be used for initial data fetch, just as usual. The same query will then be used to filter whole-DB changelog and decide what parts of it server should push to which client. Fetch is about trying to get the data given the query. Push is about finding the affected subscriptions given the changed data.</p>

<figure><img src="https://tonsky.me/blog/the-web-after-tomorrow/rss/subscriptions.png" /></figure>

<p>What we need here is probably a new query language, something like reversible SQL. We need our hypothetical ReversibleQL to run efficiently in both directions. To get these properties, ReversibleQL would probably have to be much simpler and more limiting than SQL. Or it might be two different languages. I don’t know.  Meteor.js solves this problem by limiting subscriptions to documents and collections only. RethinkDB folks are trying to build <a href="http://rethinkdb.com/blog/realtime-web/">transparently reversible queries</a>, but they aren’t very chatty about internal details. I used to work in a startup that delivered real-time query results to power comments for ESPN, WWE, CNN, Scripps and Washington Post. I wouldn’t say it was a walk in the park, we had to build a custom infrastructure for that, but it was certainly doable on a scale of 50K RPS and varied, user-specified, non-trivial queries. We just need something open-source like that.</p>

<p>The second catch is that filters and subscriptions change over time. This is not a performance problem (usually), but more of an organizational one. How do you track subscriptions? How to detect dead ones and how to collect garbage? On a client we can benefit from a insufficiently praised React feature: component lifecycles. By listening for <code class="highlighter-rouge">didMount</code> and <code class="highlighter-rouge">willUnmount</code> we can reliably track when components (and their subscriptions) come and go. That way we always know exactly what our visitor is looking at. On a server, though, it’s just timeouts, refcounting, periodic cleaning and careful coding. No rocket science here.</p>

<p>While we’re still in “DB to client” data flow, let’s talk reliability. Real-time is fine, but reliable real-time is even finer. There’s little point in pushing data changes if you can underdeliver some of them: the outcome wouldn’t be that great without consistency. A single DELETE lost from changefeed during reconnect (with no integrity validation) might lead to the catastrophic UI glitches. Reordering is out of question too, for the same reasons. This is a territory of distributed databases here, where browser plays the role of one of the peers. For example, DB could provide a strongly consistent event log, and <nobr>DB-client</nobr> synchronization protocol can take advantage of that. Or we might choose eventual consistency, CRDTs and anti-entropy measures. Anyway, distributed computing is pretty crowded these days, let’s assume we know how to do it well. Browser is not traditionally viewed as a peer (CouchDB is moving in that direction though), but in fact it doesn’t change a thing. Only this time netsplits are more than real — they are everyday routine.</p>

<p>Now we’ve talked about listening for the changes, but not about initiating them. Of course, every local action should be captured, transformed into a change/delta, put into some sort of a queue and sent to the server in the background. Easy even with the current web stack.</p>

<p>Missing spots here are lag compensation and offline work. Nothing beats unresponsive input in the amount of annoyance and frustration it causes. The Net is so slow we should compensate for the roundtrip even if person is online and has a good connection. That’s why we display effects of all user actions immediately, <em>before</em> sending them to the server.</p>

<p>Offline is a special case of lag compensation where lag is infinite. Offline mode should look just like a normal app without real-time updates. No need to treat it any different: we just embrace that deltas queue could grow indefinitely and make process of making local changes sustainable.</p>

<p>Centralized, application-wide state management is crucial here. I cannot imagine how something like this could be implemented ad-hoc, on a per-variable basis. But if you treat all your app state like some kind of storage (e.g. Relay storage, nested immutable dictionary or DataScript DB), you can implement synchronization on a system level. You would also need explicit change management to send deltas over network, track them, conserve in local storage and apply them to the local state.</p>

<h2 id="pragmatic-disenchantment">Pragmatic disenchantment</h2>

<p>This is more of a “get you into the right mode of thinking” post. I don’t know any apps based on such architecture, I don’t even have a proof-of-concept example. There’s no ready-made framework to take off the shelf. Two years ago you would even have had a bad time assembling such a thing by yourself because there were no software with required properties.</p>

<p>These days it’s not that grim though:</p>

<ul>
  <li>
    <p>We have RethinkDB aiming at the same goal, but lacking client-side storage and reliable pushes.</p>
  </li>
  <li>
    <p>We have Relay which has local storage and lag compensation, but no real-time pushes from the server (they are thinking about adding them in the future).</p>
  </li>
  <li>
    <p>Meteor.js gets closer of them all: it solves discussed problem for a simple case of small unordered collections of JSON documents. It has latency compensation, local storage, server push, subscriptions, server data filtering. I can’t find any information about consistency and reliability guarantees of their <a href="https://atmospherejs.com/meteor/ddp">DDP protocol</a> or how well server push scales with the number of subscriptions.</p>
  </li>
</ul>

<p>I personally see a great opportunity in using Clojure, Datomic and DataScript to build such a system:</p>

<figure><img src="https://tonsky.me/blog/the-web-after-tomorrow/rss/architecture.png" /></figure>

<ul>
  <li>
    <p>Datomic is a general-purpose DB which also maintains a log of all transactions. Monotonic transaction ids make reliable syncing an easy task (log replication).</p>
  </li>
  <li>
    <p>Datomic has reactive transactions queue which is part of a public API, meaning efficient reactive pushes without polling or replication log parsing.</p>
  </li>
  <li>
    <p>Datomic has RDF-like data model (datom = entity, attribute, value) which is at a great granularity level for security and subscription filters. Datom is the smallest piece of information that could be synchronized, and that’s exactly what Datomic DB is made of.</p>
  </li>
  <li>
    <p>On a client we have DataScript which mimics Datomic API, so essentially it’s the same database, with the same data model, and the two work very well together.</p>
  </li>
  <li>
    <p>Datomic and DataScript have serializable <a href="http://tonsky.me/blog/datomic-as-protocol/">transaction format</a>, no need to invent anything ad-hoc to represent the deltas.</p>
  </li>
  <li>
    <p>DataScript is immutable, meaning we can keep local changes, apply/retract them, reorder, throw away and build temporary local databases on the fly. This property is very basic for DataScript because of its immutable nature, meaning there are no hidden limitations or partial support for some sort of changes.</p>
  </li>
  <li>
    <p>Reactive UI is simple over DataScript with top-down React render. If your UI is big and complex and needs granular updates based on what have changed in a DB, it’s also pretty straightforward, although there is no ready-made library for that at the moment.</p>
  </li>
  <li>
    <p>Subscription language is the biggest missing piece of this stack. Datomic and DataScript speak Datalog which is very powerful language, but it is hard to reverse efficiently. If you have very high volume of the transactions going through your DB, for each of them you’ll have to determine which clients should get an update. Running a Datalog query per client is not an option.</p>
  </li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>The web is only as good as current generation of tools for building it are. The right tools come from the right goals. As I see it, eventually web will work by the fully reactive principles. This post lays out the map of unsolved problems and discusses possible approaches to them.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>A shallow dive into DataScript internals</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/datascript-internals/" />
      <id>https://tonsky.me/blog/datascript-internals/</id>
      <published>2015-02-23T00:00:00+00:00</published>
      <updated>2015-02-23T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          An overview of DataScript code base, what’s there and how it’s structured
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>This is an overview of <a href="https://github.com/tonsky/datascript">DataScript code base</a>. Without going into much detail, it paints the overall picture of how code is structured, what parts it’s built of and what purpose they serve. If you’re interested in studying DataScript sources, this is a great place to start.</p>

<p>For those who are using DataScript this post may help to get better understanding of machinery behind public APIs and make better use of them.</p>

<h2 id="datoms">Datoms</h2>

<p>Minimal piece of information in DataScript is Datom. It’s defined in <code class="highlighter-rouge">datascript.core</code> as</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(defrecord Datom [e a v tx added])
</code></pre></div></div>

<p>where <code class="highlighter-rouge">[e a v]</code> is entity, attribute and value, <code class="highlighter-rouge">tx</code> is a transaction id (integer) and <code class="highlighter-rouge">added</code> is a boolean flag to differentiate additions from retractions.</p>

<p>Datom has <code class="highlighter-rouge">(-hash)</code> and <code class="highlighter-rouge">(-eqiv)</code> methods overloaded so only <nobr><code>[e a v]</code></nobr> take part in comparisons. It helps to guarantee that each datom can be added to the database only once.</p>

<h2 id="db">DB</h2>

<p>Database is just an immutable, persistent collection of datoms. It’s very much like a built-in ClojureScript data structure, e.g. set. Main operations supported by DB are:</p>

<ul>
  <li>Add a datom (similar to <code class="highlighter-rouge">conj</code>)</li>
  <li>Retract a datom (similar to <code class="highlighter-rouge">disj</code>)</li>
  <li>Search for range of datoms</li>
</ul>

<p>Both addition and retraction are implemented in <code class="highlighter-rouge">datascript.core/with-datom</code>. Searching is implemented as a part of <code class="highlighter-rouge">ISearch</code> protocol.</p>

<p>DataScript DB contains only currently relevant datoms. There’s no history tracking at DB level. When datom is removed from a DB, there’s no trace of it anywhere. Retracted means gone.</p>

<p>Internally DB contains three different indexes to help with various search patterns. Each index is a sorted set of datoms (it’s literally a set). They’re named after sort order: <code class="highlighter-rouge">EAVT</code>, <code class="highlighter-rouge">AEVT</code> and <code class="highlighter-rouge">AVET</code>. Every index contains all datoms of current DB, meaning all three indexes are the same set sorted differently. There’s no other datoms storage inside the DB besides indexes.</p>

<p>DB is defined in <code class="highlighter-rouge">datascript.core</code> as</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(defrecord DB [schema
               eavt aevt avet
               max-eid
               max-tx
               rschema])
</code></pre></div></div>

<p>Besides indexes, there’s only schema (just a regular map) and some internal bookkeeping: max seen entity id, latest transaction id and reverse value-to-key schema map.</p>

<h2 id="btset">BTSet</h2>

<p>Each DataScript index is stored as <code class="highlighter-rouge">datascript.btset</code>. It’s an immutable, persistent implementation of B+ tree data structure. It’s a proper ClojureScript collection, with all protocols of <code class="highlighter-rouge">sorted-set</code> implemented.</p>

<p><code class="highlighter-rouge">BTSet</code> was needed because DataScript does a lot of range scans over indexes. Due to usage of continuous js arrays as tree nodes, range scans over <code class="highlighter-rouge">BTSet</code> are ~3 times faster than over built-in <code class="highlighter-rouge">sorted-set</code> which is a Red-Black binary tree.</p>

<p><code class="highlighter-rouge">BTSet</code> uses generative testing to validate its correctness: same operations are performed at <code class="highlighter-rouge">BTSet</code> and <code class="highlighter-rouge">sorted-set</code>, results are compared for equality (see <code class="highlighter-rouge">stresstest-...</code> in <code class="highlighter-rouge">datascript.test.btset</code>).</p>

<h2 id="adding-data-to-db">Adding data to DB</h2>

<p>DataScript has a lot of conventions about how to format data before adding it to the DB. Basically, you can provide vector of form <nobr><code>[op e a v]</code></nobr> or a map of form <nobr><code>{:db/id e, (a v)+}</code></nobr>. There’s also a lot of nuances like resolving temporary ids, calling <code class="highlighter-rouge">:db.fn/*</code> shortcuts, referencing current transaction id, using nested maps for components, understanding different attributes arity and reversing reverse references.</p>

<p>Biggest part of <code class="highlighter-rouge">datascript.core</code>, starting from <code class="highlighter-rouge">(defrecord TxReport)</code>, is all about solving these problems. Main work happens in <code class="highlighter-rouge">transact-tx-data</code>, which uses recursion to reduce complexity of transaction data step-by-step, until it’s reduced to a set of plain datoms:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>entity map → op vector[s] → id resolution → datom[s]
</code></pre></div></div>

<p><code class="highlighter-rouge">transact-tx-data</code> loop also builds <code class="highlighter-rouge">TxReport</code> record along the way:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(defrecord TxReport [db-before
                     db-after
                     tx-data
                     tempids
                     tx-meta])
</code></pre></div></div>

<p><code class="highlighter-rouge">TxReport</code> is a log of everything that has happened during transaction. It stores temporary entity ids resolution table (<code class="highlighter-rouge">tempids</code>) and raw datoms which were used to modify DB (<code class="highlighter-rouge">tx-data</code>). Given <code class="highlighter-rouge">TxReport</code> and <code class="highlighter-rouge">db-before</code>, it’s trivial to replay transaction and calculate <code class="highlighter-rouge">db-after</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>db-before + tx-data = db-after
</code></pre></div></div>

<p><code class="highlighter-rouge">tx-data</code> is an end result of transaction data simplification, with all temporary and implicit ids allocated to actual entity ids, all maps expanded into vector forms, and all vectors converted to <code class="highlighter-rouge">Datom</code>s.</p>

<p><code class="highlighter-rouge">TxReport</code> is also the only place where you can see datoms with <code class="highlighter-rouge">added == false</code> for datoms which were retracted.</p>

<h2 id="entities">Entities</h2>

<p>Entity is just a convenient interface to <code class="highlighter-rouge">EAVT</code> index. Basically this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(:person/name (d/entity db 1))
</code></pre></div></div>

<p>is translated to this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(first (d/datoms db :eavt 1 :person/name))
</code></pre></div></div>

<p>with some per-entity caching. Most of the namespace <code class="highlighter-rouge">datascript.impl.entity</code> is spent on implementing protocols to make entities look like normal ClojureScript maps.</p>

<h2 id="queries">Queries</h2>

<p>Query engine implements Datalog over DBs and collections. It is the most complicated part of DataScript so far.</p>

<p>Query engine operates on relations. Relation is just a collection of tuples. E.g. this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>:where [?e :name ?v]
</code></pre></div></div>

<p>will be resolved by querying DB to following relation:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R1 = {:symbols {?e 0 ?v 1}
      :tuples  [#js [0 “Ivan”], #js [5 “Oleg”], ...]}
</code></pre></div></div>

<p>During query execution, <code class="highlighter-rouge">:where</code> is processed clause-by-clause. Relations which share no common variables are kept separate in a <code class="highlighter-rouge">context</code>, building a collection of relations. If <code class="highlighter-rouge">:where</code> looks like this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>:where [?e :name ?v]
       [?e2 :name ?v2]
</code></pre></div></div>

<p>then DataScript will create two separate relations:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R1 = {:symbols {?e 0 ?v 1}
      :tuples  [#js [0 “Ivan”], #js [5 “Oleg”], ...]}

R2 = {:symbols {?e2 0 ?v2 1}
      :tuples  [#js [0 “Ivan”], #js [5 “Oleg”], ...]}
</code></pre></div></div>

<p>Now what happens if we introduce third clause that implicitly joins first two relations by referring to the same variables? Let’s take <nobr><code>[?e :friend ?e2]</code></nobr>. DataScript will first resolve that clause to its own relation:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R3 = {:symbols {?e 0 ?e2 1}
      :tuples  [#js [0 5], #js [5 0], ...]}
</code></pre></div></div>

<p>Now context contains three relations, but they are not truly independent: they share common variables. This is forbidden, so at this point they will be reduced to a single relation. DataScript needs to hash-join latest relation (<code class="highlighter-rouge">R3</code>) with any conflicting relations there are. In our case, <code class="highlighter-rouge">R3</code> has intersection with both <code class="highlighter-rouge">R1</code> (by <nobr><code>?e</code></nobr>) and <code class="highlighter-rouge">R2</code> (by <nobr><code>?e2</code></nobr>), so what happens is we first do cartesian product of <code class="highlighter-rouge">R1</code> and <code class="highlighter-rouge">R2</code>, thus getting single relation to join with, then hash-join result with <code class="highlighter-rouge">R3</code> by <nobr><code>(?e ?e2)</code></nobr> compound key:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R4 = (R1 × R2) `hash-join` R3
</code></pre></div></div>

<p>Then <code class="highlighter-rouge">R4</code> will replace <code class="highlighter-rouge">R1</code>, <code class="highlighter-rouge">R2</code> and <code class="highlighter-rouge">R3</code> in a context.</p>

<p>Full algorithm:</p>

<ol>
  <li>Parse query (<code class="highlighter-rouge">datascript.parser</code>) and cache parse result (planned for 0.10.0). Most of the query validation happens at parsing stage.</li>
  <li>Scan sources (<code class="highlighter-rouge">:in</code> clause) and transform them to relations. This will create initial set of relations which populate context. Constants are also resolved to relations, e.g. <code class="highlighter-rouge">:in ?a</code> → <code class="highlighter-rouge">{:symbols {?a 0}, :tuples [#js [val]]}</code></li>
  <li>For each clause in <code class="highlighter-rouge">:where</code>, do this:
    <ol>
      <li>Try to resolve as much variables as possible using context so far and substitute them to clause (planned for 0.10.0)</li>
      <li>Execute clause and get result as a relation. If clause is a rule call, there’s special inner loop for rule resolution here, but result is still a relation.</li>
      <li>If resulting relation has intersection by variables with any existing relation, hash-join them together, fusing into one big relation</li>
      <li>Put resulting relation into the context</li>
      <li>Move onto the next clause</li>
    </ol>
  </li>
  <li>Build result set based on <code class="highlighter-rouge">:find</code> and <code class="highlighter-rouge">:with</code> vars list: do cartesian product on all relevant relations, leave just vars that matter from them, collect them into a <code class="highlighter-rouge">set</code></li>
  <li>If there’s some aggregation happening, do <code class="highlighter-rouge">group-by</code> and run aggregation functions</li>
  <li>If <code class="highlighter-rouge">pull()</code> is used, call Pull API for each entity</li>
  <li>If find specifications are used, do post-processing: unwrap inner tuples, take first element from a set, etc.</li>
</ol>

<p>Query engine is implemented in <code class="highlighter-rouge">datascript.query</code> and uses parser from <code class="highlighter-rouge">datascript.parser</code>.</p>

<h2 id="pull-api">Pull API</h2>

<p>Pull API is implemented in <code class="highlighter-rouge">datascript.pull-api</code> by <a href="https://github.com/dthume">David Thomas Hume</a>. It walks all entity ids, for each entity it walks all attributes from a pull pattern, and for each recursive attribute calls itself. It’s a recursive algorithm implemented as a state machine that emulates stack so it can handle unlimited recursion depth.</p>

<p>There’s also <code class="highlighter-rouge">datascript.pull-parser</code> where pull pattern is parsed and validated.</p>

<p>During implementation of DataScript pull pattern parser and query parser, we’ve helped Datomic team to fix couple of inaccuracies in their query grammar. This is why having alternative implementations is usually a good thing.</p>

<h2 id="filtered-dbs">Filtered DBs</h2>

<p>Given database <code class="highlighter-rouge">D</code> and predicate <code class="highlighter-rouge">P: datom, DB → boolean</code>, you can construct special view <code class="highlighter-rouge">F = (datascript/filter D P)</code> that will work like a regular database but for all needs (query, entity, pull, index access) will look like as if it only contains datoms that satisfy <code class="highlighter-rouge">P</code>.</p>

<p>Filtered databases are implemented in <code class="highlighter-rouge">datascript.core</code> by just extending couple of protocols: <code class="highlighter-rouge">IDB</code>, <code class="highlighter-rouge">ISearch</code>, <code class="highlighter-rouge">IIndexAccess</code> — mostly by adding additional <code class="highlighter-rouge">filter</code> post-process step.</p>

<p>For advanced uses it means that it’s quite easy to pretend to be a database: just implement these protocols and rest of DataScript code will work as expected.</p>

<h2 id="database-mutation">Database mutation</h2>

<p>Everything we’ve discussed so far works on top of immutable, persistent DB objects. There’s also a small piece of code to handle database mutations (as of 0.9.0, it’s literally 25 lines).</p>

<p><code class="highlighter-rouge">datascript/create-conn</code> returns a new database object wrapped with an atom. There’s also a <code class="highlighter-rouge">listen!</code> machinery for listening for DB changes. It was added because regular atom watchers receive value-before and value-after, but database changes have more useful information: list of datoms added and temporary ids resolution table.</p>

<p>DataScript “connection” is not a connection in any sense. I borrowed the term from Datomic, but now I’m thinking about changing it to <code class="highlighter-rouge">db-ref</code> or better, if only I could think of anything.</p>

<h2 id="javascript-interop">JavaScript interop</h2>

<p>Almost from the beginning DataScript has supported JavaScript interface. You include pre-compiled JS file (270k raw/~60k gzipped as of 0.9.0) and call <code class="highlighter-rouge">datascript.empty_db()</code>, <code class="highlighter-rouge">datascript.query()</code> and stuff.</p>

<p>This was made possible by <code class="highlighter-rouge">datascript.js</code> facade: it converts data coming from JS into ClojureScript data structures, calls proper <code class="highlighter-rouge">datascript.*</code> APIs, converts results into JS form and returns them back to JS caller. Not the most effective way to do things, but the only one manageable without writing js-native DataScript’s evil twin. Even with such approach, some things have leaked into the main DataScript code: it has to take into account that attributes can be strings, for example. But for the most part JS interop is isolated.</p>

<p>And JS interop is feature-full: everything you can do from CLJS, you can do from JS. Maybe not as well battle-tested, but nonetheless. See <code class="highlighter-rouge">test/js/tests.html</code> for how DataScript can be used from JS.</p>

<h2 id="tests">Tests</h2>

<p>DataScript does acceptance testing almost exclusively. Everything in <code class="highlighter-rouge">datascript.test.*</code> works with top-level interfaces of <code class="highlighter-rouge">datascript</code> and <code class="highlighter-rouge">datascript.core</code> namespaces. Exceptions are <code class="highlighter-rouge">datascript.test.btset</code> (generative tests of BTSet implementation) and <code class="highlighter-rouge">datascript.test.perf</code> (somewhat ad-hoc and messy performance tests of various parts of DataScript).</p>

<p>Having just acceptance tests works because semantics and APIs are already defined and documented by Datomic team whom DataScript is following. APIs do not change often, so extensive tests suite (2.8k loc <code class="highlighter-rouge">test/</code> for 3k loc <code class="highlighter-rouge">src/</code>) is not a dead weight and requires little maintenance.</p>

<p>Tests allowed me to change underlying implementation without rewriting a single test: I completely changed index implementation and inner DB structure once already and replaced query engine twice so far. It gives tremendous confidence to pull such refactorings without breaking anyone else’s code.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I didn’t know what to write in conclusion although I felt every post needs one. So here it is: have fun, enjoy your day.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Couple of DataScript resources</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/datascript-resources/" />
      <id>https://tonsky.me/blog/datascript-resources/</id>
      <published>2014-12-18T00:00:00+00:00</published>
      <updated>2014-12-18T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Couple of new talks about DataScript
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>There’s couple of new resources available about DataScript.</p>

<p>On December 4th I gave a talk at Clojure eXchange conference about motivation behind DataScript, a little bit about internals, and then about how DataScript can be used for application development. Beyond traditional SPAs, there were couple of examples of new kind of architectures that are trivial to execute given that DataScript exists.</p>

<p>You can watch video of the talk <a href="https://skillsmatter.com/skillscasts/6038-datascript-for-web-development">at SkillsMatter website</a> (free, registration required) and check out slides:</p>

<p style="margin: 20px -38px; height: 538px"><script async="" class="speakerdeck-embed" data-id="5ba8bad06862013296c3468088921707" data-ratio="1.33333333333333" src="https://tonsky.me/rss//speakerdeck.com/assets/embed.js"></script></p>

<p>Later this month I talked at ClojureScript NYC user group. During the webinar we developed ToDo application from scratch and touched, at least quickly, almost every aspect of DataScript. Here’s the agenda:</p>

<ul>
  <li>Create DB schema (multi-valued relations, references)</li>
  <li>Add ability to create tasks (basic <code class="highlighter-rouge">transact!</code>)</li>
  <li>Display list of tasks (basic query)</li>
  <li>Display tags on tasks (multi-valued attrs)</li>
  <li>Persist database to <code class="highlighter-rouge">localStorage</code> (serialization/deserialization)</li>
  <li>Make tasks completable (transact functions)</li>
  <li>Assign projects to tasks (entity navigation)</li>
  <li>Display task count for projects (aggregate queries)</li>
  <li>Display task count for inbox (“negate” query, query functions, query predicates)</li>
  <li>Display “by month” grouping (custom fn call in a query)</li>
  <li>Make left panel navigable (storing “view” app state in a db)</li>
  <li>Add filter (implicit OR via rules and collection bindings)</li>
</ul>

<p>The recording:</p>

<p style="margin: 20px -38px; height: 404px"><iframe src="https://tonsky.me/rss//player.vimeo.com/video/114688970?byline=0&amp;portrait=0&amp;color=ff8c84" width="620" height="393" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p>

<p>After the webinar I fixed couple of bugs in ToDo repo (and in DataScript as well), added comments here and there explaining what’s going on and implemented couple of new features:</p>

<ul>
  <li>DB filtering</li>
  <li>Serialization via transit-cljs</li>
  <li>History tracking and undo/redo support</li>
</ul>

<p>DataScript-ToDo should be a good resource for learning DataScript and its applications in the wild. Source code is <a href="https://github.com/tonsky/datascript-todo/tree/gh-pages/src">on github</a>, live version here:</p>

<p class="fig" style="margin: 20px -38px;"><a href="http://tonsky.me/datascript-todo/"><img src="datascript-todo.jpg" style="width: 620px; height: 455px:" /></a></p>

<p>Stay tuned!</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Streams: Mail 3.0 concept</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/streams/" />
      <id>https://tonsky.me/blog/streams/</id>
      <published>2014-10-27T00:00:00+00:00</published>
      <updated>2014-10-27T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Introducing concept of Streams, aiming to fix most of email-as-a-medium flaws
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>It’s hard to believe people still use email. It has so many flaws yet still remains die-hard to replace. The amount of email shortcomings can compete only with the amount of email usages.</p>

<p>Google’s Inbox is an attempt to fix non-communication part of email. It claims to solve problem of managing todos, reminders, notifications and subscriptions in your inbox. With Google’s resources, they sure can fix that by categorizing every service and subscription provider on a planet and show their emails in the best possible way. Yet, from a history perspective, it’s some polishing (ok, a lot of it) on top of completely messed up foundation. Most importantly, it does not fix communications.</p>

<p>Email was envisioned as a metaphor of a post office mail. Real-world, pencil-on-paper letters are good for very specific type of communications. Transferred to the internet, email inherited these limitations: electronic messages are not real-time, they’re hard to manage in huge amounts, they work best for person-to-person dialogs.</p>

<p>Working with email at per-message level makes communication heavy, slow and boring. It’s awkward to ping somebody with email, or ask “HYD”, or say “ok”. Waste of a letter, right? You need subject, you need greeting, you need signature. Well, you don’t, but that’s kind of a format, an <em>etiquette</em>. Think about it: in most clients you have to “open” messages (with click, but anyway) to see what’s inside.</p>

<p>To fix email, we should stop thinking about it as email at all.</p>

<p class="fig">
	<a href="email_noise.jpg" target="_blank"><img src="email_noise.jpg" /></a>
	You can’t get away with that much noise
</p>

<p>Better conversation models are threads, topics and chat rooms. There, individual messages are not as important. You operate on a level of the entire messages flow. Forums, chats and web 2.0 networks are trying to make conversations feel as lightweight and barrier-free as possible.</p>

<p>We should definitely get rid of legacy tech stack. There’re so many features people want from a modern communication tool email cannot deliver: sharing threads, managing permissions and user groups (because dedicated admins are so 2003), post-factum message editing. New developer comes to your company, you add him to “devs@acme.com” group and he gets access to all communications in the past that happened in that group before him. Sounds fun, right? Unlike email, which isn’t even web-friendly: e.g., you can’t share a link to the letter.</p>

<p>This is about where Google Wave team stopped: (apart from really insane stuff) they concentrated on fixing email threads, made them real-time and almost lightweight. Big improvement, no doubt, enough to call it Email 2.0, but not improvement enough. Your inbox was still a mess, and they expected you to clean it.</p>

<p>Email gets tricky with a scale. Starting with 50+ messages per day, even if individual messages are grouped to threads, there’re still <em>a lot</em> of threads and no clue how to group them together. Google tried to fix that first with filters (failed), then by applying machine learning and other heuristics in Priority Inbox and later in Google Inbox. But there’s just not enough structure in emails or threads to make meaningful, reliable sorting.</p>

<p>Let’s introduce one more layer of abstraction: <em>stream</em>. Stream is a group of threads. Simple as that. When you start new thread, you don’t just start it by filling <code class="highlighter-rouge">To:</code> and <code class="highlighter-rouge">Subject:</code>, you also have to put it to some stream.</p>

<p>What are examples of streams? I’m a programmer and use email heavily at work. We could’ve created stream “Code review” and start all new threads about reviews here. We’d put everything non-technical to stream “Offtopic”, like “Ideas for birthday party” or “Who lost the keys?” or threads like that. Paperwork goes to “Papers” stream, and clearly not everybody would subscribe to that.</p>

<p>Streams are not created on a personal basis, they are shared between people interested in them. Streams are like shared folders for individual threads. This additional layer keeps your communications organized: you don’t anymore have one cluttered inbox, threads are now sorted in streams with authors’ hands. Streams are high-level enough to make inbox organization effortless and not to introduce significant overhead.</p>

<p>This is a principal difference from filters: filters are personal, sender doesn’t know how receivers are going to sort each particular email, and thus cannot help. Receiver have to figure out complex filter pipeline and enforce strict conventions on subjects and aliases in order for filters to work. One can break conventions by being lazy, forgetful or by mistake but cannot avoid choosing a stream.</p>

<p class="fig">
  <a href="filters.jpg" target="_blank"><img src="filters.jpg" style="width: 600px; height: 482px" /></a>
  I’ve spent a lot of time tuning filters and still only ~50% satisfied
</p>

<p>Streams also change traditional push notification model to a pull one. Robots used to ask your email address and then <em>push</em> notifications to your inbox. With Streams, they just generate a stream and publish all notifications there. Now <em>you</em> decide if you want to subscribe to it or not. For example, you’re on Amazon and they generate a personal stream for you: <code class="highlighter-rouge">amazon.com/182adb92-...</code>. You can put that stream to your inbox now, or three days later — every notification will be there no matter if you’re reading it or not. You can even share it with your family members. Notice that Amazon didn’t ask you about your address, it doesn’t, in fact, need anything from you. It always felt wrong in traditional email subscriptions that <em>you</em> have to share your email, and that decision to unsubscribe is not on your side. Streams fix that.</p>

<p>Can we get more ambitious? Yes we can.</p>

<p>With proper user/access management Streams could replace not just email, chats and group chats but also forums, blogs, mail lists, RSS and most of web 2.0 communities. Okay, mail lists have “mail” in it. But can you imagine writing blog in email? With Streams, blog is just a stream where only you can create threads (posts) and anyone can read and reply.</p>

<p class="fig">
  <a href="blog.png" target="_blank"><img src="blog.jpg" style="width: 600px; height: 400px; " /></a>
  Me writing this post as a Stream
</p>

<p>Forums and lists are most relaxed forms of a stream: everyone can create threads and comment on them. Personal chat is just an endless thread with two people having read/write access to it. To move from personal to group chat, just add more people. Private stream could be used for notes, todos and personal journal.</p>

<p class="fig">
  <a href="chats.png" target="_blank"><img src="chats.jpg" style="width: 600px; height: 400px; " /></a>
  Personal and group chats
</p>

<p>Email rooms does not differ from chat rooms, there’s no strict boundary between chats and what used to be email. It’s all just communication, just threads. UI should maintain same level of comfort for both long and short messages — tricky, subtle, but doable.</p>

<p>For resources published in Streams you don’t even need a feed aggregator, you can subscribe and read streams directly. You can follow blogs and will be notified about both new posts (threads) and new comments (messages), and will even be able to reply in-place. It feels right when, unlike RSS, writing and reading are both supported by a single platform.</p>

<p class="fig">
  <a href="feed.png" target="_blank"><img src="feed.jpg" style="width: 600px; height: 400px; " /></a>
  Me reading newsfeed and answering to blog comments in-place
</p>

<p>With all these goals, it’s easy to imagine hundreds of streams per user. To keep concept simple, on implementation side streams are always flat, you cannot put a stream into a stream. But in UI user can create stream groups and put couple of similar streams inside. E.g. it makes sense to group “Amazon”, “PayPal”, “iTunes” and “Steam” streams into a “Shopping” group:</p>

<p class="fig">
  <a href="orders.png" target="_blank"><img src="orders.jpg" style="width: 600px; height: 400px; " /></a>
  Streams group and Amazon thread about one specific order
</p>

<p>In the picture above note that Amazon stream is read-only for me, meaning I <em>physically</em> cannot reply to that. This fixes ambiguity around do-not-reply@ addresses.</p>

<p>Today’s inbox is both communication tool and notification center. In both cases there’re hundreds independent information streams fighting for your attention. As a platform, email can’t solve this problem: best email providers could offer is guessing, which is expensive, fragile and non-customizable. Streams concept represents “independent information stream” metaphor directly. With Streams, unsolvable inbox organization problem becomes couple of drag-and-drops. Unlike email, where communication happens by passing letters through letterbox holes, Streams are collaborative medium: single, shared place everybody look at. It could easily replace many modern social models: blogs, forums, mail lists, feeds. It’s an abstraction right where it is needed.</p>


      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Another powered-by-DataScript example</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/acha-acha/" />
      <id>https://tonsky.me/blog/acha-acha/</id>
      <published>2014-10-06T00:00:00+00:00</published>
      <updated>2014-10-06T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Git Achievements application built around DataScript
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>Last weekend my friends and I built Acha-Acha — a Git Achievements web app for <a href="https://clojurecup.com/#/apps/acha">ClojureCup hackathon</a>. It’s the most clojure-y application I’ve ever written: we used Clojure, core.async, transducers, http-kit, Transit, ClojureScript, sablono, and DataScript — of course. (plus React and JGit from non-clojure stack). My part was UI development, and DataScript helped a lot.</p>

<p><a href="http://acha-acha.co" style="border: none; "><img src="acha.jpg" style="width: 523px; height: 403px;" /></a></p>

<p>Acha-Acha follows the idea of a dumb but persistent server and smart ephemeral client: all data is loaded via single fetch on a page load and everything else is handled by a client. It’s literally everything, including page navigations, data sorting, filtering, aggregating: server just sends every fact it’s aware of, and client deduces lists, totals and sums from raw data on the fly. For example, on index page there’s achievement count on each user’s badge: it’s not stored in a database, but calculated on a client from a raw achievements list (equivalent of <code class="highlighter-rouge">select count group by</code>).</p>

<p style="text-align: center"><img src="aggregations.png" style="width: 345px; height: 291px" /></p>

<p>Once app is loaded, you can go to any page and there’ll be not a single ajax call for that. Each page is just a couple of queries to already fetched DB. Doing zero ajax calls is wickedly fast, much faster than talking to server, even very good one.</p>

<p>There’s no “RESTful” server API, of course — just one endpoint (<code class="highlighter-rouge">/api/db/</code>) that dumps everything. We can probably generate response once and serve it from disk via Nginx, it’s not dynamic at all.</p>

<p>Actually, we’ve added some dynamism after the contest: list of new achievements, new users and new repos are delivered to the browser when someone adds new repo or old one gets updated. Here’s all the code (literally, there’s not a line more) that handles all server pushes:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(let [socket (js/WebSocket. url)]
  (set! (.-onmessage socket)
        (fn [event]
          (let [tx-data (read-transit (.-data event))]
            (d/transact! conn tx-data)))))
</code></pre></div></div>

<p>This little snippet is everything you need to magically transform a fully static web app to a fully dynamic one. On any page, wherever you are, you’ll see up-to-date information and all the changes in real-time. If a user gets awarded, you’ll see the new achievement popping up on user’s page, on index page you’ll see how his medal’s counter gets advanced, and on repo’s page you’ll see his avatar being added to the achievements list. Amazing thing is that there’s no code to support any of this. There’s just one listener that puts everything it sees to the database.</p>

<p>It wouldn’t be possible without React, of course. Where DataScript gives you simplicity with “just put everything to the DB”, React gives you simplicity with “just take the DB and render everything from it”. In Acha-Acha, every page is always rendered from scratch, including data queries for everything it needs; we don’t even have Om/Quiescent style optimisations of <code class="highlighter-rouge">shouldComponentUpdate</code> — and still, it’s quite performant and perfectly useful.</p>

<p>Speaking of performance — we haven’t implemented any limits for main page, we aren’t even truncating list of users and just render everybody. I presumed that my browser will start suffering after 10th repository added, but real-world experience was much more positive. We’ve seen up to ~50K datoms kept in the DB, main time spent on initial DB population, working fast after that (speaking of which, I found a good potential to speed up initial bulk import ~5-10 times in DataScript). 26K datoms were inserted in ~800ms, not that lethal, especially after I’ve added progress bar (not in the deployed version yet). Again, 26K datoms is for ~30 repos and ~1200 users, much bigger than typical app will probably need to load at once. Still faster that GMail though :)</p>

<p>Another huge performance revelation was Transit. It’s a serialization format that keeps all your Clojure data structures intact (persistent maps/vectors/sets/lists, keywords, dates — yes, we send dates as-is, totally transparent and very handy) and still performs on par with browser’s built-in <code class="highlighter-rouge">JSON.parse</code>. Here’s totally unscientific comparison of deserialization speeds:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>json              8.338ms   1006 Kb
transit          14.228ms    950 Kb
json + js-&gt;clj  213.135ms   1006 Kb
edn             358.302ms   1055 Kb
</code></pre></div></div>

<p class="fig">(in our case, 1Mb of data corresponds to those 50K datoms, if I remember correctly)</p>

<p>Overall experience from using DataScript was very smooth and it performed with dignity in tough conditions of limited time and unexpected performance demands (e.g. each page re-rendering is a couple of queries and <em>a lot</em> of entities lookups over a database that contains every fact about everything). It leads to an architecture that is quick to develop and requires very little effort to achieve outstanding results.</p>

<p>Now about fun stuff.</p>

<p>You can check out live version at <a href="http://acha-acha.co">acha-acha.co</a>. Everything is still not smooth enough<a id="f1" href="#fn1" class="footnote">†</a> — beware. Please do not abuse it, as we’re still not prepared for real-world SaaS.</p>

<p>We also have the source code available <a href="https://github.com/someteam/acha">at github</a>. It was updated with most urgent patches, including real-time page updates, missing images, better repo handling, progress-bar, etc.</p>

<p>And we have <a href="https://github.com/someteam/acha/releases">portable version</a>. It’s totally autonomous, only prerequisite is Java. It’s for private network setups, when you want to play with achievements but don’t want to share your secret code with us. Feel free to. <a href="https://github.com/someteam/acha/blob/master/README.md">Instructions</a>.</p>

<p>As for the achievements themselves, we’ve implemented just about ⅓ of what we’ve planned. Much more to come.</p>

<p><img src="tease.png" style="width: 498px; height: 57px;" /></p>

<div class="footnotes-br"></div>
<ol class="footnotes_alt">
<li id="fn1"><span class="dagger">†</span> Except for pixel art, which is far more than I could dream of. It’s remarkable. <a href="#f1" class="">↩︎</a></li>
</ol>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Chatting cats use DataScript for fun</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/datascript-chat/" />
      <id>https://tonsky.me/blog/datascript-chat/</id>
      <published>2014-09-18T00:00:00+00:00</published>
      <updated>2014-09-18T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          How to write chat application with ClojureScript, core.async, React and DataScript
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>What DataScript-driven application looks like? Does DataScript really makes the difference? I tried to answer both questions by writing small single-page application. Not to bore you (and myself; mostly myself) with another TodoMVC show-off, I made a simple chat. Meet CatChat:</p>

<figure><a style="border: none; " href="http://tonsky.me/datascript-chat/"><img src="https://tonsky.me/blog/datascript-chat/rss/datascript_chat.png" style="width: 620px; height: 420px; margin: 20px 0;" /></a></figure>

<p>Check out <a href="https://github.com/tonsky/datascript-chat">source code</a> and <a href="http://tonsky.me/datascript-chat/">live version</a>.</p>

<p>CatChat is organized by principles of Flux architecture. DataScript is a storage, clojure/core.async is an event bus, DOM is rendered by React. Some <a href="http://gridstylesheets.org">GSS</a> used out of curiosity. Not to complicate things, server-side calls are emulated.</p>

<figure><img src="https://tonsky.me/blog/datascript-chat/rss/overview.png" /></figure>

<h2 id="starting">Starting</h2>

<p>At the beginning we just create a DB:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(def conn (d/create-conn {}))
</code></pre></div></div>

<p>Initial data is loaded and pushed directly to DB in <code class="highlighter-rouge">onReady</code> callbacks. We assume server sends data in a format that matches client-side DB:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(server/call server/get-rooms []
  (fn [rooms]
    (d/transact! conn rooms)))

(server/call server/whoami []
  (fn [user]
    (d/transact! conn [(assoc user
                         :user/me    true
                         :user/state :loaded)])))
</code></pre></div></div>

<p>Notice how user object gets <em>augmented</em>. Persistent attributes like <code class="highlighter-rouge">:user/name</code> or <code class="highlighter-rouge">:room/title</code> come directly from server DB. But some stuff only makes sense on a client: who current user is, which room is selected — session-dependent stuff. We store these transient attributes in the same DataScript database, exactly at the same entities. They will come in handy when queries kick in.</p>

<p>Good thing about code above is that it doesn’t know or care about any other part of the system: how data is rendered, who else listen or cares about data — it doesn’t matter at this point. Initial database population is a small, self-contained piece of logic. Our app will be built from pieces like that: independent, focused and composable. They do not communicate with each other, only thing they share is the database.</p>

<h2 id="dispatching">Dispatching</h2>

<p>Data flow incorporates event bus to make events observable and allow reactions to be added. Event bus opens a lot of possibilities, including events mocking, simulation, logging. Having simple way to get insight into causality graph is <em>crucial</em> for effective understanding of complex systems. Debug, refactoring and optimization benefits follow.</p>

<p>Most importantly, event bus helps with decoupling: nobody knows what parties are interested in particular message; different pieces of functionality can be developed, tested and run independently from each other.</p>

<p>We use core.async pub/sub channel as event bus. Incoming chat messages are delivered via server push and then <code class="highlighter-rouge">put!</code> to the channel:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(def event-bus (async/chan))
(def event-bus-pub (async/pub event-bus first))

(server/subscribe
  (fn [message]
    (async/put! event-bus [:recv-msg message])))
</code></pre></div></div>

<p>Our first consumer just saves messages to the database:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(let [ch (async/chan)]
  (async/sub event-bus-pub :recv-msg ch)
  (go-loop []
    (let [[_ msg] (async/&lt;! ch)]
      (d/transact! conn [msg])))
    (recur))
</code></pre></div></div>

<p>I put a little twist to data model here. With each message, server sends user id, but whole user entity (name, avatar) is needed for rendering. Thus, we must issue another async request to fetch user data. It’s done in another listener to event stream:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(let [ch (async/chan)]
  (async/sub event-bus-pub :recv-msg ch)
  (go-loop [seen-uids #{}]
    (let [[_ msg] (&lt;! ch)
          uid     (:message/author msg)]
      (if (contains? seen-uids uid)
        (recur seen-uids)
        (do
          (d/transact! conn [(user-stub uid)])
          (load-user uid)
          (recur (conj seen-uids uid)))))))

(defn user-stub [uid]
  { :db/id       uid
    :user/name   "Loading..."
    :user/avatar "avatars/loading.jpg"
    :user/state  :loading })

(defn load-user [uid]
  (server/call server/get-user [uid]
    (fn [user]
      (d/transact! conn [(assoc user
                           :user/state :loaded)]))))
</code></pre></div></div>

<p>For every incoming message we check if we’ve seen author id already, and if not, then we send request to the server, put temporary user stub to the database (to display placeholders instead of avatar and name), and recur. Once server responds, callback gets called and we store actual user data with the same entity id, overwriting stub attributes.</p>

<p>Note that code above contains an infinite loop that tracks state (seen user ids) naturally — a thing you can’t afford with callbacks. Go blocks are sequential co-programs which give an illusion of parallel execution a-la green threads. Their parking and resuming happens at point where data arrives to or leaves channels. Core.async can do much more beyond simple pub-sub, (think complex topologies of channels, modifiable at runtime), but I couldn’t find a good occasion for that in CatChat.</p>

<h2 id="rendering">Rendering</h2>

<p><code class="highlighter-rouge">Render</code> is literally a function of two arguments: DB value for building DOM and event bus for communicating events back. Root React component receives a value of a DB as one and only source of data. Having all state as a single, immutable value brings many benefits:</p>

<ul>
  <li>Rendering is always consistent. No matter how state mutation and rendering loops work, you take immutable DB snapshot once and render everything from it. User never sees a screen in transient state.</li>
  <li>Previous states can be stored and reverted to. This makes undo/redo, replays and time traveling trivial.</li>
  <li>Rendering code does not care how data gets there. You can easily render mock states and do what-if speculations without touching rendering at all.</li>
  <li>Application state can be remembered and restored trivially (e.g. from <code class="highlighter-rouge">localStorage</code> between page reloads).</li>
</ul>

<p>It’s trivial to know when re-rendering is needed. We just establish a DB listener and trigger re-rendering after each transaction:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(d/listen! conn
  (fn [tx-report]
    (ui/request-rerender (:db-after tx-report) event-bus)))
</code></pre></div></div>

<p>Independent widget development is also a breeze. All widgets are derived from the same database, but other than that, they do not communicate neither depend on each other. It removes large piece of logic responsible for two-way data flow between UI components: user clicked here, let’s tell everyone what and how they should update. We all love shortcuts, but even in small applications this approach is not sustainable. What UI needs to communicate back to DB goes through the same event bus everybody else in a system uses. After all, rendering is not <em>that</em> special.</p>

<h2 id="queries">Queries</h2>

<p>Let’s now dive into the deeps of DataScript usage. Rendering is the main reader of a database, utilizing all sorts of queries.</p>

<p>Simplest possible query selects for each room id its title:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(d/q '[:find ?r ?t
       :where [?r :room/title ?t]]
  db)
</code></pre></div></div>

<p>Results are always a set of tuples, each tuple consisting of values in <code class="highlighter-rouge">:find</code> clause order. In our case it’ll look like this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#{[12 "Room1"]
  [42 "Room2"]
  ...}
</code></pre></div></div>

<p>Here we select all unread messages in a specific room:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(d/q '[:find ?m
       :in $ ?r
       :where [?m :message/unread true]
              [?m :message/room ?r]]
  db room-id)
</code></pre></div></div>

<p>That query does implicit join (all unread messages are inner joined with all messages of a specific room) and has a query parameter (<code class="highlighter-rouge">room-id</code>).</p>

<p>Notice that <code class="highlighter-rouge">db</code> is also just a parameter for a query. DataScript allows for several databases in a single query (and/or collections, they work the same) and can do effective cross-db joins between them.</p>

<p>This function uses previous query to construct a list of datoms for a transaction that will mark all messages in a room as read:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(defn mark-read [db room-id]
  (let [unread (d/q '[:find ?m
                      :in $ ?r
                      :where [?m :message/unread true]
                             [?m :message/room ?r]]
                    db room-id)]
    (map (fn [[mid]]
           [:db/retract mid :message/unread true])
         unread)))
</code></pre></div></div>

<p>Aggregates are another handy feature. This query takes, for each room, all messages that satisfy <code class="highlighter-rouge">:where</code> clause and <em>then</em> applies <code class="highlighter-rouge">count</code> on them, grouping by room:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(d/q '[:find ?r (count ?m)
       :where [?m :message/unread]
              [?m :message/room ?r]]
  db)
</code></pre></div></div>

<p>Result will look like this:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#{[1 18]
  [2  0]
  [3  2]}
</code></pre></div></div>

<h2 id="entities">Entities</h2>

<p>Take a look at how messages are retrieved by room id:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(let [msgs (-&gt;&gt; (d/q '[:find ?m
                       :in $ ?r
                       :where [?m :message/room ?r]]
               db room-id)
             (map first)
             (map #(d/entity db %))
             (sort-by :message/timestamp))])
</code></pre></div></div>

<p>Query first selects messages for specific room, then results are unpacked (so we have <code class="highlighter-rouge">(1 2 3)</code> instead of <code class="highlighter-rouge">#{[1] [2] [3]}</code>), then every id gets converted to an entity, and finally all entities are sorted by <code class="highlighter-rouge">:message/timestamp</code> attribute.</p>

<p>Sometimes entities are very handy, and you’ll probably use them a lot. Entities are map-like interface to accessing DB: given entity id and DB value, all attributes of that entity id will be in a map (well, <nobr>sort of —</nobr> you cannot <code class="highlighter-rouge">assoc</code> them, and <code class="highlighter-rouge">get</code> is lazy). For example, you have room with id 17:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(def room (d/entity db 17))
</code></pre></div></div>

<p>Use it to get attribute values as if it was a regular map:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(:room/title room)    =&gt; "Room 17"
(:room/selected room) =&gt; true
(:db/id room)         =&gt; 17
</code></pre></div></div>

<p>As you access attributes, they get lazily retrieved and cached:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>room =&gt; { :db/id 17,
          :room/title "Room 17",
          :room/selected true }
</code></pre></div></div>

<p>Entities are intentionally dumb and simple. They’re just a view at a specific part of specific database version. They do not auto-update when database is changed. They cannot communicate changes back to the database. Entities are not ORM. In essence, entities are just handy way to write <code class="highlighter-rouge">[:find ?v :in $ ?e ?a :where [?e ?a ?v]]</code> queries.</p>

<p>Entities also make it easy to walk references. If a value of an attribute is a reference to another entity, it’ll be represented as entity object itself:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(d/entity db msg-id)
=&gt;  {:db/id 10001
     :message/text   "..."
     :message/room   { :db/id 2
                       :room/title "Room2" }
     :message/author { :db/id 17
                       :user/name "Ilya"   }}
</code></pre></div></div>

<p>For this to work, specify attribute type in schema during initial database creation:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(def conn (d/create-conn {
  :message/room   {:db/valueType :db.type/ref}
  :message/author {:db/valueType :db.type/ref}
}))
</code></pre></div></div>

<h2 id="multi-valued-relations">Multi-valued relations</h2>

<p>DataScript is especially good at multi-valued relations. One-to-many and many-to-many relations are first class. If a group has a list of students, DataScript can support that. If an actor plays in a movie, and movie has a list of an actors, you can model that without intermediate table nonsense.</p>

<p>Relations are two-way. It doesn’t really matter if room contains list of messages or message has a reference to a room. You can query it both ways:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(def conn (d/create-conn {
  :message/room {:db/valueType :db.type/ref}
}))

(d/q '[:find ?m
       :in $ ?r
       :where [?m :message/room ?r]
  db room-id)

(d/q '[:find ?r
       :in $ ?m
       :where [?m :message/room ?r]
  db message-id)
</code></pre></div></div>

<p>Even if we reverse relation in schema, it wouldn’t really matter:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(def conn (d/create-conn {
  :room/messages {:db/valueType   :db.type/ref
                  :db/cardinality :db.cardinality/many }
}))

(d/q '[:find ?m
       :in $ ?r
       :where [?r :room/messages ?m]
  db room-id)

(d/q '[:find ?r
       :in $ ?m
       :where [?r :room/messages ?m]
  db message-id)
</code></pre></div></div>

<p>Entities have a nice way to handle references in both directions. In CatChat we use <code class="highlighter-rouge">:message/room</code> relation. To access it in forward direction (from message to room):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(get message-entity :message/room) =&gt; &lt;room-ent&gt;
</code></pre></div></div>

<p><em>Exactly the same</em> relation can be accessed backwards (from room to messages):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(get room-entity :message/_room)   =&gt; #{&lt;message-ent&gt;, ...}
</code></pre></div></div>

<p>Backward-accessed relations always return sets of entities. Forward access returns single entity or a set depending on relation’s arity. All this makes DataScript natural to express and easy to navigate entities graphs.</p>

<h2 id="resume">Resume</h2>

<p>Let’s recap:</p>

<ol>
  <li>Event bus is implemented as core.async channel with listeners implemented as independent <code class="highlighter-rouge">go</code> loops.</li>
  <li>Listeners issue DB transactions to “alter” DB value.</li>
  <li>React render is a function of immutable DB value and is triggered after each transaction. Current value of DB is passed as the only property.</li>
  <li>Any action in UI, if it want to change something, sends an event to event bus. Loop closes.</li>
</ol>

<p>For me, that was the best way to write UI application I ever experienced.</p>

<p>Turned out adopting a database is a really good idea for client-side app. Programming languages make it easy to model state as nested dictionaries and arrays, but most data access patterns are more complicated. “I know, I’ll put messages inside rooms! Oh, now I need to count unread messages across all rooms… Oh, now I need to group messages by user id. Ok, I’m screwed”. This is where DataScript shines: you store datom once and look at it from different angles: messages by room, room by message, messages by user, user by having unread messages, messages by unread status, and so on. One-to-many collections, many-to-many relations, reference graphs — it all fits naturally to DataScript. It frees a lot of cognitive resources: you don’t have to invent optimal storage strategy for every next property, messing with all these nested hash map structures, clever rolling caches, consistency issues. In DataScript all data is in one place, it’s normalized, it’s handled uniformly, it’s already optimized — much better than you usually do by hand. And you can query it any way you need.</p>

<p>Project trackers, email clients, calendars, online banks, professional to-do lists are all kinds of client-side apps that are highly structured and can benefit from adopting DataScript. Think Trello or GMail: in any sufficiently complex client-side app there’s a lot of structured data to take care of. I personally sometimes fantasize about rewriting GitHub issues page:</p>

<figure><img src="https://tonsky.me/blog/datascript-chat/rss/github_issues.png" /></figure>

<p>Just imagine how we can store all these tiny issues and all their little properties in DataScript, and then implement all these tabs, buttons and filters <em>on a client</em>, without even touching a server.</p>

<p>This should bring sanity to web app development. Finally, server API is dumb and inflexible, returning, within a single call, all essential data in a bulk dump format. Server is freed from any presentation-level hacks like <code class="highlighter-rouge">?sort_by=name</code>, <code class="highlighter-rouge">?unread=unread</code> or <nobr><code>?flash_message=Saved</code></nobr>. That’s all part of presentation logic and must reside on a client.</p>

<h2 id="where-to-get-more-info">Where to get more info?</h2>

<ol>
  <li>
    <p><a href="http://facebook.github.io/react/docs/flux-overview.html">Flux architecture overview</a></p>
  </li>
  <li>
    <p>Rich Hickey speaks core.async and why channels are fundamentally better than callbacks: <a href="http://www.infoq.com/presentations/clojure-core-async">infoq.com/presentations/clojure-core-async</a> (esp. from 32:00)</p>
  </li>
  <li>
    <p>Stuart Halloway <a href="http://www.youtube.com/watch?v=bAilFQdaiHk">introduces Datalog for Datomic</a> (DataScript syntax is heavily based on Datomic’s one)</p>
  </li>
  <li>
    <p>While DataScript doesn’t have its own documentation, take a look at Datomic’s docs on <a href="http://docs.datomic.com/query.html">queries</a>,  <a href="http://docs.datomic.com/transactions.html">transactions</a>, <a href="http://docs.datomic.com/entities.html">entities</a> and <a href="http://docs.datomic.com/indexes.html">indexes</a>. They are pretty close, with some minor differences</p>
  </li>
  <li>
    <p><a href="https://github.com/tonsky/datascript/tree/master/test/datascript/test">DataScript tests suite</a> can give you a good overview of what’s possible with DataScript</p>
  </li>
  <li>
    <p>And, of course, don’t forget <a href="https://github.com/tonsky/datascript-chat">CatChat codebase</a></p>
  </li>
</ol>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Irrelevant Things</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/irrelevant-things/" />
      <id>https://tonsky.me/blog/irrelevant-things/</id>
      <published>2014-08-12T00:00:00+00:00</published>
      <updated>2014-08-12T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          As a programmer on a way to technical excellency, you should teach yourself to constantly spot and reduce waste.
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>I had a conversation once, whether trailing spaces should be removed from code or not. Real conversation, with an actual person, with “arguments”, “pros and cons”. Even appeals to taste. Half an hour lost on something that isn’t a problem at all. Trailing spaces are okay, not having trailing spaces is okay too, I guess; I’m only concerned when somebody cares about such irrelevant thing.</p>

<p>A lot of people care, to be frank. Enough to have plugins written for all major editors to check, highlight, eliminate trailing spaces. To make invisible, not-a-problem thing bold, visible disaster. But I’m more or less fine with this waste, I can accept it being small compared to the fact there’s a whole bunch of <em>companies</em> building their <em>businesses</em> around to-do applications. Even guy who wrote JavaDoc generator for getters in Eclipse seems to be making Earth a better place compared to that.</p>

<p class="fig">
<img src="todos.png" style="width: 320px; height: 480px;" />
There’s always a room for innovation
</p>

<p>It’s easy to spot <a href="http://en.wikipedia.org/wiki/Muda_(Japanese_term)">muda</a> in well-known holywars. But a lot of everyday programmer’s activities fall into the same category. Dependency management, for example. If you spent a day setting up compilation workflow and getting dependencies right, it’s not a day of good work. It’s a day lost. You haven’t created new value, you haven’t enabled a single person to do anything that wasn’t possible before. You were <a href="http://www.lighttable.com/2014/05/16/pain-we-forgot/">satisfying other programs’ demands</a>. Even the fact that this activity has its own name indicates there’s something wrong with it. I hope there isn’t an actual job title like “Dependency management engineer”, is there? I probably don’t want to know.</p>

<p>As a programmer on a way to technical excellency, you should teach yourself to constantly spot and reduce waste. At their very essence, programs are about converting information: data in, data out. When you understand that, you can tell, for every piece of code in your system, if it’s essential for <em>the</em> task, or not. Kind of universal criteria. If it converts X to Y, it’s <em>probably</em> doing something valuable. If it’s just passing data around, it’s <em>probably</em> a waste. Every case is different, but overall these are good markers to trigger alarm.</p>

<p>There’s some point in having full-blown class hierarchies, or paranoid incapsulation, or split interface and implementation for every other bit of your program. But, with high degree of probability, you can get away without that perfectly fine. You can build modern, competitive <a href="https://github.com/LightTable/LightTable">10K LOC systems</a> without a single class. You can build small, ridiculously sophisticated things <a href="http://thenewstack.io/the-new-stack-makers-adrian-cockcroft-on-sun-netflix-clojure-go-docker-and-more/">in a very short time</a>. Here’s a whole <a href="https://news.ycombinator.com/item?id=1114410">operating system under 20K LOC</a>. And we’re not talking about compromising quality or feature set. We’re talking about taking away non-essential parts.</p>

<p>There are practices to keep code ready for changes, but those are only for changes you can foresee. By leaving stuff out and keeping codebase small, you’re making it ready for <em>any change</em> because there’s so little code to change in the first place. Small codebase is a valuable asset per se.</p>

<p class="fig">
  <img src="getters.png" style="width: 320px; height: 480px;" />
  How much value was added on this screen?
</p>

<p>So the idea is to go with as little things as possible. Then look at yourself. Is your life getting easier? It probably won’t right away, as you’ll be kicked off your comfort zone and will have to fight habits. Habits are not good indicators of anything, they’re accidental, so let some time pass. Does it become harder to get tasks done? Are you slowing down or speeding up? Have you completed more? Has quality of your work increased?</p>

<p>Give it a try, it’s not lethal. Do a project without ORM, use SQL instead. Do not create a constant, use a string. Do not use inheritance. Put everything in a single file. Start writing code in a text editor. Interesting things may happen. Without help of an IDE, for example, your code may become better. There’s <a href="http://usabilitypost.com/2011/01/10/dark-side-of-usability/">a flaw in human nature</a> saying that the more help you get on a task, the less deep you’re actually involved.</p>

<p>I’m not saying all of these things are good. They may be situational, they may not worth it at all. But real reasons, real value of things is often not on a surface, it’s so far away from conventional wisdom you need to do something radical to reveal it. You need to clear your vision. That’s the point. Even if you return, you’ll know exactly why you’re returning. What you cannot live without, and what you can dispense with. I haven’t touched IDEs for three years, and now I’m returning, but not for the usual stuff (highlighting, refactorings, automation — effect from them is negligible). I’m returning for interactive development. Turns out it really changes the game.</p>

<p>By going ascetic, you’ll develop new meanings for good and bad. You’ll learn that good tool is not the one with billion modules already written. Good one makes writing your own module a no-brainer. You’ll learn that good things value your time. Wasting time is a shame, and you should constantly look for a ways to reduce waste. You’ll have a small amount of tools in your hand, and each one of them has to be deep. Some widely adopted engineering practices will fade away, some will stick. The point is, again, to know exactly why you’re doing what. It’s a question of life and death now, not just fashion or habits.</p>

<p>The rest is for you to figure out. Different experience may lead to different results, but overall it’s very beneficial to constantly reflect and question if you can live without things. The less you need, the more powerful you are.</p>


      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Reinventing Git interface</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/reinventing-git-interface/" />
      <id>https://tonsky.me/blog/reinventing-git-interface/</id>
      <published>2014-06-17T00:00:00+00:00</published>
      <updated>2014-06-17T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          A set of recommendations on how Git UI can be improved not on a cosmetic, but on a very fundamental level. We aim at making Git more usable, powerful and easier to learn by radically simplifying its interface and keeping compartibility with the implementation
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>I have a long love-hate relationship with Git. Despite solving all my problems with version control and having a technically excellent implementation, the whole experience sucks constantly. I’ve tried it all: official CLI, non-official CLIs, gitk, third-party GUIs. It always strikes me — how, while having this brilliant model, the model that’s plain dead simple at its heart, the one about DAG of commits, — how <em>every other interface to it</em> manages to ruin it completely?</p>

<p>And it’s not just me — people are complaining about Git complexity on the internet <em>a lot</em>. I’ve seen my fellow developers needing a crash course into even basic Git usage, and many were still puzzled by some “advanced” stuff like rebasing months after starting using it. It’s easy to see how wrong it is: basic Git concepts can be explained in a matter of half an hour <em>on a whiteboard</em>, yet actually touching Git <em>on a computer</em> takes you <em>weeks</em> to get used to. Sure, it feels nice to be accounted for something like a “Git guru”, but, the thing is, I do not know that much about Git’s command-line arguments or advanced tricks. I just see that things are much simpler than they seem to be.</p>

<p class="fig">
  <img src="louie_ck_parking_sign@2x.jpg" style="width: 554px; height: 310px;" />
  Typical Git cheatsheet
</p>

<p>So, what shall we do with it? I suggest we get to the core, remove everything accidental, including any UIs and commands, and keep just fundamental information model. And then we start building from there.</p>

<h2 id="git-model">Git model</h2>

<p>At the very core, Git is about keeping history of a directory. It can store all of the directory content <em>as a snapshot</em>, and it can store a lot of snapshots effectively. So, as you keep changing your project, you are making these snapshots and Git puts them to its local database. You can later restore any of these snapshots, and it will bring your directory’s content exactly as it was back then. Snapshots are called <em>commits</em>, and we will stick to that term too.</p>

<p>Besides directory’s content and some metadata like author and timestamp, each commit also remembers link to its parent commit. This is important because it helps tracking causality. History in Git is non-linear: there may be several versions of a project co-exisiting in parallel. History forms directed acyclic graph (DAG), a tree of commits with splits (branching) and joins (merges).</p>

<p>Notice that commits and DAG are self-sufficient. They live without branches or remote repositories or stage index or whatever. It’s also important to remember what Git is calling “a branch” has nothing to do with branches in graph terms. Git’s branch is just a pointer to some commit, exactly like a tag is. To avoid confusion, we’ll call them <em>branch pointers</em>.</p>

<h2 id="grow-only-repository">Grow-only repository</h2>

<p>It’s all fun and games, but here comes a chance to make the first serious improvement. You may have noticed that Git warns you <em>a lot</em>. Rebase is dangerous, headless state is dangerous, don’t do <nobr><code>push -f</code></nobr>, are you sure, think twice, you’re not supposed to do that, stuff like that. The idea was, I believe, not to prevent any harm, but to help use Git as its creators intended it to be used. Because, the fact is, you cannot really destroy anything by doing any “potentially dangerous” operations like <code class="highlighter-rouge">rebase</code> or <nobr><code>commit --amend</code></nobr>. Git repo is immutable, it only grows, but never shrinks. You can add new snapshots to the repo, but you cannot remove old ones. You cannot change contents of a file once it has been snapshotted, but you can add a new version of it. When you rebase, you do not “move” any commits, neither are you “overwriting” history. You actually create several <em>new</em> commits, keeping old ones intact. You can still reference them or even checkout them by SHA. Even deleting unmerged branch just removes branch pointer, keeping actual commits exactly where they were.</p>

<p>Understanding there’s no harm to be done eases things a lot. It encourages experimenting, which is one of the most effective ways to learn new things and to get familiar with them. Imagine this: you start rebase, mess things up, hit <nobr><code>Ctrl+Z</code></nobr> several times and try again. Good news is, we can implement Undo/Redo given <em>just ordinary Git implementation</em>. Git already stores all the possible states our repo was in. All Undo/Redo will have to do is to shuffle some branch pointers here and there.</p>

<h2 id="working-with-working-copy">Working with working copy</h2>

<p>Another step towards safe Git experience is working copy management.
Working copy is just a term for all changes you’ve made to the repo directory and haven’t commited yet, so Git knows nothing about them and is not managing them in any way. One sad case where you <em>may</em> lose your work is when you have “dirty” working copy and want to perfom <em>any other operation</em> with Git. It’s a very common use-case, and what Git recommends is to create temporary work-in-progress commit or stash current changes and return back to them later. Git will, in fact, warn you and refuse to do anything before you get your working copy clean. This is very irritating.</p>

<p>As we’re building our (imaginary) brave new Git interface, let’s make some principles and stick to them. Here’s the first one: never bother user with warnings, and never get in a user’s way. What he wants, he should be able to do. But we cannot lose the user’s data either. So what I propose is to, as soon as you need clean working copy, convert current work in progress into “WIP” commit automatically. It saves the user manual labour of commiting or stashing, and keeps unfinished work safe and accessible. The overall Git experience should feel much  smoother and hassle-free.</p>

<div class="anim_cont">
  <div class="anim" style="background-image: url(wip@2x.png);"></div> <div class="anim" style="background-image: url(two-wips@2x.png);"></div>
  <div class="label">Switching branches while having dirty working copy; keeping 2 dirty working copies (hover to animate)</div>
</div>

<p>Unification of working copy and commits brings another major win: it simplifies mental model and brings consistency to working copy interactions. Git is built around commits manipulation, so it’s very logical and consistent to being able to apply all its tools to working copy too. Under the hood, working copy may be treated differently, but for a user there’s no point to be aware of that distinction. From a user’s standpoint, we’ve just removed the concept of working copy altogether, leaving him with the very basic idea — everything is a commit.</p>

<p>This may seem small, but there’re big consequences for Git usage patterns. For example, commiting becomes much more trivial, as you always have WIP commit ready. <nobr><code>git commit</code></nobr> will become, in fact, just a commit renaming. Instead of staging changes to index, we’ll split WIP commit into two — WIP and STAGED, and then rename STAGED to something official. This brings very important addition to the table — ability to explicitly checkout STAGED version. Git’s index won’t allow you that.</p>

<div class="anim_cont">
  <div class="anim" style="background-image: url(commit@2x.png);"></div> <div class="anim" style="background-image: url(staging@2x.png);"></div>
  <div class="label">Commit by rename, stage by split (hover to animate)</div>
</div>

<p>By leaving the user with just one concept that everything is a commit, we put him in a very favourable position — all he needs to learn is how to interact with commits. If he knows that, he’ll also be able to manipulate working copy and to stage changes. We simplified things a lot because in traditional Git these operations are done via completely separate set of commands.</p>

<h2 id="delta-algebra">Delta algebra</h2>

<p>As we more or less know how to commit changes, let’s move to the second most essential thing one can do with Git repo — delta manipulation. Kind of advanced stuff, yet it occurs in everyday Git usage nonetheless. But before discussing that, let me introduce you to commit’s delta-snapshot duality.</p>

<p>As we’ve already learned, commit is a snapshot of repo directory at some point in time. This is technically correct (this is how Git stores commits internally), and this is how commits are used for checkouts. But that’s not the only way one can look at commits. Each commit can also be viewed as delta (or diff, change) of parent’s snapshot and its own. If commit B is based on A, then <code class="highlighter-rouge">delta(B) := diff(snapshot(B), snapshot(A))</code>. Deltas are derived, they are not directly stored by Git, but rather calculated on the fly when needed. Also, merge commits cannot be directly expressed as deltas because they are based on more than one commit.</p>

<p>So, we can view a Git repository not only as a series of periodical backups, but also as a series of changes applied on top of one another. Deltas are easier to comprehend and more directly represent “work done” (you usually think in terms of what was changed rather than entire repo state). They also enable a rich set of interactions with repo we’ll call “delta algebra”.</p>

<p>Main operations of delta algebra are: combine deltas (squash), split delta into two, reverse delta. We’ll also need some bridge to/from commits, specifically getting delta from commit and creating commit from delta. Given that, all sort of Git magic can be expressed: rebase, cherry-pick, revert, commit reordering. Important thing to understand is that they all are based on a very basic delta operations — in essence, we always take <em>these</em> changes, combine/<wbr />split/<wbr />reverse/<wbr />reorder them, and then apply them <em>there</em>. You won’t need anything more than that.</p>

<div class="anim_cont">
  <div class="anim" style="background-image: url(squash@2x.png);"></div>
  <div class="label">Squash operation (hover to animate)</div>
</div>

<p>The main difference from Git is that you expose basic operations instead of high-level shortcuts. Working with fundamental mechanics brings power (there’re more ways to combine basic operations), predictability (as each individual operation is simpler) and eases the learning curve (you’ll be learning the correct mental model from the start).</p>

<div class="anim_cont">
  <div class="anim" style="background-image: url(rebase@2x.png);"></div>  <div class="anim" style="background-image: url(cherry-pick@2x.png);"></div>
  <div class="label">Using direct manipulation to imitate Git rebase and cherry-pick (hover to animate)</div>
</div>

<p>Another important aspect is to make manipulations <em>direct</em> and <em>visual</em>. This always bothers me even in best Git UIs — you see commit tree, you <em>know</em> how you want to rearrange commits, but there’s always that next, very unfortunate step to figure out how to express that in terms of command-line Git commands, which, in its turn, has no direct mappings to your intentions. What proper UI should enable is to select, drag, copy and shuffle commits and branch pointers, including HEAD, <em>directly on the DAG tree</em>. Experience should be much like dragging points in vector graphics editor.</p>

<div class="anim_cont">
  <div class="anim" style="background-image: url(moving-head@2x.png);"></div>
  <div class="label">Moving HEAD pointer to imitate Git checkout (hover to animate)</div>
</div>

<h2 id="staying-connected">Staying connected</h2>

<p>Of course Git is a social tool. While there’s (usually small) point in using it just for yourself, most people use it to collaborate. Git model exposes concept of “remote repositories” and a set of commands to communicate with them: <code class="highlighter-rouge">fetch</code>, <code class="highlighter-rouge">pull</code>, <code class="highlighter-rouge">push</code> and local-remote branches facilities. This is where Git model is a little bit too flexible. But first let’s talk about power of decisions and introduce one more principle.</p>

<p>In some situations, user’s decision is required. Only a human can bring sense and meaning to work, and computer’s job is to provide tools for that. But there’re situations where software asks user about the matters that do not actually require any decision to make. This is dull and tiresome to do operations which add nothing to the job, but are only required for software to continue to run. Sometimes these situations can be easily spotted (like annoying UAC popups), sometimes people are so used to them they think there’s nothing wrong with it (like manual install of bugfix releases), but the criteria is always simple: do I really have a choice? Will my work really, in a qualitative sense, depend on decision I’d make?</p>

<p>So, our next UI principle will be: do not ask user when his decision is not required. Applying this to Git, we should remove any manual branch syncing stuff. Our Git client will always stay online, and will always sync local branches state with remotes. When you create a branch, it gets immediately pushed and visible for all other clients connected to the same repository. If someone else created or advanced any of the branches, it’ll become immediately visible for you. Not a single button click required. Sure, situations when you’ve done changes to the branch and someone else’ve done the same will occur — there’s nothing wrong with that — but these are exceptional cases and in that case two branches will be displayed, local and remote.</p>

<p>There’s a solid foundation for such “always online” experience. <nobr><code>git fetch</code></nobr> is already always safe to do. As we remember, Git never changes or modifies commits, but always creates new ones. So there’s no reason this couldn’t be done automatically (by some Git clients it actually <em>is</em> done automatically already). Creating local branch to track remote one is purely mechanical thing to do — this is required by current Git implementation, but a human has nothing <em>to decide</em> here. The only non-trivial situation is missynced branches, which we leave for user’s decision, because they <em>do require</em> user’s decision.</p>

<p>This is another huge win for us: we’ve removed a whole school of manual syncing commands besides just setting up remote’s URL. No questions to ask, nothing to learn, no place to make a mistake, it just works. And we haven’t really lost anything here because we’ve removed only mechanical operations, ones which do not require user’s decision. From now on, you’ll just commit locally and, magically, everybody else will be able to see your changes. Feels like Dropbox, and this is a big thing. You’ll love that ”always online” experience, I promise.</p>

<p>You may think auto-sync will completely ruin your familiar “commit now, restructure later” workflow. It will not. As you’re working in your branch, you can still reorganise, restructure, reorder and rename commits in your branch. These changes will be incrementally synced to all other peoples’ machines as you go. They’ll initially see your mess, but then they’ll see all the changes you’re doing to make your branch look pretty. All happening without any manual button clicking/<wbr />remotes selections/<wbr />any other decisions from them. As this branch is yours, it’s a perfectly safe and does not require any human intervention.</p>

<p>Remember that network connection is <em>not</em> required for our client to work properly. Offline experience is more or less the same, but when you’re connected, you’ll have less buttons to click.</p>

<h2 id="looks-matter">Looks matter</h2>

<p>I do believe that the best way to observe and understand such a complex thing as DAG of commits is a visual representation. Command-line just don’t cut it. There’s a bad reputation about lousy Git GUIs in a programmer’s world, and they may have a thing. Current Git clients do limit their users to small subset of basic Git operations and rely on a manual command-line mode for all non-trivial cases. In traditional GUIs, you don’t win that much, therefore there’s little motivation to go for GUI in the first place. We, on the other hand, are talking about full-featured Git client able to cover <em>all</em> use-cases that were previously possible only in a command-line. We also bring direct manipulation and Undo/Redo to the picture which is a significant improvement over what we could <em>ever</em> have in console.</p>

<p>So, it has to be visual, what else? Nothing revolutionary here, just a few tweaks to the current state of affairs:</p>

<div class="anim_cont">
  <img src="overview@2x.png" style="width: 554px; height: 400px; padding: 10px; background-color: white; " />
  <div class="label">Visualisation of DAG tree (static screenshot)</div>
</div>

<ul>
  <li>Branch always occupies vertical column, never bends right or left;</li>
  <li>Commits are colored not by branch color (we keep branches visually separated by previous rule), but by author. Author matters — in a team, you usually either look for a commits by specific teammate (to review or merge), or you’re trying to understand who wrote specific piece;</li>
  <li>Merge commits have a different, much subtler look, because they are not an effort per se, but a place where two other efforts join;</li>
  <li>Parents of the current HEAD highlighted, effectively slightly hiding future and parallel commits;</li>
  <li>Branch labels on the left help scan what you are interested in: branches or commit messages.</li>
</ul>

<h2 id="remote-interface">Remote interface</h2>

<p>There’s one single feature that still makes CLI clients look so appealing: ability to work on another machine. Proxying CLI is ubiquitous, proxying GUI is uncommon and still awkward. Can we possibly answer to that?</p>

<p>Thing is, we actually can. There’s one way to proxy GUI applications that is widely used and, if not as smooth as local apps, at least pretty usable. It’s web. Applications controlled via web browser can be run anywhere you can connect to, yet can have almost all the benefits of native GUI apps.</p>

<p>This is the way all modern apps should be written (if “app as a service” model cannot be used): they start web server and open a browser window, providing all UI though JS and HTML. And I’m not talking about node-webkit nonsense here which combines downsides of a web app (limited system integration) with downsides of a native app (cannot be accessed remotely). No, just a regular web server, honest HTTP port, regular browser window. When used locally, experience is the same as with local app, but we get remote execution, literally, for free. With current state of web technology it won’t be any harder (and may, in fact, sometimes be much easier) to develop apps that way.</p>

<h2 id="this-is-awkwardly-long-lets-sum-it-up">This is awkwardly long, let’s sum it up</h2>

<p>We gave a set of recommendations on how Git UI can be improved not on a cosmetic, but on a very fundamental level. Our concept makes Git more usable, powerful and easier to learn mainly by unifying redundant concepts and adding some new features. Here they are:</p>

<ul>
  <li>Remove warnings as Git repo is immutable and cannot lose data</li>
  <li>Provide undo/redo</li>
  <li>Everything is a commit. Treat working copy and staging area as commits, allow regular commit operations to be applied to them</li>
  <li>Provide basic delta manipulations interface</li>
  <li>Direct interaction with visual DAG tree</li>
  <li>Provide always online experience, automatically sync branches with remotes</li>
  <li>Improve looks of DAG tree by providing better coloring and layout</li>
  <li>Make it web app in order to make it accessible from remote machines via browser</li>
</ul>

<p>In spite of the fact that all this sounds revolutinary, it’s important that we can keep full compatibility with regular Git repositories and allow different Git clients to be used together.</p>

<p>I also ask not to discard all this nonsense right away, but at least give it a fair round of thought. My recommendations, if applied in their entirety, can radically change Git experience. They can move Git from advanced, hacky league to the mainstream and enable adoption of VCS by very wide groups of people. While this is still a concept and obviosly requires a hell of a job to become reality, my hope is that somebody working on a Git interface can borrow from these ideas and we all will get better Git client someday.</p>

<style type="text/css">
  .anim_cont { width: 1088px; text-align: center; margin: 2em 0 2em -272px; }
  .anim { width: 400px; height: 250px; background-size: 100%; background-color: white; border-radius: 3px; margin: 0 6px; display: inline-block; }
  .label { margin: 0; text-align: center; font-size: 12px; font-style: italic; }
  img { border-radius: 3px; }
</style>

<script type="text/javascript">

  function animate(el) {
    if (el.animated) {
      el.offset = (el.offset || 0) - 250;  
      setTimeout(function() { animate(el); }, 700);
    }
    el.style.backgroundPosition = "0 " + el.offset + "px";
  }

  var els = document.getElementsByClassName("anim");  
  for (var i=0; i<els.length; ++i) {
    var el = els[i];
    el.onmouseover = function() {
      if (!this.animated) {
        this.animated = true;
        animate(this);
      }
    }
    el.onmouseout = function() {
      this.animated = false;
      this.offset = 0;
      animate(this);
    }
  }
</script>


      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Unofficial guide to Datomic internals</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/unofficial-guide-to-datomic-internals/" />
      <id>https://tonsky.me/blog/unofficial-guide-to-datomic-internals/</id>
      <published>2014-05-06T00:00:00+00:00</published>
      <updated>2014-05-06T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          This post is a compilation of publicly available information, Datomic docs and google group answers about Datomic internals. Intention is to help others understand implementation model and use Datomic more efficiently.
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p><em>Disclaimer: I do not work for Cognitect and, unfortunately, haven’t seen any source code of Datomic. I just made it through a lot of public talks, docs and google group answers about Datomic. This post is a compilation thereof. Intention is to help others use Datomic more efficiently by understanding what they are doing.</em></p>

<h2 id="persistence">Persistence</h2>

<p>Datomic models all data as 4-tuples <code class="highlighter-rouge">(entity, attribute, value, time)</code> called <em>datoms</em>. In “John likes pizza” “John” is an entity, “likes” is an attribute and “pizza” is a value. Everything in Datomic is represented as such simple facts. This simplicity enables Datomic to do more than any relational DB or KV storage can ever afford: to efficiently store and access sparse, irregular, hierarchical, graph data and multi-valued attributes.</p>

<p>Datomic does not manage persistence itself, instead, it outsources storage problems to databases implemented by other people. Data can be kept, at your expense, in DynamoDB, Riak, Infinispan, Couchbase or SQL database.</p>

<p>Storage is used to store segments as binary blobs, similar to how DBs store blocks on file system. It’s basically segment key (UUIDs are used) to segment body mapping, so Datomic requires only two things to be supported by a storage: key-value interface and CAS for updating index root records. Segments are immutable, and, once written, cannot be changed. Re-indexing only writes new segments. This makes consistent reads and immutability possible.</p>

<h2 id="indexes">Indexes</h2>

<p>There’s no dedicated datom storage; instead, covering indexes are used. This means they contain actual data, not a reference to a place where data can be obtained. Data reads happen directly from index, there’s no other place where data is stored beyond indexes. There’s some redundancy in it, because if а datom ends up in 3 indexes, it’ll be stored 3 times. But it’s partially mitigated.</p>

<p>Indexes are B-tree-like structures: sorted, immutable, persistent, 1,000+ branching factor, custom sort order, fast lookup and range scans, able to be efficiently merged (details unknown). Index trees are shallow, no more than three level deep: root node, directories and segments as leafs.</p>

<p>Elements of index trees are not individual datoms, but segments. Segment is an array of datoms, serialised with <a href="https://github.com/datomic/fressian">Fressian</a>, then compressed with zip. Segment size may be up to ~50 Kb, usually including from <nobr>1,000</nobr> to <nobr>20,000</nobr> datoms. Compression enables for faster access time and more efficient cache and storage use.</p>

<p>There’re five indexes, they differ in coverage and are named after the sort order used:</p>

<ul>
  <li>
    <p>EAVT is for efficient access to the attributes of an entity, similar to primary key lookup in traditional DBs.</p>
  </li>
  <li>
    <p>AEVT is for column-style access, to retrieve entities list by a given attribute. Both EAVT and AEVT store every datom.</p>
  </li>
  <li>
    <p>VAET is used for navigating relations backwards and stores all datoms with reference attributes. Given VAET, you can not only find out whom John follows (<code class="highlighter-rouge">“John” :follows ?x</code>), but also efficiently lookup who follows John (<code class="highlighter-rouge">?x :follows “John”</code>).</p>
  </li>
  <li>
    <p>AVET provides efficient lookup by value and stores datoms with attributes marked as <code class="highlighter-rouge">unique</code> or <code class="highlighter-rouge">index</code> in schema. Attributes of this kind are good for external ids. AVET is the most problematic index in practice, and it’s better if you can manage to put monotonic values in it, or use it sparingly.</p>
  </li>
  <li>
    <p>Finally, there’s Log index, which stores all datoms sorted by transaction id.</p>
  </li>
</ul>

<p><img src="https://tonsky.me/blog/unofficial-guide-to-datomic-internals/rss/eavt@2x.png" style="width: 509px; height: 154px" /></p>

<p>Partitions are just big pre-allocated entity id ranges (2<sup>42</sup>). That way, when you add new entities to one partition, they will not mess up EAVT index segments related to other partitions. They also provide semantic grouping: when querying cities, for example, you will not get random stuff that happened to interleave them just by getting next db-wide sequential id.</p>

<p>Same logic applies to attributes: it’s better to have not a single <code class="highlighter-rouge">:name</code> attribute, but use namespaced versions for different entity classes (<code class="highlighter-rouge">:city/name</code>, <code class="highlighter-rouge">:person/name</code>, <code class="highlighter-rouge">:transaction/name</code>, etc.). That way AEVT and AVET index updates will get better locality.</p>

<p>Queries that cannot be covered by index (e.g., filter DB by Tx; or lookup by value of non-indexed attribute) lead to full DB scan and either throw exceptions at you or spend a lot of time “thinking”.</p>

<h2 id="index-internals">Index internals</h2>

<p>Each index is conceptually a single unit, but (except Log) is technically split into three parts, with different location and usage pattern:</p>

<ol>
  <li><em>History</em> part contains datoms that by now have been changed or deleted, so no longer hold true (both initial assertions and subsequent retractions). History is durable and kept in storage.</li>
  <li><em>Current</em> part contains latest assertions only, facts that are relevant at the moment index was built. If “Mary” gets renamed to “John”, only “John”, as latest true datom, will be included. Current part is durable and is kept in the storage too.</li>
  <li><em>In-memory</em> part contains both assertions and retractions, is ephemeral and is kept in peers’ and transactor’s memory.</li>
</ol>

<p>In-memory part acts like a buffer, accumulating novelty between index rebuilds. Newly written data gets written to the Log (hitting storage for write here) and to the in-memory index of transactor. Transactor then propagates that novelty to all peers, ensuring they have the same in-memory index content.</p>

<p><img src="https://tonsky.me/blog/unofficial-guide-to-datomic-internals/rss/index-parts@2x.png" style="width: 450px; height: 157px" /></p>

<p>New peers or peers that got disconnected all start with empty in-memory index. They start reading Log from the point where the latest current index was built, populating their in-memory index from that information.</p>

<p>Peer and transactor communication is push-based. Whenever transactor has completed a transaction, it’ll notify all peers immediately, so peers will know about the new data as fast as it’s possible. Peer <code class="highlighter-rouge">db</code> call does not communicate with transactor, it returns the latest DB value that the peer has heard of.</p>

<h2 id="executing-queries">Executing queries</h2>

<p>Now, we have indexes and want to execute queries over them, right? It is just the time where the ability to efficiently merge persistent trees comes in handy. Queries are never answered from a single index, they always consult two, sometimes three index parts:</p>

<ul>
  <li>
    <p>To answer a regular query, current and in-memory parts get merged, giving you an illusion you’re querying the latest version of DB.</p>
  </li>
  <li>
    <p>To answer <code class="highlighter-rouge">as-of</code> query for moment T, current, in-memory and history parts get merged, and then all data with timestamp after moment T is ignored. Note that <code class="highlighter-rouge">as-of</code> queries do not require older versions of current index, they use most recent current index and filter it by time, deducing the previous view of the database.</p>
  </li>
  <li>
    <p>With <code class="highlighter-rouge">history</code> API call, you get merge result of in-memory, current and history index parts. It will contain all assertions and retractions that have happened during the DB lifetime. You decide what to do with that information.</p>
  </li>
  <li>
    <p>With recent versions of Datomic, you can also access <em>Log</em> index (<code class="highlighter-rouge">log</code>) which is not very efficient for queries, but can be efficiently asked for a range of transactions between two timestamps.</p>
  </li>
</ul>

<h2 id="re-indexing-and-garbage-collection">Re-indexing and garbage collection</h2>

<p>When in-memory index gets too big (<code class="highlighter-rouge">memory-index-threshold</code>, e.g. 32 Mb), transactor starts current index re-built. It is done by merging latest current index with in-memory index. Assertions are copied from in-memory to current index, outdated assertions and retractions are copied from in-memory to history. Changes in attributes marked as <code class="highlighter-rouge">noHistory</code> are silently dropped. When current/history index rebuild is done, peers and transactor learn about new version of them and drop all in-memory novelty that is now covered by the new indexes.</p>

<p><img src="https://tonsky.me/blog/unofficial-guide-to-datomic-internals/rss/index-rebuild@2x.png" style="width: 505px; height: 220px" /></p>

<p>There’s an API call to force re-indexing, <code class="highlighter-rouge">request-index</code>.</p>

<p>All databases obtained from <code class="highlighter-rouge">datomic.api/db</code> call always reference the latest current index. Once current index is rebuilt, there’s no way to obtain reference to older versions of it. The data segments that were referenced by older versions of current index, if they were “changed” and therefore not reused by latest version, are now subject to GC.</p>

<p>Garbage segments can be cleaned up, but if some peer is keeping the reference to the DB it obtained long time ago, that DB still may be referencing an old index. In most cases, you get the <code class="highlighter-rouge">db</code>, do some processing, and forget about it. But analytics processing or other long-running jobs may violate that pattern. Thus, GC is a manual operation, and is recommended to be run rarely (e.g., once a week). There’s an API call for that, <code class="highlighter-rouge">gc-storage</code>. If old index referenced by DB was garbage collected, an equivalent DB version can be obtained by getting latest DB and calling <code class="highlighter-rouge">as-of</code> on it.</p>

<p><img src="https://tonsky.me/blog/unofficial-guide-to-datomic-internals/rss/index-update@2x.png" style="width: 563px; height: 388px" /></p>

<p>Neither GC nor re-indexing are blocking operations. They both happen in background and do not interrupt normal DB operation in any way.</p>

<h2 id="laziness">Laziness</h2>

<p>DB value you run queries across contains reference to root index node. Peer then deduces which segments it needs to execute the query, and reaches storage for missing segments. Queries can run across datasets that do not fit in memory (by loading and unloading cached segments during DB scans), but the result of query should fit in memory. Query results are not lazy.</p>

<p>There’s an API for walking indexes directly (<code class="highlighter-rouge">datoms</code> and <code class="highlighter-rouge">seek-datoms</code>). It’s lazy and can be used when you need to walk big dataset but cannot express your intentions in a query.</p>

<p>Transactor does not participate in queries. Peers with no transactor connection can still do reads from storage. If required segments are already cached, query will be executed without network reads at all.</p>

<h2 id="caching">Caching</h2>

<p>Caching helps to keep working set close and warm, reducing latency and storage load.</p>

<p>Since segments are immutable, it’s a no-brainer to cache them — you don’t need to invalidate. Datomic supports memcache for fast external segments cache, and peer library keeps in-memory cache too. In-memory peer segments maintain two types of cache: compressed segments cache (off heap) and uncompressed segments cache (on heap, limited by <code class="highlighter-rouge">object-cache-max</code>, e.g. 128m).</p>

<p>Because caching happens at segments level, when you obtain one attribute, you probably also obtain 1,000–20,000 datoms around it. It means you won’t get N+1 select problem if you, say, are reading entity attributes one-by-one. This kind of thing was a big no-no in traditional client-server databases.</p>

<h2 id="in-conclusion">In conclusion</h2>

<p>Overall, I’m very impressed how simple and elegant underlying structure is. Building blocks are small, but the combination of them is impressive in feature set. There’s almost no tricks and compromises, everything is derived directly from core model. Transactor and peers are doing very different things using the same set of basic primitives. It feels like they’ve built a whole database from tuple, persistent sorted set and communication queue.</p>


      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Datomic as a Protocol</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/datomic-as-protocol/" />
      <id>https://tonsky.me/blog/datomic-as-protocol/</id>
      <published>2014-04-29T00:00:00+00:00</published>
      <updated>2014-04-29T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Datomic introduced a data structure model: entity-attribute-value store, transaction format, Datalog query language dialect. As you get familiar with it, you notice that this model has a lot of nice properties and is, in fact, more thought-out than it may appear at the first glance.
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>Datomic introduced a data structure model: entity-attribute-value store, transaction format, Datalog query language dialect. As you get familiar with it, you notice that this model has a lot of nice properties and is, in fact, more thought-out than it may appear at the first glance.</p>

<p>Data format is agile and multi-purpose. It works perfectly well with non-regular data, wide columns, a lot of rows, sparse data, graph data. It all can be efficiently stored and accessed.</p>

<p>Since it’s a commercial database, it covers all sorts of use-cases real people face in real world while working with data. You can actually see how the Datomic team started small and added features to the data model as they felt need for them. In other words, the Datomic model is feature-full.</p>

<p>Transactions are just data. In Clojure we’re <a href="http://www.infoq.com/presentations/Thinking-in-Data">used to data-oriented approach</a> and are well aware of its benefits. But there we have data representation not only for database itself, but also for transitions. Simple data structures work well at small scales and within the bounds of a single machine. If you have an atom, it’s easy to store and transfer its value. But when you do <code class="highlighter-rouge">(swap! atom inc)</code>, you cannot transfer that anywhere. You can transfer new value (and it’s totally ok while you can keep it small), but not the change. For dataset sizes up from few hundred kilobytes you start to feel need to transfer deltas instead of entire value. Datomic’s transaction report is a format that allows you to express that delta as a data structure. Benefits follow.</p>

<p>Transaction format happens to match database format. Same exact queries can be run on both. Given a stream of all transactions going through your system, you can easily know when data you’re interested in changes. For example, you have a query that returns a list of items. To monitor for query result updates, you run same query over transaction’s data instead of entire DB and, when you get non-empty results, then some item has been changed, or new item has been added, or some item has been deleted. Note that we monitor not only for changes inside returned items, but for any changes <em>in a collection</em> of items that match or will match, once added, our query. And query doesn’t have to be simple <code class="highlighter-rouge">select * from table</code> query. It can include joins or filtering, and this property will still hold true. The ability to monitor query results’ relevance without querying entire database at each change is indispensable for reactive applications.</p>

<p>Transaction format is reversible. You can easily build a transaction that reverts another transaction. It sure is a nice property to have. I was completely unaware of that before seeing <a href="https://gist.github.com/allgress/11348685">Dave Dixon’s gist</a>.</p>

<p>Datomic model is compact and can be recreated from scratch. It opens the possibility for other languages to utilize same conventions and roll out alternate implementations. I love Rich’s work because he always spends extra time thinking how to reduce required development effort. If he happened, for example, to choose SQL for Datomic, we wouldn’t have any DataScript neither now nor in any foreseeable future. (and probably no Datomic either)</p>

<p>I can easily imagine a distributed system where parts talk to each other via tx-reports and peers run Datalog queries over data and subscribe to database changes. The only big obstacle on our way there is, of course, lack of open-source implementation of Datomic’s basic parts like in-memory index and Datalog query engine. While Cognitect still hasn’t open-sourced these, I started <a href="https://github.com/tonsky/datascript">DataScript</a> to cover that breach for some time. I also see how open-source, lightweight library like DataScript may add value at server-side too, so there’s probably a Clojure version coming.</p>

<p>Given all that, I believe that Datomic was more important as a format, protocol, standard, than as a particular implementation. It sure has a lot of potential, and, what’s more intriguing, not all of its potential is completely understood today. Maybe it’ll change Clojure development landscape to the better — once again.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
  
    <entry>
      <title>Decomposing web app development</title>
      <link rel="alternate" type="text/html" href="https://tonsky.me/blog/decomposing-web-app-development/" />
      <id>https://tonsky.me/blog/decomposing-web-app-development/</id>
      <published>2014-04-24T00:00:00+00:00</published>
      <updated>2014-04-24T00:00:00+00:00</updated>
      
        <summary type="html"><![CDATA[
          Web applications’ story has been incomplete for a long time. There’s a lot of people working in web development, a lot of effort put into it, a lot of thought (I hope), and still we’re far, far away from complex, evolving, reactive web apps. It’s still the Dark Ages.
        ]]></summary>
      
      <content type="html"><![CDATA[
        
        
        
        
        
        <p>Web applications’ story has been incomplete for a long time. There’s a lot of people working in web development, a lot of effort put into it, a lot of thought (I hope), and still we’re far, far away from complex, evolving, reactive web apps. It’s still the Dark Ages.</p>

<p>Web frameworks approach this problem by solving all problems at once. They mix rendering, state management, server communication and reactivity into one big ball of, khm, software. It’s a complex, hard to control, hard to combine and rarely fit-all-your-needs-perfectly way to live your life. Unless you’re writing a TodoMVC app. Then you have a lot of good options, with perfect documentation and loads of examples.</p>

<p>But there’s no reason it has to be that way. We can get closer to building large, maintainable browser apps by separating concerns and providing solutions for them independently.</p>

<p>Rendering DOM was a big problem with a lot of somewhat-okay-ish solutions to choose from, but then <a href="http://facebook.github.io/react/">React.js</a> popped up and now, just one year later, React is really, really hard to ignore. Even me, working on server side most of the day, have already published a public praise to it.</p>

<p>Communication between components is still very much unexplored. <a href="http://clojure.com/blog/2013/06/28/clojure-core-async-channels.html">Core.async</a> is more than fine foundation for it, but usage patterns and best practices have yet to emerge. I know, it <em>is</em> trivial on a small scale, just like connecting plug and socket, but when you have 100 cables to connect, you better wait and see how smart people do it first.</p>

<p>And then there’s an application state. It has been a grey area for a long time, with most frameworks covering it either too aggressive (like Meteor.js), or more as an afterthought. And that’s where DataScript enters.</p>

<p>You always start small, and back then any state management solution seemed like an overkill. You know, “I’ll do fine by just putting this into array…”, “I‘ll create a global variable to store result of this AJAX request”, this kind of attitude. As you grow, this non-uniform, ad-hoc approach to state starts to get in your way. At some point of your life, you will need to query app state in interesting ways. You will need to subscribe for updates not in one model, but in two, three at once, or look for specific pattern in data. You will need rollback. You will need two-ways server sync, failure handling strategy, you will need caching and transactions. Unless you won’t. I mean, that’s a lot of needs, and I have no illusions I can give you one single pill that will address all of them. And it’s not just me, so far nobody succeeded in this area. But it doesn’t mean I can’t help.</p>

<p>If you’re familiar with <a href="https://github.com/swannodette/om">Om</a>, you may have noticed that main thing it sells is not a React integration. It’s state management solution. Which is, in Om, just an atom (a mutable ref holding pointer to immutable tree) where you put state of your whole app. This thing alone gives you a lot of nice properties: rewind to any point in time, subscribe to state changes, synchronization logic can be done outside of the components and is not their concern. Even rendering is, in fact, decoupled nicely from the state, being just one of many potential listeners to state storage. Which is totally fine and a huge win by all means, the only problem being that your state is rarely a nested Hashmap. You can present your app state as a nested Hashmap, but you’ll soon realize that a rare component depends on a strict subtree of that structure. I mean, I wrote a <a href="https://github.com/tonsky/41-socks/">200-line Om app</a> and I already faced this issue.</p>

<p>So, if we want to do better (which we do), how do we keep all these nice properties of Om? They come from two simple facts: state is an immutable data structure, and state management is uniform: everything you app cares about is stored in one single place.</p>

<p>DataScript is exactly that: it’s immutable uniform state management solution. You can think of it as a DB (and that’s totally correct because it imitates a server-side DB, <a href="http://www.datomic.com/">Datomic</a>), but very lightweight and pure in-memory. Or, to put it better, it’s an immutable data structure, like a Hashmap, with ability to run non-trivial queries over it. The whole database is an immutable value, and at any point you can take its value, run query over it (no matter if it’s current actual database or a snapshot from 2 weeks ago), pass it to render, put it into array, store it, send over the wire and so on. It then adds a thin layer on top of that which provides atomic mutations and ability to subscribe for data coming in and out of the database.</p>

<p>And that’s it. There’s nothing more to it. It does not do automatic server sync, it does not do lazy loading, it does not persists itself to local storage, it does not do reactive programming. Instead, it’s <em>a foundation</em>. A sound, capable <em>primitive</em> to build storage solution that fits your application’s needs.</p>

<p>The idea of having a database running inside your browser sounds less crazy when you start to think how much state modern client-side application have to deal with. Take GMail, one of the pioneers of rich web applications: it loads a pile of emails organized into threads which are attached to the labels. At each moment, you have up to three simultaneous <em>views</em> into the same dataset to be kept in sync. Stuff like this is most naturally expressed as queries to structured storage.</p>

<p>But browsers are so scarce in resources, you say. That’s why I do not recommend to think of DataScript as of database. In traditional mindset, doing SQL query is a pain. It’s a thing to avoid. For in-memory database, there’s no particular overhead to it. You don’t do networking, you don’t do serialization/deserialization. It’s all comes down to a lookup in data structure. Or series of lookups. Or array iteration. You put little data in it, it’s fast. You put a lot of data, well, at least it has indexes. That should do better than you filtering an array by hand anyway. Yes, you may even get some performance benefits out of it, although it’s not a primary objective. But the thing is really lightweight.</p>

<p>So, here’s DataScript. Check out <a href="https://github.com/tonsky/datascript">the repo</a>. I hope this example will motivate other people to build other solutions with different performance characteristics and different usage experience. I’ll definitely be glad to see that. The idea is not to use my library, but to have tons of libraries with intentionally narrow scope and excellent combinability. As an app developer, I want to decompose needs of my app and, for every one of them, choose the best possible solution out there. Maybe I’ll have to write some glue code, but in this perfect world, I’m totally ok with it.</p>

      ]]></content>  
      <author>
        <name>Nikita Prokopov</name>
        <email>niki@tonsky.me</email>
      </author>
    </entry>
  
  
 
</feed>